{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPavz-CozWnc"
      },
      "source": [
        "1. This program takes the combined trade and sentiments data as input:\n",
        "a. chainofthought_aapl_trading_sentiment_data_all_days.csv and\n",
        "b. aapl_trading_sentiment_data_all_days_RefPaper.csv\n",
        "2. Sets up the stock trading environment using libraries from https://github.com/benstaf/FinRL_DeepSeek.git\n",
        "3. Trains agents based on data from Chain of Thought prompting approach and the Reference Paper's prompting approach\n",
        "4. Peforms back testing and evaluates both the trading agents\n",
        "5. Compares the performance of the agents     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwYMED_PzgrY",
        "outputId": "b8022a39-693e-440a-ebcc-aeab35e84136"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Collecting finrl\n",
            "  Downloading FinRL-0.3.7-py3-none-any.whl.metadata (909 bytes)\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.11/dist-packages (0.2.54)\n",
            "Collecting stockstats\n",
            "  Downloading stockstats-0.6.4-py2.py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.11/dist-packages (1.1.0)\n",
            "Collecting stable_baselines3\n",
            "  Downloading stable_baselines3-2.6.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting alpaca-trade-api\n",
            "  Downloading alpaca_trade_api-3.2.0-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting exchange_calendars\n",
            "  Downloading exchange_calendars-4.10-py3-none-any.whl.metadata (37 kB)\n",
            "Collecting wrds\n",
            "  Downloading wrds-3.3.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Collecting ta\n",
            "  Downloading ta-0.11.0.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (1.26.4)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.32.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.3.6)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2025.1)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.11/dist-packages (from yfinance) (3.17.9)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.13.3)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (0.0.4)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.5.1+cu124)\n",
            "Collecting urllib3<2,>1.24 (from alpaca-trade-api)\n",
            "  Downloading urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: websocket-client<2,>=0.56.0 in /usr/local/lib/python3.11/dist-packages (from alpaca-trade-api) (1.8.0)\n",
            "Collecting websockets<11,>=9.0 (from alpaca-trade-api)\n",
            "  Downloading websockets-10.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting msgpack==1.0.3 (from alpaca-trade-api)\n",
            "  Downloading msgpack-1.0.3.tar.gz (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from alpaca-trade-api) (3.11.13)\n",
            "Collecting PyYAML==6.0.1 (from alpaca-trade-api)\n",
            "  Downloading PyYAML-6.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting deprecation==2.1.0 (from alpaca-trade-api)\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from deprecation==2.1.0->alpaca-trade-api) (24.2)\n",
            "Collecting pyluach (from exchange_calendars)\n",
            "  Downloading pyluach-2.2.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.11/dist-packages (from exchange_calendars) (0.12.1)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.11/dist-packages (from exchange_calendars) (2025.1)\n",
            "Collecting korean_lunar_calendar (from exchange_calendars)\n",
            "  Downloading korean_lunar_calendar-0.3.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting psycopg2-binary<2.10,>=2.9 (from wrds)\n",
            "  Downloading psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: sqlalchemy<2.1,>=2 in /usr/local/lib/python3.11/dist-packages (from wrds) (2.0.38)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.3->alpaca-trade-api) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.3->alpaca-trade-api) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.3->alpaca-trade-api) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.3->alpaca-trade-api) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.3->alpaca-trade-api) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.3->alpaca-trade-api) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.3->alpaca-trade-api) (1.18.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<2.1,>=2->wrds) (3.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable_baselines3) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0,>=2.3->stable_baselines3) (3.0.2)\n",
            "Downloading FinRL-0.3.7-py3-none-any.whl (127 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.2/127.2 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stockstats-0.6.4-py2.py3-none-any.whl (31 kB)\n",
            "Downloading stable_baselines3-2.6.0-py3-none-any.whl (184 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.5/184.5 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alpaca_trade_api-3.2.0-py3-none-any.whl (34 kB)\n",
            "Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading PyYAML-6.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (757 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m757.7/757.7 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading exchange_calendars-4.10-py3-none-any.whl (198 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.4/198.4 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrds-3.3.0-py3-none-any.whl (13 kB)\n",
            "Downloading psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m103.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m103.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.2/144.2 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-10.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.4/107.4 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading korean_lunar_calendar-0.3.1-py3-none-any.whl (9.0 kB)\n",
            "Downloading pyluach-2.2.0-py3-none-any.whl (25 kB)\n",
            "Building wheels for collected packages: msgpack, ta\n",
            "  Building wheel for msgpack (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for msgpack: filename=msgpack-1.0.3-cp311-cp311-linux_x86_64.whl size=15688 sha256=15fe15db60d65ff6f0ca5bf30c50532890af13a9f6409a6f689e5e71c1b730ce\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/35/da/ed9b26b510235e00e3a3c3bab7bad97b59214729662255ab3d\n",
            "  Building wheel for ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ta: filename=ta-0.11.0-py3-none-any.whl size=29412 sha256=9638696350b2bd3b28ae28e0eaf52a70a9d618425618b1f1f99bf06bbd1a039e\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/d7/29/7781cc5eb9a3659d032d7d15bdd0f49d07d2b24fec29f44bc4\n",
            "Successfully built msgpack ta\n",
            "Installing collected packages: msgpack, korean_lunar_calendar, websockets, urllib3, PyYAML, pyluach, psycopg2-binary, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, finrl, deprecation, nvidia-cusparse-cu12, nvidia-cudnn-cu12, wrds, ta, stockstats, nvidia-cusolver-cu12, exchange_calendars, alpaca-trade-api, stable_baselines3\n",
            "  Attempting uninstall: msgpack\n",
            "    Found existing installation: msgpack 1.1.0\n",
            "    Uninstalling msgpack-1.1.0:\n",
            "      Successfully uninstalled msgpack-1.1.0\n",
            "  Attempting uninstall: websockets\n",
            "    Found existing installation: websockets 14.2\n",
            "    Uninstalling websockets-14.2:\n",
            "      Successfully uninstalled websockets-14.2\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.3.0\n",
            "    Uninstalling urllib3-2.3.0:\n",
            "      Successfully uninstalled urllib3-2.3.0\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 6.0.2\n",
            "    Uninstalling PyYAML-6.0.2:\n",
            "      Successfully uninstalled PyYAML-6.0.2\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-genai 1.2.0 requires websockets<15.0dev,>=13.0, but you have websockets 10.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PyYAML-6.0.1 alpaca-trade-api-3.2.0 deprecation-2.1.0 exchange_calendars-4.10 finrl-0.3.7 korean_lunar_calendar-0.3.1 msgpack-1.0.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 psycopg2-binary-2.9.10 pyluach-2.2.0 stable_baselines3-2.6.0 stockstats-0.6.4 ta-0.11.0 urllib3-1.26.20 websockets-10.4 wrds-3.3.0\n",
            "Cloning into 'FinRL_DeepSeek'...\n",
            "remote: Enumerating objects: 145, done.\u001b[K\n",
            "remote: Counting objects: 100% (145/145), done.\u001b[K\n",
            "remote: Compressing objects: 100% (144/144), done.\u001b[K\n",
            "remote: Total 145 (delta 94), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (145/145), 1.21 MiB | 8.70 MiB/s, done.\n",
            "Resolving deltas: 100% (94/94), done.\n",
            "/content/FinRL_DeepSeek\n"
          ]
        }
      ],
      "source": [
        "# Step 0: Prerequisites & Setup\n",
        "# -------------------------------------------------\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install finrl yfinance stockstats gymnasium stable_baselines3 alpaca-trade-api exchange_calendars wrds matplotlib pandas scikit-learn ta\n",
        "%matplotlib inline\n",
        "\n",
        "# Clone repo and set paths\n",
        "!git clone https://github.com/benstaf/FinRL_DeepSeek.git\n",
        "%cd /content/FinRL_DeepSeek\n",
        "import sys\n",
        "sys.path.append('/content/FinRL_DeepSeek')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wjIshuqAXEPC"
      },
      "outputs": [],
      "source": [
        "# Step 1: Create directory to persist models\n",
        "# -------------------------------------------------\n",
        "\n",
        "\n",
        "import os\n",
        "\n",
        "MODEL_DIR = \"/content/drive/MyDrive/finrl_models\"\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ruZ065y6ziXX"
      },
      "outputs": [],
      "source": [
        "# -------------------------------------------------\n",
        "# Step 2: Data Loading and Preparation\n",
        "# -------------------------------------------------\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from finrl.meta.preprocessor.preprocessors import data_split\n",
        "import itertools\n",
        "\n",
        "def load_and_prepare_data(filepath):\n",
        "    \"\"\"Load and prepare dataset for training\"\"\"\n",
        "    df = pd.read_csv(filepath)\n",
        "    df['date'] = pd.to_datetime(df['date']).dt.normalize()\n",
        "\n",
        "    # Drop unwanted columns\n",
        "    df = df.drop(columns=[col for col in df.columns if 'Unnamed:' in col or col.endswith('_y')])\n",
        "    df.columns = [col.replace('_x', '') for col in df.columns]\n",
        "\n",
        "    # Forward fill missing values\n",
        "    list_ticker = df[\"tic\"].unique().tolist()\n",
        "    list_date = pd.date_range(start=df['date'].min(), end=df['date'].max())\n",
        "    combination = list(itertools.product(list_date, list_ticker))\n",
        "\n",
        "    processed_full = pd.DataFrame(combination, columns=[\"date\", \"tic\"])\n",
        "    processed_full['date'] = pd.to_datetime(processed_full['date']).dt.normalize()\n",
        "    processed_full = processed_full.merge(df, on=[\"date\", \"tic\"], how=\"left\")\n",
        "    processed_full = processed_full.sort_values(by=[\"tic\", \"date\"]).ffill()\n",
        "\n",
        "    return processed_full\n",
        "\n",
        "# Load both datasets\n",
        "chainofthought_df = load_and_prepare_data('/content/chainofthought_aapl_trading_sentiment_data_all_days.csv')\n",
        "refpaper_df = load_and_prepare_data('/content/aapl_trading_sentiment_data_all_days_RefPaper.csv')\n",
        "\n",
        "# Split into train/trade periods\n",
        "TRAIN_START_DATE = '2022-06-03'\n",
        "TRAIN_END_DATE = '2023-06-30'\n",
        "TRADE_START_DATE = '2023-07-01'\n",
        "TRADE_END_DATE = '2023-12-16'\n",
        "\n",
        "def split_data(df):\n",
        "    train_df = data_split(df, TRAIN_START_DATE, TRAIN_END_DATE)\n",
        "    trade_df = data_split(df, TRADE_START_DATE, TRADE_END_DATE)\n",
        "    return train_df, trade_df\n",
        "\n",
        "chainofthought_train, chainofthought_trade = split_data(chainofthought_df)\n",
        "refpaper_train, refpaper_trade = split_data(refpaper_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "249pPx9K0IAO",
        "outputId": "dcb94f19-b260-4399-abf4-719475942e99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lenght of INDICATORS 8\n",
            "lenght of INDICATORS 8\n",
            "Number of indicators: 8\n"
          ]
        }
      ],
      "source": [
        "# -------------------------------------------------\n",
        "# Step 3: Environment Setup\n",
        "# -------------------------------------------------\n",
        "from env_stocktrading import StockTradingEnv\n",
        "from finrl.config import INDICATORS\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "import gymnasium as gym\n",
        "\n",
        "def create_env(df, state_space=11):  # Correct observation space size\n",
        "    \"\"\"Create trading environment\"\"\"\n",
        "    env = StockTradingEnv(\n",
        "        df=df,\n",
        "        stock_dim=1,\n",
        "        num_stock_shares=[100],\n",
        "        buy_cost_pct=[0.001],\n",
        "        sell_cost_pct=[0.001],\n",
        "        hmax=100,\n",
        "        initial_amount=1_000_000,\n",
        "        reward_scaling=1e-4,\n",
        "        state_space=state_space,\n",
        "        action_space=1,\n",
        "        tech_indicator_list=INDICATORS,\n",
        "        risk_indicator_col='sentiment'\n",
        "    )\n",
        "    print(\"lenght of INDICATORS\" , len(INDICATORS))\n",
        "    return DummyVecEnv([lambda: env])\n",
        "\n",
        "# Create environments with correct observation size\n",
        "chainofthought_train_env = create_env(chainofthought_train)\n",
        "refpaper_train_env = create_env(refpaper_train)\n",
        "\n",
        "from finrl.config import INDICATORS\n",
        "print(f\"Number of indicators: {len(INDICATORS)}\")  # e.g., 5\n",
        "state_space_size=11\n",
        "#state_space_sizeprint(f\"State space size : {len(state_space_size)}\")\n",
        "#state_space_size = 4 (price) + 1 (holdings) + len(INDICATORS) + 1 #(sentiment if used)\n",
        "#print(f\"Calculated state space size: {state_space_size}\")\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKoDZquekHLX",
        "outputId": "377ce4d3-8dcb-4f0a-869c-eaf2b139099a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Chain of Thought Agent…\n",
            "Using cuda device\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/policies.py:486: UserWarning: As shared layers in the mlp_extractor are removed since SB3 v1.8.0, you should now pass directly a dictionary and not a list (net_arch=dict(pi=..., vf=...) instead of net_arch=[dict(pi=..., vf=...)])\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 463  |\n",
            "|    iterations      | 1    |\n",
            "|    time_elapsed    | 4    |\n",
            "|    total_timesteps | 2048 |\n",
            "-----------------------------\n",
            "day: 391, episode: 10\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1047200.94\n",
            "total_reward: 32857.98\n",
            "total_cost: 3850.27\n",
            "total_trades: 386\n",
            "Sharpe: 0.517\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 393          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 10           |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0004316172 |\n",
            "|    clip_fraction        | 0.0108       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | -0.0194      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.244        |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.000242    |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 0.749        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 411          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 14           |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034424572 |\n",
            "|    clip_fraction        | 0.0195       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.43        |\n",
            "|    explained_variance   | -0.00181     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.339        |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.00097     |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 0.527        |\n",
            "------------------------------------------\n",
            "day: 391, episode: 20\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1014782.29\n",
            "total_reward: 439.33\n",
            "total_cost: 2991.83\n",
            "total_trades: 333\n",
            "Sharpe: 0.026\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 419          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 19           |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054024467 |\n",
            "|    clip_fraction        | 0.0313       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.43        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.17         |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.00195     |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 0.231        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 412          |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 24           |\n",
            "|    total_timesteps      | 10240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036071527 |\n",
            "|    clip_fraction        | 0.016        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0143       |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.000929    |\n",
            "|    std                  | 0.999        |\n",
            "|    value_loss           | 0.052        |\n",
            "------------------------------------------\n",
            "day: 391, episode: 30\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1008502.96\n",
            "total_reward: -5840.00\n",
            "total_cost: 3548.11\n",
            "total_trades: 383\n",
            "Sharpe: -0.102\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 418         |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 29          |\n",
            "|    total_timesteps      | 12288       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007491653 |\n",
            "|    clip_fraction        | 0.0371      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.41       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0384      |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.00334    |\n",
            "|    std                  | 0.979       |\n",
            "|    value_loss           | 0.0757      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 417          |\n",
            "|    iterations           | 7            |\n",
            "|    time_elapsed         | 34           |\n",
            "|    total_timesteps      | 14336        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011347557 |\n",
            "|    clip_fraction        | 0.000586     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.39        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.41         |\n",
            "|    n_updates            | 60           |\n",
            "|    policy_gradient_loss | -0.000151    |\n",
            "|    std                  | 0.963        |\n",
            "|    value_loss           | 0.697        |\n",
            "------------------------------------------\n",
            "day: 391, episode: 40\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1145892.53\n",
            "total_reward: 131549.57\n",
            "total_cost: 3438.05\n",
            "total_trades: 388\n",
            "Sharpe: 0.985\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 417          |\n",
            "|    iterations           | 8            |\n",
            "|    time_elapsed         | 39           |\n",
            "|    total_timesteps      | 16384        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0071198856 |\n",
            "|    clip_fraction        | 0.075        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.37        |\n",
            "|    explained_variance   | 0.000688     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.293        |\n",
            "|    n_updates            | 70           |\n",
            "|    policy_gradient_loss | -0.00488     |\n",
            "|    std                  | 0.95         |\n",
            "|    value_loss           | 0.764        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 421         |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 43          |\n",
            "|    total_timesteps      | 18432       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002685722 |\n",
            "|    clip_fraction        | 0.00195     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.36       |\n",
            "|    explained_variance   | 0.0119      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.991       |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.000334   |\n",
            "|    std                  | 0.941       |\n",
            "|    value_loss           | 2.16        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 50\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1302112.17\n",
            "total_reward: 287769.21\n",
            "total_cost: 3626.40\n",
            "total_trades: 388\n",
            "Sharpe: 1.210\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 417        |\n",
            "|    iterations           | 10         |\n",
            "|    time_elapsed         | 49         |\n",
            "|    total_timesteps      | 20480      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00382774 |\n",
            "|    clip_fraction        | 0.0269     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.35      |\n",
            "|    explained_variance   | 0          |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.74       |\n",
            "|    n_updates            | 90         |\n",
            "|    policy_gradient_loss | -0.00178   |\n",
            "|    std                  | 0.932      |\n",
            "|    value_loss           | 1.25       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 420         |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 53          |\n",
            "|    total_timesteps      | 22528       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003236146 |\n",
            "|    clip_fraction        | 0.0184      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.35       |\n",
            "|    explained_variance   | -0.0268     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.841       |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.00191    |\n",
            "|    std                  | 0.936       |\n",
            "|    value_loss           | 2.81        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 60\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1293798.26\n",
            "total_reward: 279455.30\n",
            "total_cost: 3474.88\n",
            "total_trades: 389\n",
            "Sharpe: 1.147\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 423          |\n",
            "|    iterations           | 12           |\n",
            "|    time_elapsed         | 58           |\n",
            "|    total_timesteps      | 24576        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012085277 |\n",
            "|    clip_fraction        | 0.0165       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.35        |\n",
            "|    explained_variance   | 0.0999       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.74         |\n",
            "|    n_updates            | 110          |\n",
            "|    policy_gradient_loss | -0.00133     |\n",
            "|    std                  | 0.927        |\n",
            "|    value_loss           | 5.1          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 419          |\n",
            "|    iterations           | 13           |\n",
            "|    time_elapsed         | 63           |\n",
            "|    total_timesteps      | 26624        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012474463 |\n",
            "|    clip_fraction        | 0.0131       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.34        |\n",
            "|    explained_variance   | 0.311        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.05         |\n",
            "|    n_updates            | 120          |\n",
            "|    policy_gradient_loss | -0.000158    |\n",
            "|    std                  | 0.929        |\n",
            "|    value_loss           | 7.34         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 70\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1288453.14\n",
            "total_reward: 274110.18\n",
            "total_cost: 3207.33\n",
            "total_trades: 389\n",
            "Sharpe: 0.961\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 421          |\n",
            "|    iterations           | 14           |\n",
            "|    time_elapsed         | 67           |\n",
            "|    total_timesteps      | 28672        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032647264 |\n",
            "|    clip_fraction        | 0.0218       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.34        |\n",
            "|    explained_variance   | 0.34         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.68         |\n",
            "|    n_updates            | 130          |\n",
            "|    policy_gradient_loss | -0.00176     |\n",
            "|    std                  | 0.926        |\n",
            "|    value_loss           | 7.57         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 422          |\n",
            "|    iterations           | 15           |\n",
            "|    time_elapsed         | 72           |\n",
            "|    total_timesteps      | 30720        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0043919953 |\n",
            "|    clip_fraction        | 0.033        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.34        |\n",
            "|    explained_variance   | 0.389        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.59         |\n",
            "|    n_updates            | 140          |\n",
            "|    policy_gradient_loss | -0.00181     |\n",
            "|    std                  | 0.919        |\n",
            "|    value_loss           | 6.82         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 80\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1280080.74\n",
            "total_reward: 265737.78\n",
            "total_cost: 3429.03\n",
            "total_trades: 390\n",
            "Sharpe: 1.296\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 421         |\n",
            "|    iterations           | 16          |\n",
            "|    time_elapsed         | 77          |\n",
            "|    total_timesteps      | 32768       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004291202 |\n",
            "|    clip_fraction        | 0.0221      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.33       |\n",
            "|    explained_variance   | 0.516       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.05        |\n",
            "|    n_updates            | 150         |\n",
            "|    policy_gradient_loss | 7.5e-06     |\n",
            "|    std                  | 0.906       |\n",
            "|    value_loss           | 8.01        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 423          |\n",
            "|    iterations           | 17           |\n",
            "|    time_elapsed         | 82           |\n",
            "|    total_timesteps      | 34816        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025252816 |\n",
            "|    clip_fraction        | 0.018        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.32        |\n",
            "|    explained_variance   | 0.553        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.72         |\n",
            "|    n_updates            | 160          |\n",
            "|    policy_gradient_loss | -0.00126     |\n",
            "|    std                  | 0.901        |\n",
            "|    value_loss           | 8.16         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 90\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1293879.80\n",
            "total_reward: 279536.84\n",
            "total_cost: 2819.48\n",
            "total_trades: 385\n",
            "Sharpe: 0.994\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 421         |\n",
            "|    iterations           | 18          |\n",
            "|    time_elapsed         | 87          |\n",
            "|    total_timesteps      | 36864       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004612758 |\n",
            "|    clip_fraction        | 0.0455      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.31       |\n",
            "|    explained_variance   | 0.633       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.27        |\n",
            "|    n_updates            | 170         |\n",
            "|    policy_gradient_loss | -0.00328    |\n",
            "|    std                  | 0.889       |\n",
            "|    value_loss           | 8.14        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 422         |\n",
            "|    iterations           | 19          |\n",
            "|    time_elapsed         | 92          |\n",
            "|    total_timesteps      | 38912       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004564065 |\n",
            "|    clip_fraction        | 0.0371      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.3        |\n",
            "|    explained_variance   | 0.623       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.11        |\n",
            "|    n_updates            | 180         |\n",
            "|    policy_gradient_loss | -0.00224    |\n",
            "|    std                  | 0.886       |\n",
            "|    value_loss           | 9.27        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 100\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1292196.12\n",
            "total_reward: 277853.16\n",
            "total_cost: 3201.90\n",
            "total_trades: 386\n",
            "Sharpe: 1.013\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 423          |\n",
            "|    iterations           | 20           |\n",
            "|    time_elapsed         | 96           |\n",
            "|    total_timesteps      | 40960        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0055242274 |\n",
            "|    clip_fraction        | 0.0271       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.673        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.49         |\n",
            "|    n_updates            | 190          |\n",
            "|    policy_gradient_loss | -0.00194     |\n",
            "|    std                  | 0.879        |\n",
            "|    value_loss           | 8.7          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 422         |\n",
            "|    iterations           | 21          |\n",
            "|    time_elapsed         | 101         |\n",
            "|    total_timesteps      | 43008       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006683482 |\n",
            "|    clip_fraction        | 0.053       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.29       |\n",
            "|    explained_variance   | 0.689       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.14        |\n",
            "|    n_updates            | 200         |\n",
            "|    policy_gradient_loss | -0.00403    |\n",
            "|    std                  | 0.875       |\n",
            "|    value_loss           | 9.14        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 110\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1260045.54\n",
            "total_reward: 245702.58\n",
            "total_cost: 2604.54\n",
            "total_trades: 388\n",
            "Sharpe: 0.772\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 423          |\n",
            "|    iterations           | 22           |\n",
            "|    time_elapsed         | 106          |\n",
            "|    total_timesteps      | 45056        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015303787 |\n",
            "|    clip_fraction        | 0.011        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.7          |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.79         |\n",
            "|    n_updates            | 210          |\n",
            "|    policy_gradient_loss | -0.000147    |\n",
            "|    std                  | 0.874        |\n",
            "|    value_loss           | 9.44         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 120\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1229882.78\n",
            "total_reward: 215539.82\n",
            "total_cost: 2445.21\n",
            "total_trades: 391\n",
            "Sharpe: 0.673\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 424         |\n",
            "|    iterations           | 23          |\n",
            "|    time_elapsed         | 110         |\n",
            "|    total_timesteps      | 47104       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003272114 |\n",
            "|    clip_fraction        | 0.00396     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.29       |\n",
            "|    explained_variance   | 0.698       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.36        |\n",
            "|    n_updates            | 220         |\n",
            "|    policy_gradient_loss | -0.000505   |\n",
            "|    std                  | 0.876       |\n",
            "|    value_loss           | 9.8         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 423         |\n",
            "|    iterations           | 24          |\n",
            "|    time_elapsed         | 116         |\n",
            "|    total_timesteps      | 49152       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004639621 |\n",
            "|    clip_fraction        | 0.0294      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.29       |\n",
            "|    explained_variance   | 0.621       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.31        |\n",
            "|    n_updates            | 230         |\n",
            "|    policy_gradient_loss | -0.00198    |\n",
            "|    std                  | 0.879       |\n",
            "|    value_loss           | 10.7        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 130\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1244951.29\n",
            "total_reward: 230608.34\n",
            "total_cost: 2627.80\n",
            "total_trades: 389\n",
            "Sharpe: 0.732\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 424          |\n",
            "|    iterations           | 25           |\n",
            "|    time_elapsed         | 120          |\n",
            "|    total_timesteps      | 51200        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010851659 |\n",
            "|    clip_fraction        | 0.0188       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.614        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.91         |\n",
            "|    n_updates            | 240          |\n",
            "|    policy_gradient_loss | 0.000125     |\n",
            "|    std                  | 0.875        |\n",
            "|    value_loss           | 10.5         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 423          |\n",
            "|    iterations           | 26           |\n",
            "|    time_elapsed         | 125          |\n",
            "|    total_timesteps      | 53248        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0049646664 |\n",
            "|    clip_fraction        | 0.0128       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.555        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.8          |\n",
            "|    n_updates            | 250          |\n",
            "|    policy_gradient_loss | -0.00101     |\n",
            "|    std                  | 0.877        |\n",
            "|    value_loss           | 10.5         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 140\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1272558.62\n",
            "total_reward: 258215.66\n",
            "total_cost: 2652.89\n",
            "total_trades: 389\n",
            "Sharpe: 0.809\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 423         |\n",
            "|    iterations           | 27          |\n",
            "|    time_elapsed         | 130         |\n",
            "|    total_timesteps      | 55296       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004755087 |\n",
            "|    clip_fraction        | 0.0326      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.28       |\n",
            "|    explained_variance   | 0.626       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.49        |\n",
            "|    n_updates            | 260         |\n",
            "|    policy_gradient_loss | -0.000538   |\n",
            "|    std                  | 0.87        |\n",
            "|    value_loss           | 9.23        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 424         |\n",
            "|    iterations           | 28          |\n",
            "|    time_elapsed         | 134         |\n",
            "|    total_timesteps      | 57344       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003985365 |\n",
            "|    clip_fraction        | 0.0176      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.28       |\n",
            "|    explained_variance   | 0.56        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.39        |\n",
            "|    n_updates            | 270         |\n",
            "|    policy_gradient_loss | -0.000439   |\n",
            "|    std                  | 0.861       |\n",
            "|    value_loss           | 10          |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 150\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1245604.57\n",
            "total_reward: 231261.61\n",
            "total_cost: 2464.93\n",
            "total_trades: 388\n",
            "Sharpe: 0.737\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 423          |\n",
            "|    iterations           | 29           |\n",
            "|    time_elapsed         | 140          |\n",
            "|    total_timesteps      | 59392        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0057225293 |\n",
            "|    clip_fraction        | 0.0437       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.26        |\n",
            "|    explained_variance   | 0.548        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.49         |\n",
            "|    n_updates            | 280          |\n",
            "|    policy_gradient_loss | -0.00173     |\n",
            "|    std                  | 0.846        |\n",
            "|    value_loss           | 10.1         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 424          |\n",
            "|    iterations           | 30           |\n",
            "|    time_elapsed         | 144          |\n",
            "|    total_timesteps      | 61440        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025116717 |\n",
            "|    clip_fraction        | 0.0252       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.25        |\n",
            "|    explained_variance   | 0.538        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.8          |\n",
            "|    n_updates            | 290          |\n",
            "|    policy_gradient_loss | -0.000435    |\n",
            "|    std                  | 0.843        |\n",
            "|    value_loss           | 10.8         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 160\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1269478.53\n",
            "total_reward: 255135.57\n",
            "total_cost: 2764.08\n",
            "total_trades: 385\n",
            "Sharpe: 0.824\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 425          |\n",
            "|    iterations           | 31           |\n",
            "|    time_elapsed         | 149          |\n",
            "|    total_timesteps      | 63488        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019839664 |\n",
            "|    clip_fraction        | 0.0313       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.25        |\n",
            "|    explained_variance   | 0.579        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.47         |\n",
            "|    n_updates            | 300          |\n",
            "|    policy_gradient_loss | 0.000301     |\n",
            "|    std                  | 0.84         |\n",
            "|    value_loss           | 10.1         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 423          |\n",
            "|    iterations           | 32           |\n",
            "|    time_elapsed         | 154          |\n",
            "|    total_timesteps      | 65536        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034011584 |\n",
            "|    clip_fraction        | 0.0386       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.24        |\n",
            "|    explained_variance   | 0.591        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.55         |\n",
            "|    n_updates            | 310          |\n",
            "|    policy_gradient_loss | -0.000785    |\n",
            "|    std                  | 0.834        |\n",
            "|    value_loss           | 9.69         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 170\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1249056.62\n",
            "total_reward: 234713.66\n",
            "total_cost: 2408.10\n",
            "total_trades: 386\n",
            "Sharpe: 0.747\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 423          |\n",
            "|    iterations           | 33           |\n",
            "|    time_elapsed         | 159          |\n",
            "|    total_timesteps      | 67584        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030730194 |\n",
            "|    clip_fraction        | 0.0419       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.24        |\n",
            "|    explained_variance   | 0.637        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.13         |\n",
            "|    n_updates            | 320          |\n",
            "|    policy_gradient_loss | 0.000826     |\n",
            "|    std                  | 0.834        |\n",
            "|    value_loss           | 8.62         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 423          |\n",
            "|    iterations           | 34           |\n",
            "|    time_elapsed         | 164          |\n",
            "|    total_timesteps      | 69632        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0064250254 |\n",
            "|    clip_fraction        | 0.033        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.24        |\n",
            "|    explained_variance   | 0.641        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.17         |\n",
            "|    n_updates            | 330          |\n",
            "|    policy_gradient_loss | -9.6e-05     |\n",
            "|    std                  | 0.83         |\n",
            "|    value_loss           | 9.66         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 180\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1261716.70\n",
            "total_reward: 247373.74\n",
            "total_cost: 2533.37\n",
            "total_trades: 388\n",
            "Sharpe: 0.799\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 423          |\n",
            "|    iterations           | 35           |\n",
            "|    time_elapsed         | 169          |\n",
            "|    total_timesteps      | 71680        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038368022 |\n",
            "|    clip_fraction        | 0.0271       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.23        |\n",
            "|    explained_variance   | 0.623        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.83         |\n",
            "|    n_updates            | 340          |\n",
            "|    policy_gradient_loss | -0.0016      |\n",
            "|    std                  | 0.829        |\n",
            "|    value_loss           | 9.95         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 424          |\n",
            "|    iterations           | 36           |\n",
            "|    time_elapsed         | 173          |\n",
            "|    total_timesteps      | 73728        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020990535 |\n",
            "|    clip_fraction        | 0.0222       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.23        |\n",
            "|    explained_variance   | 0.6          |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.56         |\n",
            "|    n_updates            | 350          |\n",
            "|    policy_gradient_loss | 0.000902     |\n",
            "|    std                  | 0.821        |\n",
            "|    value_loss           | 10.4         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 190\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1263388.63\n",
            "total_reward: 249045.67\n",
            "total_cost: 2579.59\n",
            "total_trades: 387\n",
            "Sharpe: 0.784\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 423         |\n",
            "|    iterations           | 37          |\n",
            "|    time_elapsed         | 179         |\n",
            "|    total_timesteps      | 75776       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003910023 |\n",
            "|    clip_fraction        | 0.034       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.22       |\n",
            "|    explained_variance   | 0.586       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.53        |\n",
            "|    n_updates            | 360         |\n",
            "|    policy_gradient_loss | 0.000248    |\n",
            "|    std                  | 0.815       |\n",
            "|    value_loss           | 10.3        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 423         |\n",
            "|    iterations           | 38          |\n",
            "|    time_elapsed         | 183         |\n",
            "|    total_timesteps      | 77824       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004233734 |\n",
            "|    clip_fraction        | 0.0347      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.22       |\n",
            "|    explained_variance   | 0.608       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.38        |\n",
            "|    n_updates            | 370         |\n",
            "|    policy_gradient_loss | -0.00135    |\n",
            "|    std                  | 0.821       |\n",
            "|    value_loss           | 10.6        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 200\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1254810.91\n",
            "total_reward: 240467.95\n",
            "total_cost: 2343.69\n",
            "total_trades: 389\n",
            "Sharpe: 0.812\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 424          |\n",
            "|    iterations           | 39           |\n",
            "|    time_elapsed         | 188          |\n",
            "|    total_timesteps      | 79872        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033648363 |\n",
            "|    clip_fraction        | 0.0197       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.23        |\n",
            "|    explained_variance   | 0.582        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.27         |\n",
            "|    n_updates            | 380          |\n",
            "|    policy_gradient_loss | 0.000922     |\n",
            "|    std                  | 0.827        |\n",
            "|    value_loss           | 10.9         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 423          |\n",
            "|    iterations           | 40           |\n",
            "|    time_elapsed         | 193          |\n",
            "|    total_timesteps      | 81920        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045851385 |\n",
            "|    clip_fraction        | 0.0272       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.22        |\n",
            "|    explained_variance   | 0.587        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.18         |\n",
            "|    n_updates            | 390          |\n",
            "|    policy_gradient_loss | -0.000135    |\n",
            "|    std                  | 0.813        |\n",
            "|    value_loss           | 9.98         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 210\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1249393.15\n",
            "total_reward: 235050.19\n",
            "total_cost: 2383.21\n",
            "total_trades: 389\n",
            "Sharpe: 0.728\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 423         |\n",
            "|    iterations           | 41          |\n",
            "|    time_elapsed         | 198         |\n",
            "|    total_timesteps      | 83968       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005900711 |\n",
            "|    clip_fraction        | 0.033       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.21       |\n",
            "|    explained_variance   | 0.542       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.52        |\n",
            "|    n_updates            | 400         |\n",
            "|    policy_gradient_loss | -0.000166   |\n",
            "|    std                  | 0.811       |\n",
            "|    value_loss           | 9.74        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 423          |\n",
            "|    iterations           | 42           |\n",
            "|    time_elapsed         | 202          |\n",
            "|    total_timesteps      | 86016        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0052124984 |\n",
            "|    clip_fraction        | 0.0351       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.2         |\n",
            "|    explained_variance   | 0.564        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.45         |\n",
            "|    n_updates            | 410          |\n",
            "|    policy_gradient_loss | -0.000214    |\n",
            "|    std                  | 0.799        |\n",
            "|    value_loss           | 9.79         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 220\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1249533.80\n",
            "total_reward: 235190.84\n",
            "total_cost: 2349.07\n",
            "total_trades: 388\n",
            "Sharpe: 0.788\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 423          |\n",
            "|    iterations           | 43           |\n",
            "|    time_elapsed         | 207          |\n",
            "|    total_timesteps      | 88064        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0071589416 |\n",
            "|    clip_fraction        | 0.056        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.2         |\n",
            "|    explained_variance   | 0.579        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.67         |\n",
            "|    n_updates            | 420          |\n",
            "|    policy_gradient_loss | -0.000429    |\n",
            "|    std                  | 0.799        |\n",
            "|    value_loss           | 10.4         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 424          |\n",
            "|    iterations           | 44           |\n",
            "|    time_elapsed         | 212          |\n",
            "|    total_timesteps      | 90112        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016658485 |\n",
            "|    clip_fraction        | 0.0168       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.19        |\n",
            "|    explained_variance   | 0.656        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.28         |\n",
            "|    n_updates            | 430          |\n",
            "|    policy_gradient_loss | 2.66e-05     |\n",
            "|    std                  | 0.799        |\n",
            "|    value_loss           | 8.79         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 230\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1278595.18\n",
            "total_reward: 264252.23\n",
            "total_cost: 2506.91\n",
            "total_trades: 388\n",
            "Sharpe: 0.863\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 423          |\n",
            "|    iterations           | 45           |\n",
            "|    time_elapsed         | 217          |\n",
            "|    total_timesteps      | 92160        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0055195056 |\n",
            "|    clip_fraction        | 0.0226       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.19        |\n",
            "|    explained_variance   | 0.657        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.03         |\n",
            "|    n_updates            | 440          |\n",
            "|    policy_gradient_loss | -0.000627    |\n",
            "|    std                  | 0.789        |\n",
            "|    value_loss           | 9.36         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 240\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1260706.95\n",
            "total_reward: 246363.99\n",
            "total_cost: 2075.14\n",
            "total_trades: 390\n",
            "Sharpe: 0.754\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 423         |\n",
            "|    iterations           | 46          |\n",
            "|    time_elapsed         | 222         |\n",
            "|    total_timesteps      | 94208       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008028019 |\n",
            "|    clip_fraction        | 0.0522      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.18       |\n",
            "|    explained_variance   | 0.629       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.88        |\n",
            "|    n_updates            | 450         |\n",
            "|    policy_gradient_loss | -0.000109   |\n",
            "|    std                  | 0.791       |\n",
            "|    value_loss           | 9.51        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 424          |\n",
            "|    iterations           | 47           |\n",
            "|    time_elapsed         | 226          |\n",
            "|    total_timesteps      | 96256        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0073205833 |\n",
            "|    clip_fraction        | 0.0557       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.18        |\n",
            "|    explained_variance   | 0.622        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.3          |\n",
            "|    n_updates            | 460          |\n",
            "|    policy_gradient_loss | -0.00211     |\n",
            "|    std                  | 0.79         |\n",
            "|    value_loss           | 10.4         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 250\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1257383.43\n",
            "total_reward: 243040.47\n",
            "total_cost: 2162.30\n",
            "total_trades: 387\n",
            "Sharpe: 0.757\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 423          |\n",
            "|    iterations           | 48           |\n",
            "|    time_elapsed         | 232          |\n",
            "|    total_timesteps      | 98304        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0060119955 |\n",
            "|    clip_fraction        | 0.0461       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.18        |\n",
            "|    explained_variance   | 0.574        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.71         |\n",
            "|    n_updates            | 470          |\n",
            "|    policy_gradient_loss | -0.000254    |\n",
            "|    std                  | 0.785        |\n",
            "|    value_loss           | 11           |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 424         |\n",
            "|    iterations           | 49          |\n",
            "|    time_elapsed         | 236         |\n",
            "|    total_timesteps      | 100352      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005250913 |\n",
            "|    clip_fraction        | 0.0503      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.17       |\n",
            "|    explained_variance   | 0.584       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.39        |\n",
            "|    n_updates            | 480         |\n",
            "|    policy_gradient_loss | -0.000946   |\n",
            "|    std                  | 0.776       |\n",
            "|    value_loss           | 10.4        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 260\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1237748.81\n",
            "total_reward: 223405.85\n",
            "total_cost: 2117.87\n",
            "total_trades: 388\n",
            "Sharpe: 0.688\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 424         |\n",
            "|    iterations           | 50          |\n",
            "|    time_elapsed         | 241         |\n",
            "|    total_timesteps      | 102400      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003789249 |\n",
            "|    clip_fraction        | 0.0166      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.16       |\n",
            "|    explained_variance   | 0.614       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.7         |\n",
            "|    n_updates            | 490         |\n",
            "|    policy_gradient_loss | 0.000274    |\n",
            "|    std                  | 0.77        |\n",
            "|    value_loss           | 9.39        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 423          |\n",
            "|    iterations           | 51           |\n",
            "|    time_elapsed         | 246          |\n",
            "|    total_timesteps      | 104448       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024826622 |\n",
            "|    clip_fraction        | 0.0224       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.15        |\n",
            "|    explained_variance   | 0.579        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.62         |\n",
            "|    n_updates            | 500          |\n",
            "|    policy_gradient_loss | -0.000812    |\n",
            "|    std                  | 0.763        |\n",
            "|    value_loss           | 9.78         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 270\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1247775.61\n",
            "total_reward: 233432.65\n",
            "total_cost: 1957.98\n",
            "total_trades: 390\n",
            "Sharpe: 0.701\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 424         |\n",
            "|    iterations           | 52          |\n",
            "|    time_elapsed         | 250         |\n",
            "|    total_timesteps      | 106496      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001068615 |\n",
            "|    clip_fraction        | 0.0569      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.15       |\n",
            "|    explained_variance   | 0.459       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.21        |\n",
            "|    n_updates            | 510         |\n",
            "|    policy_gradient_loss | -0.00196    |\n",
            "|    std                  | 0.763       |\n",
            "|    value_loss           | 10.9        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 423          |\n",
            "|    iterations           | 53           |\n",
            "|    time_elapsed         | 256          |\n",
            "|    total_timesteps      | 108544       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020232697 |\n",
            "|    clip_fraction        | 0.0158       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.14        |\n",
            "|    explained_variance   | 0.372        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.18         |\n",
            "|    n_updates            | 520          |\n",
            "|    policy_gradient_loss | -0.000323    |\n",
            "|    std                  | 0.755        |\n",
            "|    value_loss           | 11.6         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 280\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1261598.97\n",
            "total_reward: 247256.01\n",
            "total_cost: 1800.96\n",
            "total_trades: 389\n",
            "Sharpe: 0.727\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 424          |\n",
            "|    iterations           | 54           |\n",
            "|    time_elapsed         | 260          |\n",
            "|    total_timesteps      | 110592       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0008908545 |\n",
            "|    clip_fraction        | 0.0208       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.13        |\n",
            "|    explained_variance   | 0.437        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.79         |\n",
            "|    n_updates            | 530          |\n",
            "|    policy_gradient_loss | 0.000625     |\n",
            "|    std                  | 0.749        |\n",
            "|    value_loss           | 10.7         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 424          |\n",
            "|    iterations           | 55           |\n",
            "|    time_elapsed         | 265          |\n",
            "|    total_timesteps      | 112640       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029936875 |\n",
            "|    clip_fraction        | 0.0395       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.13        |\n",
            "|    explained_variance   | 0.34         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.51         |\n",
            "|    n_updates            | 540          |\n",
            "|    policy_gradient_loss | -0.00124     |\n",
            "|    std                  | 0.748        |\n",
            "|    value_loss           | 11.4         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 290\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1240170.20\n",
            "total_reward: 225827.24\n",
            "total_cost: 1863.32\n",
            "total_trades: 390\n",
            "Sharpe: 0.686\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 423         |\n",
            "|    iterations           | 56          |\n",
            "|    time_elapsed         | 270         |\n",
            "|    total_timesteps      | 114688      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009709733 |\n",
            "|    clip_fraction        | 0.0472      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.12       |\n",
            "|    explained_variance   | 0.335       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.61        |\n",
            "|    n_updates            | 550         |\n",
            "|    policy_gradient_loss | 0.000398    |\n",
            "|    std                  | 0.741       |\n",
            "|    value_loss           | 11.5        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 424         |\n",
            "|    iterations           | 57          |\n",
            "|    time_elapsed         | 275         |\n",
            "|    total_timesteps      | 116736      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001514448 |\n",
            "|    clip_fraction        | 0.0466      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.12       |\n",
            "|    explained_variance   | 0.286       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 8.46        |\n",
            "|    n_updates            | 560         |\n",
            "|    policy_gradient_loss | 0.00077     |\n",
            "|    std                  | 0.739       |\n",
            "|    value_loss           | 11.8        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 300\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1257352.68\n",
            "total_reward: 243009.72\n",
            "total_cost: 1504.95\n",
            "total_trades: 387\n",
            "Sharpe: 0.718\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 424          |\n",
            "|    iterations           | 58           |\n",
            "|    time_elapsed         | 279          |\n",
            "|    total_timesteps      | 118784       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040521356 |\n",
            "|    clip_fraction        | 0.0683       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.12        |\n",
            "|    explained_variance   | 0.326        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.75         |\n",
            "|    n_updates            | 570          |\n",
            "|    policy_gradient_loss | -0.00296     |\n",
            "|    std                  | 0.74         |\n",
            "|    value_loss           | 11.4         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 423          |\n",
            "|    iterations           | 59           |\n",
            "|    time_elapsed         | 285          |\n",
            "|    total_timesteps      | 120832       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0072993655 |\n",
            "|    clip_fraction        | 0.0367       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.11        |\n",
            "|    explained_variance   | 0.282        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.62         |\n",
            "|    n_updates            | 580          |\n",
            "|    policy_gradient_loss | -0.000979    |\n",
            "|    std                  | 0.733        |\n",
            "|    value_loss           | 11.6         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 310\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1255723.33\n",
            "total_reward: 241380.37\n",
            "total_cost: 1388.68\n",
            "total_trades: 390\n",
            "Sharpe: 0.715\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 424          |\n",
            "|    iterations           | 60           |\n",
            "|    time_elapsed         | 289          |\n",
            "|    total_timesteps      | 122880       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014435492 |\n",
            "|    clip_fraction        | 0.045        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.1         |\n",
            "|    explained_variance   | 0.182        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.51         |\n",
            "|    n_updates            | 590          |\n",
            "|    policy_gradient_loss | -0.0018      |\n",
            "|    std                  | 0.726        |\n",
            "|    value_loss           | 12.2         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 424         |\n",
            "|    iterations           | 61          |\n",
            "|    time_elapsed         | 294         |\n",
            "|    total_timesteps      | 124928      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004874198 |\n",
            "|    clip_fraction        | 0.0454      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.1        |\n",
            "|    explained_variance   | 0.124       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.34        |\n",
            "|    n_updates            | 600         |\n",
            "|    policy_gradient_loss | -0.000235   |\n",
            "|    std                  | 0.723       |\n",
            "|    value_loss           | 13          |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 320\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1258612.02\n",
            "total_reward: 244269.06\n",
            "total_cost: 1284.34\n",
            "total_trades: 389\n",
            "Sharpe: 0.723\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 424          |\n",
            "|    iterations           | 62           |\n",
            "|    time_elapsed         | 299          |\n",
            "|    total_timesteps      | 126976       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021926973 |\n",
            "|    clip_fraction        | 0.0323       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.09        |\n",
            "|    explained_variance   | 0.105        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.17         |\n",
            "|    n_updates            | 610          |\n",
            "|    policy_gradient_loss | 0.000637     |\n",
            "|    std                  | 0.714        |\n",
            "|    value_loss           | 13.1         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 424          |\n",
            "|    iterations           | 63           |\n",
            "|    time_elapsed         | 303          |\n",
            "|    total_timesteps      | 129024       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048530465 |\n",
            "|    clip_fraction        | 0.0275       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.08        |\n",
            "|    explained_variance   | 0.114        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.48         |\n",
            "|    n_updates            | 620          |\n",
            "|    policy_gradient_loss | 0.000395     |\n",
            "|    std                  | 0.704        |\n",
            "|    value_loss           | 12.8         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 330\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1266770.26\n",
            "total_reward: 252427.30\n",
            "total_cost: 1452.84\n",
            "total_trades: 385\n",
            "Sharpe: 0.737\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 423          |\n",
            "|    iterations           | 64           |\n",
            "|    time_elapsed         | 309          |\n",
            "|    total_timesteps      | 131072       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040664654 |\n",
            "|    clip_fraction        | 0.042        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.06        |\n",
            "|    explained_variance   | 0.0914       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.38         |\n",
            "|    n_updates            | 630          |\n",
            "|    policy_gradient_loss | -0.00159     |\n",
            "|    std                  | 0.696        |\n",
            "|    value_loss           | 12.7         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 424          |\n",
            "|    iterations           | 65           |\n",
            "|    time_elapsed         | 313          |\n",
            "|    total_timesteps      | 133120       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010738685 |\n",
            "|    clip_fraction        | 0.0357       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.05        |\n",
            "|    explained_variance   | 0.0846       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.89         |\n",
            "|    n_updates            | 640          |\n",
            "|    policy_gradient_loss | -0.000845    |\n",
            "|    std                  | 0.695        |\n",
            "|    value_loss           | 13.8         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 340\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1250634.44\n",
            "total_reward: 236291.48\n",
            "total_cost: 1273.87\n",
            "total_trades: 389\n",
            "Sharpe: 0.706\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 424         |\n",
            "|    iterations           | 66          |\n",
            "|    time_elapsed         | 318         |\n",
            "|    total_timesteps      | 135168      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001180936 |\n",
            "|    clip_fraction        | 0.0336      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.06       |\n",
            "|    explained_variance   | 0.0869      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 8.4         |\n",
            "|    n_updates            | 650         |\n",
            "|    policy_gradient_loss | 0.000192    |\n",
            "|    std                  | 0.697       |\n",
            "|    value_loss           | 13.3        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 350\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1251777.23\n",
            "total_reward: 237434.27\n",
            "total_cost: 1290.22\n",
            "total_trades: 389\n",
            "Sharpe: 0.708\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 424         |\n",
            "|    iterations           | 67          |\n",
            "|    time_elapsed         | 323         |\n",
            "|    total_timesteps      | 137216      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006063983 |\n",
            "|    clip_fraction        | 0.0303      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.06       |\n",
            "|    explained_variance   | 0.0837      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.94        |\n",
            "|    n_updates            | 660         |\n",
            "|    policy_gradient_loss | 0.000331    |\n",
            "|    std                  | 0.694       |\n",
            "|    value_loss           | 13.2        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 424          |\n",
            "|    iterations           | 68           |\n",
            "|    time_elapsed         | 328          |\n",
            "|    total_timesteps      | 139264       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0069336086 |\n",
            "|    clip_fraction        | 0.0448       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.05        |\n",
            "|    explained_variance   | 0.0929       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.3          |\n",
            "|    n_updates            | 670          |\n",
            "|    policy_gradient_loss | -0.00214     |\n",
            "|    std                  | 0.686        |\n",
            "|    value_loss           | 12.7         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 360\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1247842.59\n",
            "total_reward: 233499.63\n",
            "total_cost: 1516.52\n",
            "total_trades: 389\n",
            "Sharpe: 0.699\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 424         |\n",
            "|    iterations           | 69          |\n",
            "|    time_elapsed         | 333         |\n",
            "|    total_timesteps      | 141312      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003935407 |\n",
            "|    clip_fraction        | 0.0167      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.04       |\n",
            "|    explained_variance   | 0.0936      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.61        |\n",
            "|    n_updates            | 680         |\n",
            "|    policy_gradient_loss | 0.000849    |\n",
            "|    std                  | 0.685       |\n",
            "|    value_loss           | 12.9        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 424          |\n",
            "|    iterations           | 70           |\n",
            "|    time_elapsed         | 338          |\n",
            "|    total_timesteps      | 143360       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038716458 |\n",
            "|    clip_fraction        | 0.0224       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.04        |\n",
            "|    explained_variance   | 0.0895       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.16         |\n",
            "|    n_updates            | 690          |\n",
            "|    policy_gradient_loss | 0.000507     |\n",
            "|    std                  | 0.686        |\n",
            "|    value_loss           | 13.1         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 370\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1246801.09\n",
            "total_reward: 232458.13\n",
            "total_cost: 1373.20\n",
            "total_trades: 390\n",
            "Sharpe: 0.696\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 424          |\n",
            "|    iterations           | 71           |\n",
            "|    time_elapsed         | 342          |\n",
            "|    total_timesteps      | 145408       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018224838 |\n",
            "|    clip_fraction        | 0.0493       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.04        |\n",
            "|    explained_variance   | 0.0667       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.54         |\n",
            "|    n_updates            | 700          |\n",
            "|    policy_gradient_loss | -0.000526    |\n",
            "|    std                  | 0.689        |\n",
            "|    value_loss           | 13.5         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 423          |\n",
            "|    iterations           | 72           |\n",
            "|    time_elapsed         | 347          |\n",
            "|    total_timesteps      | 147456       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038030653 |\n",
            "|    clip_fraction        | 0.0304       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.04        |\n",
            "|    explained_variance   | 0.073        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.57         |\n",
            "|    n_updates            | 710          |\n",
            "|    policy_gradient_loss | -0.0013      |\n",
            "|    std                  | 0.681        |\n",
            "|    value_loss           | 13.1         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 380\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1235616.16\n",
            "total_reward: 221273.20\n",
            "total_cost: 1392.77\n",
            "total_trades: 388\n",
            "Sharpe: 0.674\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 424         |\n",
            "|    iterations           | 73          |\n",
            "|    time_elapsed         | 352         |\n",
            "|    total_timesteps      | 149504      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003649503 |\n",
            "|    clip_fraction        | 0.026       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.03       |\n",
            "|    explained_variance   | 0.0662      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.63        |\n",
            "|    n_updates            | 720         |\n",
            "|    policy_gradient_loss | -0.000746   |\n",
            "|    std                  | 0.672       |\n",
            "|    value_loss           | 12.9        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 424        |\n",
            "|    iterations           | 74         |\n",
            "|    time_elapsed         | 356        |\n",
            "|    total_timesteps      | 151552     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00514442 |\n",
            "|    clip_fraction        | 0.0601     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.01      |\n",
            "|    explained_variance   | 0.1        |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 5.66       |\n",
            "|    n_updates            | 730        |\n",
            "|    policy_gradient_loss | -0.00323   |\n",
            "|    std                  | 0.662      |\n",
            "|    value_loss           | 13.1       |\n",
            "----------------------------------------\n",
            "day: 391, episode: 390\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1252446.62\n",
            "total_reward: 238103.66\n",
            "total_cost: 1326.25\n",
            "total_trades: 387\n",
            "Sharpe: 0.718\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 424         |\n",
            "|    iterations           | 75          |\n",
            "|    time_elapsed         | 362         |\n",
            "|    total_timesteps      | 153600      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002621593 |\n",
            "|    clip_fraction        | 0.0337      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.01       |\n",
            "|    explained_variance   | 0.173       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.28        |\n",
            "|    n_updates            | 740         |\n",
            "|    policy_gradient_loss | 0.000363    |\n",
            "|    std                  | 0.669       |\n",
            "|    value_loss           | 12.1        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 424         |\n",
            "|    iterations           | 76          |\n",
            "|    time_elapsed         | 366         |\n",
            "|    total_timesteps      | 155648      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010890508 |\n",
            "|    clip_fraction        | 0.0346      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.01       |\n",
            "|    explained_variance   | 0.271       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.51        |\n",
            "|    n_updates            | 750         |\n",
            "|    policy_gradient_loss | 9.12e-05    |\n",
            "|    std                  | 0.662       |\n",
            "|    value_loss           | 11          |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 400\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1265185.56\n",
            "total_reward: 250842.61\n",
            "total_cost: 1383.02\n",
            "total_trades: 389\n",
            "Sharpe: 0.751\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 424         |\n",
            "|    iterations           | 77          |\n",
            "|    time_elapsed         | 371         |\n",
            "|    total_timesteps      | 157696      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006273358 |\n",
            "|    clip_fraction        | 0.0493      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1          |\n",
            "|    explained_variance   | 0.379       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.69        |\n",
            "|    n_updates            | 760         |\n",
            "|    policy_gradient_loss | -0.000372   |\n",
            "|    std                  | 0.662       |\n",
            "|    value_loss           | 10.2        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 424         |\n",
            "|    iterations           | 78          |\n",
            "|    time_elapsed         | 376         |\n",
            "|    total_timesteps      | 159744      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007172455 |\n",
            "|    clip_fraction        | 0.0361      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.01       |\n",
            "|    explained_variance   | 0.422       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.38        |\n",
            "|    n_updates            | 770         |\n",
            "|    policy_gradient_loss | 0.00139     |\n",
            "|    std                  | 0.665       |\n",
            "|    value_loss           | 10.3        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 410\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1265287.41\n",
            "total_reward: 250944.46\n",
            "total_cost: 1332.11\n",
            "total_trades: 388\n",
            "Sharpe: 0.750\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 424          |\n",
            "|    iterations           | 79           |\n",
            "|    time_elapsed         | 381          |\n",
            "|    total_timesteps      | 161792       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030002047 |\n",
            "|    clip_fraction        | 0.0287       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.01        |\n",
            "|    explained_variance   | 0.419        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.16         |\n",
            "|    n_updates            | 780          |\n",
            "|    policy_gradient_loss | -0.000443    |\n",
            "|    std                  | 0.658        |\n",
            "|    value_loss           | 11.2         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 424          |\n",
            "|    iterations           | 80           |\n",
            "|    time_elapsed         | 386          |\n",
            "|    total_timesteps      | 163840       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023012096 |\n",
            "|    clip_fraction        | 0.04         |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1           |\n",
            "|    explained_variance   | 0.451        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.27         |\n",
            "|    n_updates            | 790          |\n",
            "|    policy_gradient_loss | -0.00101     |\n",
            "|    std                  | 0.661        |\n",
            "|    value_loss           | 10.9         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 420\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1250550.08\n",
            "total_reward: 236207.12\n",
            "total_cost: 1474.15\n",
            "total_trades: 386\n",
            "Sharpe: 0.717\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 424          |\n",
            "|    iterations           | 81           |\n",
            "|    time_elapsed         | 390          |\n",
            "|    total_timesteps      | 165888       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017470104 |\n",
            "|    clip_fraction        | 0.0303       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.01        |\n",
            "|    explained_variance   | 0.418        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.93         |\n",
            "|    n_updates            | 800          |\n",
            "|    policy_gradient_loss | -0.000657    |\n",
            "|    std                  | 0.667        |\n",
            "|    value_loss           | 10.8         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 424         |\n",
            "|    iterations           | 82          |\n",
            "|    time_elapsed         | 395         |\n",
            "|    total_timesteps      | 167936      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004818974 |\n",
            "|    clip_fraction        | 0.0555      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.01       |\n",
            "|    explained_variance   | 0.392       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.94        |\n",
            "|    n_updates            | 810         |\n",
            "|    policy_gradient_loss | -0.0042     |\n",
            "|    std                  | 0.664       |\n",
            "|    value_loss           | 10.8        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 430\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1253667.51\n",
            "total_reward: 239324.55\n",
            "total_cost: 1764.54\n",
            "total_trades: 387\n",
            "Sharpe: 0.741\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 424          |\n",
            "|    iterations           | 83           |\n",
            "|    time_elapsed         | 400          |\n",
            "|    total_timesteps      | 169984       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0058292346 |\n",
            "|    clip_fraction        | 0.0574       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.01        |\n",
            "|    explained_variance   | 0.453        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.76         |\n",
            "|    n_updates            | 820          |\n",
            "|    policy_gradient_loss | 4.52e-05     |\n",
            "|    std                  | 0.659        |\n",
            "|    value_loss           | 10.9         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 424          |\n",
            "|    iterations           | 84           |\n",
            "|    time_elapsed         | 405          |\n",
            "|    total_timesteps      | 172032       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028642854 |\n",
            "|    clip_fraction        | 0.0332       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.999       |\n",
            "|    explained_variance   | 0.476        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.39         |\n",
            "|    n_updates            | 830          |\n",
            "|    policy_gradient_loss | 0.000245     |\n",
            "|    std                  | 0.653        |\n",
            "|    value_loss           | 11.3         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 440\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1232376.33\n",
            "total_reward: 218033.37\n",
            "total_cost: 1903.60\n",
            "total_trades: 389\n",
            "Sharpe: 0.686\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 424          |\n",
            "|    iterations           | 85           |\n",
            "|    time_elapsed         | 410          |\n",
            "|    total_timesteps      | 174080       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038415971 |\n",
            "|    clip_fraction        | 0.0293       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.992       |\n",
            "|    explained_variance   | 0.506        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.28         |\n",
            "|    n_updates            | 840          |\n",
            "|    policy_gradient_loss | 0.000421     |\n",
            "|    std                  | 0.653        |\n",
            "|    value_loss           | 10.5         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 424         |\n",
            "|    iterations           | 86          |\n",
            "|    time_elapsed         | 415         |\n",
            "|    total_timesteps      | 176128      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008914833 |\n",
            "|    clip_fraction        | 0.027       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.993      |\n",
            "|    explained_variance   | 0.514       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.08        |\n",
            "|    n_updates            | 850         |\n",
            "|    policy_gradient_loss | -1.15e-05   |\n",
            "|    std                  | 0.652       |\n",
            "|    value_loss           | 9.7         |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 450\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1245502.70\n",
            "total_reward: 231159.74\n",
            "total_cost: 1590.96\n",
            "total_trades: 387\n",
            "Sharpe: 0.701\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 424          |\n",
            "|    iterations           | 87           |\n",
            "|    time_elapsed         | 419          |\n",
            "|    total_timesteps      | 178176       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018984766 |\n",
            "|    clip_fraction        | 0.0527       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.988       |\n",
            "|    explained_variance   | 0.486        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.47         |\n",
            "|    n_updates            | 860          |\n",
            "|    policy_gradient_loss | 0.000954     |\n",
            "|    std                  | 0.648        |\n",
            "|    value_loss           | 10.7         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 424          |\n",
            "|    iterations           | 88           |\n",
            "|    time_elapsed         | 424          |\n",
            "|    total_timesteps      | 180224       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026509338 |\n",
            "|    clip_fraction        | 0.0266       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.979       |\n",
            "|    explained_variance   | 0.472        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.92         |\n",
            "|    n_updates            | 870          |\n",
            "|    policy_gradient_loss | 0.000271     |\n",
            "|    std                  | 0.643        |\n",
            "|    value_loss           | 11.4         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 460\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1246086.66\n",
            "total_reward: 231743.70\n",
            "total_cost: 1758.33\n",
            "total_trades: 388\n",
            "Sharpe: 0.710\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 424          |\n",
            "|    iterations           | 89           |\n",
            "|    time_elapsed         | 429          |\n",
            "|    total_timesteps      | 182272       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011715232 |\n",
            "|    clip_fraction        | 0.0189       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.977       |\n",
            "|    explained_variance   | 0.479        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.04         |\n",
            "|    n_updates            | 880          |\n",
            "|    policy_gradient_loss | -0.000193    |\n",
            "|    std                  | 0.643        |\n",
            "|    value_loss           | 10.6         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 470\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1242009.05\n",
            "total_reward: 227666.09\n",
            "total_cost: 1578.30\n",
            "total_trades: 389\n",
            "Sharpe: 0.687\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 424          |\n",
            "|    iterations           | 90           |\n",
            "|    time_elapsed         | 434          |\n",
            "|    total_timesteps      | 184320       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031312504 |\n",
            "|    clip_fraction        | 0.0139       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.981       |\n",
            "|    explained_variance   | 0.475        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.65         |\n",
            "|    n_updates            | 890          |\n",
            "|    policy_gradient_loss | -0.000271    |\n",
            "|    std                  | 0.648        |\n",
            "|    value_loss           | 10.3         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 424         |\n",
            "|    iterations           | 91          |\n",
            "|    time_elapsed         | 439         |\n",
            "|    total_timesteps      | 186368      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005523201 |\n",
            "|    clip_fraction        | 0.0587      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.983      |\n",
            "|    explained_variance   | 0.385       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.92        |\n",
            "|    n_updates            | 900         |\n",
            "|    policy_gradient_loss | -0.00313    |\n",
            "|    std                  | 0.645       |\n",
            "|    value_loss           | 11          |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 480\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1254915.11\n",
            "total_reward: 240572.15\n",
            "total_cost: 1326.29\n",
            "total_trades: 391\n",
            "Sharpe: 0.717\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 424         |\n",
            "|    iterations           | 92          |\n",
            "|    time_elapsed         | 443         |\n",
            "|    total_timesteps      | 188416      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011759432 |\n",
            "|    clip_fraction        | 0.0592      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.974      |\n",
            "|    explained_variance   | 0.474       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.58        |\n",
            "|    n_updates            | 910         |\n",
            "|    policy_gradient_loss | -0.00161    |\n",
            "|    std                  | 0.642       |\n",
            "|    value_loss           | 10.3        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 424          |\n",
            "|    iterations           | 93           |\n",
            "|    time_elapsed         | 448          |\n",
            "|    total_timesteps      | 190464       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021791907 |\n",
            "|    clip_fraction        | 0.0354       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.969       |\n",
            "|    explained_variance   | 0.415        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.75         |\n",
            "|    n_updates            | 920          |\n",
            "|    policy_gradient_loss | 0.000711     |\n",
            "|    std                  | 0.635        |\n",
            "|    value_loss           | 11.2         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 490\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1244002.27\n",
            "total_reward: 229659.31\n",
            "total_cost: 1517.55\n",
            "total_trades: 388\n",
            "Sharpe: 0.693\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 424         |\n",
            "|    iterations           | 94          |\n",
            "|    time_elapsed         | 453         |\n",
            "|    total_timesteps      | 192512      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006060957 |\n",
            "|    clip_fraction        | 0.0534      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.959      |\n",
            "|    explained_variance   | 0.393       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.71        |\n",
            "|    n_updates            | 930         |\n",
            "|    policy_gradient_loss | -0.00261    |\n",
            "|    std                  | 0.627       |\n",
            "|    value_loss           | 11.1        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 424          |\n",
            "|    iterations           | 95           |\n",
            "|    time_elapsed         | 458          |\n",
            "|    total_timesteps      | 194560       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029794427 |\n",
            "|    clip_fraction        | 0.0255       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.952       |\n",
            "|    explained_variance   | 0.349        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.56         |\n",
            "|    n_updates            | 940          |\n",
            "|    policy_gradient_loss | -0.000278    |\n",
            "|    std                  | 0.627        |\n",
            "|    value_loss           | 11.2         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 500\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1256962.31\n",
            "total_reward: 242619.35\n",
            "total_cost: 1488.11\n",
            "total_trades: 390\n",
            "Sharpe: 0.716\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 424         |\n",
            "|    iterations           | 96          |\n",
            "|    time_elapsed         | 463         |\n",
            "|    total_timesteps      | 196608      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005736041 |\n",
            "|    clip_fraction        | 0.043       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.948      |\n",
            "|    explained_variance   | 0.244       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.91        |\n",
            "|    n_updates            | 950         |\n",
            "|    policy_gradient_loss | -2.57e-05   |\n",
            "|    std                  | 0.624       |\n",
            "|    value_loss           | 12.4        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 424         |\n",
            "|    iterations           | 97          |\n",
            "|    time_elapsed         | 468         |\n",
            "|    total_timesteps      | 198656      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.000749703 |\n",
            "|    clip_fraction        | 0.0173      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.953      |\n",
            "|    explained_variance   | 0.121       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.94        |\n",
            "|    n_updates            | 960         |\n",
            "|    policy_gradient_loss | -0.000333   |\n",
            "|    std                  | 0.63        |\n",
            "|    value_loss           | 13.3        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 510\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1243923.73\n",
            "total_reward: 229580.77\n",
            "total_cost: 1287.51\n",
            "total_trades: 387\n",
            "Sharpe: 0.691\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 424          |\n",
            "|    iterations           | 98           |\n",
            "|    time_elapsed         | 472          |\n",
            "|    total_timesteps      | 200704       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027126875 |\n",
            "|    clip_fraction        | 0.026        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.961       |\n",
            "|    explained_variance   | 0.163        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.36         |\n",
            "|    n_updates            | 970          |\n",
            "|    policy_gradient_loss | -0.00212     |\n",
            "|    std                  | 0.634        |\n",
            "|    value_loss           | 12.7         |\n",
            "------------------------------------------\n",
            "\n",
            "Training RefPaper Agent…\n",
            "Using cuda device\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/policies.py:486: UserWarning: As shared layers in the mlp_extractor are removed since SB3 v1.8.0, you should now pass directly a dictionary and not a list (net_arch=dict(pi=..., vf=...) instead of net_arch=[dict(pi=..., vf=...)])\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 525  |\n",
            "|    iterations      | 1    |\n",
            "|    time_elapsed    | 3    |\n",
            "|    total_timesteps | 2048 |\n",
            "-----------------------------\n",
            "day: 391, episode: 10\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1047200.94\n",
            "total_reward: 32857.98\n",
            "total_cost: 3850.27\n",
            "total_trades: 386\n",
            "Sharpe: 0.517\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 487          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 8            |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0004316172 |\n",
            "|    clip_fraction        | 0.0108       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | -0.0194      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.244        |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.000242    |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 0.749        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 476          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 12           |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034424572 |\n",
            "|    clip_fraction        | 0.0195       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.43        |\n",
            "|    explained_variance   | -0.00181     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.339        |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.00097     |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 0.527        |\n",
            "------------------------------------------\n",
            "day: 391, episode: 20\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1014782.29\n",
            "total_reward: 439.33\n",
            "total_cost: 2991.83\n",
            "total_trades: 333\n",
            "Sharpe: 0.026\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 452          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 18           |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054024467 |\n",
            "|    clip_fraction        | 0.0313       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.43        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.17         |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.00195     |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 0.231        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 452          |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 22           |\n",
            "|    total_timesteps      | 10240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036071527 |\n",
            "|    clip_fraction        | 0.016        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0143       |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.000929    |\n",
            "|    std                  | 0.999        |\n",
            "|    value_loss           | 0.052        |\n",
            "------------------------------------------\n",
            "day: 391, episode: 30\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1008502.96\n",
            "total_reward: -5840.00\n",
            "total_cost: 3548.11\n",
            "total_trades: 383\n",
            "Sharpe: -0.102\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 446         |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 27          |\n",
            "|    total_timesteps      | 12288       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007491653 |\n",
            "|    clip_fraction        | 0.0371      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.41       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0384      |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.00334    |\n",
            "|    std                  | 0.979       |\n",
            "|    value_loss           | 0.0757      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 442          |\n",
            "|    iterations           | 7            |\n",
            "|    time_elapsed         | 32           |\n",
            "|    total_timesteps      | 14336        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011347557 |\n",
            "|    clip_fraction        | 0.000586     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.39        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.41         |\n",
            "|    n_updates            | 60           |\n",
            "|    policy_gradient_loss | -0.000151    |\n",
            "|    std                  | 0.963        |\n",
            "|    value_loss           | 0.697        |\n",
            "------------------------------------------\n",
            "day: 391, episode: 40\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1145892.53\n",
            "total_reward: 131549.57\n",
            "total_cost: 3438.05\n",
            "total_trades: 388\n",
            "Sharpe: 0.985\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 443          |\n",
            "|    iterations           | 8            |\n",
            "|    time_elapsed         | 36           |\n",
            "|    total_timesteps      | 16384        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0071198856 |\n",
            "|    clip_fraction        | 0.075        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.37        |\n",
            "|    explained_variance   | 0.000688     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.293        |\n",
            "|    n_updates            | 70           |\n",
            "|    policy_gradient_loss | -0.00488     |\n",
            "|    std                  | 0.95         |\n",
            "|    value_loss           | 0.764        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 436         |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 42          |\n",
            "|    total_timesteps      | 18432       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002685722 |\n",
            "|    clip_fraction        | 0.00195     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.36       |\n",
            "|    explained_variance   | 0.0119      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.991       |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.000334   |\n",
            "|    std                  | 0.941       |\n",
            "|    value_loss           | 2.16        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 50\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1302112.17\n",
            "total_reward: 287769.21\n",
            "total_cost: 3626.40\n",
            "total_trades: 388\n",
            "Sharpe: 1.210\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 437        |\n",
            "|    iterations           | 10         |\n",
            "|    time_elapsed         | 46         |\n",
            "|    total_timesteps      | 20480      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00382774 |\n",
            "|    clip_fraction        | 0.0269     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.35      |\n",
            "|    explained_variance   | 0          |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.74       |\n",
            "|    n_updates            | 90         |\n",
            "|    policy_gradient_loss | -0.00178   |\n",
            "|    std                  | 0.932      |\n",
            "|    value_loss           | 1.25       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 438         |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 51          |\n",
            "|    total_timesteps      | 22528       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003236146 |\n",
            "|    clip_fraction        | 0.0184      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.35       |\n",
            "|    explained_variance   | -0.0268     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.841       |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.00191    |\n",
            "|    std                  | 0.936       |\n",
            "|    value_loss           | 2.81        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 60\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1293798.26\n",
            "total_reward: 279455.30\n",
            "total_cost: 3474.88\n",
            "total_trades: 389\n",
            "Sharpe: 1.147\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 434          |\n",
            "|    iterations           | 12           |\n",
            "|    time_elapsed         | 56           |\n",
            "|    total_timesteps      | 24576        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012085277 |\n",
            "|    clip_fraction        | 0.0165       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.35        |\n",
            "|    explained_variance   | 0.0999       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.74         |\n",
            "|    n_updates            | 110          |\n",
            "|    policy_gradient_loss | -0.00133     |\n",
            "|    std                  | 0.927        |\n",
            "|    value_loss           | 5.1          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 435          |\n",
            "|    iterations           | 13           |\n",
            "|    time_elapsed         | 61           |\n",
            "|    total_timesteps      | 26624        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012474463 |\n",
            "|    clip_fraction        | 0.0131       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.34        |\n",
            "|    explained_variance   | 0.311        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.05         |\n",
            "|    n_updates            | 120          |\n",
            "|    policy_gradient_loss | -0.000158    |\n",
            "|    std                  | 0.929        |\n",
            "|    value_loss           | 7.34         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 70\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1288453.14\n",
            "total_reward: 274110.18\n",
            "total_cost: 3207.33\n",
            "total_trades: 389\n",
            "Sharpe: 0.961\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 435          |\n",
            "|    iterations           | 14           |\n",
            "|    time_elapsed         | 65           |\n",
            "|    total_timesteps      | 28672        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032647264 |\n",
            "|    clip_fraction        | 0.0218       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.34        |\n",
            "|    explained_variance   | 0.34         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.68         |\n",
            "|    n_updates            | 130          |\n",
            "|    policy_gradient_loss | -0.00176     |\n",
            "|    std                  | 0.926        |\n",
            "|    value_loss           | 7.57         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 433          |\n",
            "|    iterations           | 15           |\n",
            "|    time_elapsed         | 70           |\n",
            "|    total_timesteps      | 30720        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0043919953 |\n",
            "|    clip_fraction        | 0.033        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.34        |\n",
            "|    explained_variance   | 0.389        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.59         |\n",
            "|    n_updates            | 140          |\n",
            "|    policy_gradient_loss | -0.00181     |\n",
            "|    std                  | 0.919        |\n",
            "|    value_loss           | 6.82         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 80\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1280080.74\n",
            "total_reward: 265737.78\n",
            "total_cost: 3429.03\n",
            "total_trades: 390\n",
            "Sharpe: 1.296\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 434         |\n",
            "|    iterations           | 16          |\n",
            "|    time_elapsed         | 75          |\n",
            "|    total_timesteps      | 32768       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004291202 |\n",
            "|    clip_fraction        | 0.0221      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.33       |\n",
            "|    explained_variance   | 0.516       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.05        |\n",
            "|    n_updates            | 150         |\n",
            "|    policy_gradient_loss | 7.5e-06     |\n",
            "|    std                  | 0.906       |\n",
            "|    value_loss           | 8.01        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 431          |\n",
            "|    iterations           | 17           |\n",
            "|    time_elapsed         | 80           |\n",
            "|    total_timesteps      | 34816        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025252816 |\n",
            "|    clip_fraction        | 0.018        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.32        |\n",
            "|    explained_variance   | 0.553        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.72         |\n",
            "|    n_updates            | 160          |\n",
            "|    policy_gradient_loss | -0.00126     |\n",
            "|    std                  | 0.901        |\n",
            "|    value_loss           | 8.16         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 90\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1293879.80\n",
            "total_reward: 279536.84\n",
            "total_cost: 2819.48\n",
            "total_trades: 385\n",
            "Sharpe: 0.994\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 432         |\n",
            "|    iterations           | 18          |\n",
            "|    time_elapsed         | 85          |\n",
            "|    total_timesteps      | 36864       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004612758 |\n",
            "|    clip_fraction        | 0.0455      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.31       |\n",
            "|    explained_variance   | 0.633       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.27        |\n",
            "|    n_updates            | 170         |\n",
            "|    policy_gradient_loss | -0.00328    |\n",
            "|    std                  | 0.889       |\n",
            "|    value_loss           | 8.14        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 431         |\n",
            "|    iterations           | 19          |\n",
            "|    time_elapsed         | 90          |\n",
            "|    total_timesteps      | 38912       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004564065 |\n",
            "|    clip_fraction        | 0.0371      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.3        |\n",
            "|    explained_variance   | 0.623       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.11        |\n",
            "|    n_updates            | 180         |\n",
            "|    policy_gradient_loss | -0.00224    |\n",
            "|    std                  | 0.886       |\n",
            "|    value_loss           | 9.27        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 100\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1292196.12\n",
            "total_reward: 277853.16\n",
            "total_cost: 3201.90\n",
            "total_trades: 386\n",
            "Sharpe: 1.013\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 428          |\n",
            "|    iterations           | 20           |\n",
            "|    time_elapsed         | 95           |\n",
            "|    total_timesteps      | 40960        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0055242274 |\n",
            "|    clip_fraction        | 0.0271       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.673        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.49         |\n",
            "|    n_updates            | 190          |\n",
            "|    policy_gradient_loss | -0.00194     |\n",
            "|    std                  | 0.879        |\n",
            "|    value_loss           | 8.7          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 429         |\n",
            "|    iterations           | 21          |\n",
            "|    time_elapsed         | 100         |\n",
            "|    total_timesteps      | 43008       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006683482 |\n",
            "|    clip_fraction        | 0.053       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.29       |\n",
            "|    explained_variance   | 0.689       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.14        |\n",
            "|    n_updates            | 200         |\n",
            "|    policy_gradient_loss | -0.00403    |\n",
            "|    std                  | 0.875       |\n",
            "|    value_loss           | 9.14        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 110\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1260045.54\n",
            "total_reward: 245702.58\n",
            "total_cost: 2604.54\n",
            "total_trades: 388\n",
            "Sharpe: 0.772\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 429          |\n",
            "|    iterations           | 22           |\n",
            "|    time_elapsed         | 104          |\n",
            "|    total_timesteps      | 45056        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015303787 |\n",
            "|    clip_fraction        | 0.011        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.7          |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.79         |\n",
            "|    n_updates            | 210          |\n",
            "|    policy_gradient_loss | -0.000147    |\n",
            "|    std                  | 0.874        |\n",
            "|    value_loss           | 9.44         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 120\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1229882.78\n",
            "total_reward: 215539.82\n",
            "total_cost: 2445.21\n",
            "total_trades: 391\n",
            "Sharpe: 0.673\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 428         |\n",
            "|    iterations           | 23          |\n",
            "|    time_elapsed         | 110         |\n",
            "|    total_timesteps      | 47104       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003272114 |\n",
            "|    clip_fraction        | 0.00396     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.29       |\n",
            "|    explained_variance   | 0.698       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.36        |\n",
            "|    n_updates            | 220         |\n",
            "|    policy_gradient_loss | -0.000505   |\n",
            "|    std                  | 0.876       |\n",
            "|    value_loss           | 9.8         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 428         |\n",
            "|    iterations           | 24          |\n",
            "|    time_elapsed         | 114         |\n",
            "|    total_timesteps      | 49152       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004639621 |\n",
            "|    clip_fraction        | 0.0294      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.29       |\n",
            "|    explained_variance   | 0.621       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.31        |\n",
            "|    n_updates            | 230         |\n",
            "|    policy_gradient_loss | -0.00198    |\n",
            "|    std                  | 0.879       |\n",
            "|    value_loss           | 10.7        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 130\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1244951.29\n",
            "total_reward: 230608.34\n",
            "total_cost: 2627.80\n",
            "total_trades: 389\n",
            "Sharpe: 0.732\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 427          |\n",
            "|    iterations           | 25           |\n",
            "|    time_elapsed         | 119          |\n",
            "|    total_timesteps      | 51200        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010851659 |\n",
            "|    clip_fraction        | 0.0188       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.614        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.91         |\n",
            "|    n_updates            | 240          |\n",
            "|    policy_gradient_loss | 0.000125     |\n",
            "|    std                  | 0.875        |\n",
            "|    value_loss           | 10.5         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 428          |\n",
            "|    iterations           | 26           |\n",
            "|    time_elapsed         | 124          |\n",
            "|    total_timesteps      | 53248        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0049646664 |\n",
            "|    clip_fraction        | 0.0128       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.555        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.8          |\n",
            "|    n_updates            | 250          |\n",
            "|    policy_gradient_loss | -0.00101     |\n",
            "|    std                  | 0.877        |\n",
            "|    value_loss           | 10.5         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 140\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1272558.62\n",
            "total_reward: 258215.66\n",
            "total_cost: 2652.89\n",
            "total_trades: 389\n",
            "Sharpe: 0.809\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 428         |\n",
            "|    iterations           | 27          |\n",
            "|    time_elapsed         | 128         |\n",
            "|    total_timesteps      | 55296       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004755087 |\n",
            "|    clip_fraction        | 0.0326      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.28       |\n",
            "|    explained_variance   | 0.626       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.49        |\n",
            "|    n_updates            | 260         |\n",
            "|    policy_gradient_loss | -0.000538   |\n",
            "|    std                  | 0.87        |\n",
            "|    value_loss           | 9.23        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 427         |\n",
            "|    iterations           | 28          |\n",
            "|    time_elapsed         | 134         |\n",
            "|    total_timesteps      | 57344       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003985365 |\n",
            "|    clip_fraction        | 0.0176      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.28       |\n",
            "|    explained_variance   | 0.56        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.39        |\n",
            "|    n_updates            | 270         |\n",
            "|    policy_gradient_loss | -0.000439   |\n",
            "|    std                  | 0.861       |\n",
            "|    value_loss           | 10          |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 150\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1245604.57\n",
            "total_reward: 231261.61\n",
            "total_cost: 2464.93\n",
            "total_trades: 388\n",
            "Sharpe: 0.737\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 427          |\n",
            "|    iterations           | 29           |\n",
            "|    time_elapsed         | 138          |\n",
            "|    total_timesteps      | 59392        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0057225293 |\n",
            "|    clip_fraction        | 0.0437       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.26        |\n",
            "|    explained_variance   | 0.548        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.49         |\n",
            "|    n_updates            | 280          |\n",
            "|    policy_gradient_loss | -0.00173     |\n",
            "|    std                  | 0.846        |\n",
            "|    value_loss           | 10.1         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 428          |\n",
            "|    iterations           | 30           |\n",
            "|    time_elapsed         | 143          |\n",
            "|    total_timesteps      | 61440        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025116717 |\n",
            "|    clip_fraction        | 0.0252       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.25        |\n",
            "|    explained_variance   | 0.538        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.8          |\n",
            "|    n_updates            | 290          |\n",
            "|    policy_gradient_loss | -0.000435    |\n",
            "|    std                  | 0.843        |\n",
            "|    value_loss           | 10.8         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 160\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1269478.53\n",
            "total_reward: 255135.57\n",
            "total_cost: 2764.08\n",
            "total_trades: 385\n",
            "Sharpe: 0.824\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 427          |\n",
            "|    iterations           | 31           |\n",
            "|    time_elapsed         | 148          |\n",
            "|    total_timesteps      | 63488        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019839664 |\n",
            "|    clip_fraction        | 0.0313       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.25        |\n",
            "|    explained_variance   | 0.579        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.47         |\n",
            "|    n_updates            | 300          |\n",
            "|    policy_gradient_loss | 0.000301     |\n",
            "|    std                  | 0.84         |\n",
            "|    value_loss           | 10.1         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 427          |\n",
            "|    iterations           | 32           |\n",
            "|    time_elapsed         | 153          |\n",
            "|    total_timesteps      | 65536        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034011584 |\n",
            "|    clip_fraction        | 0.0386       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.24        |\n",
            "|    explained_variance   | 0.591        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.55         |\n",
            "|    n_updates            | 310          |\n",
            "|    policy_gradient_loss | -0.000785    |\n",
            "|    std                  | 0.834        |\n",
            "|    value_loss           | 9.69         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 170\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1249056.62\n",
            "total_reward: 234713.66\n",
            "total_cost: 2408.10\n",
            "total_trades: 386\n",
            "Sharpe: 0.747\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 427          |\n",
            "|    iterations           | 33           |\n",
            "|    time_elapsed         | 158          |\n",
            "|    total_timesteps      | 67584        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030730194 |\n",
            "|    clip_fraction        | 0.0419       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.24        |\n",
            "|    explained_variance   | 0.637        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.13         |\n",
            "|    n_updates            | 320          |\n",
            "|    policy_gradient_loss | 0.000826     |\n",
            "|    std                  | 0.834        |\n",
            "|    value_loss           | 8.62         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 427          |\n",
            "|    iterations           | 34           |\n",
            "|    time_elapsed         | 162          |\n",
            "|    total_timesteps      | 69632        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0064250254 |\n",
            "|    clip_fraction        | 0.033        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.24        |\n",
            "|    explained_variance   | 0.641        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.17         |\n",
            "|    n_updates            | 330          |\n",
            "|    policy_gradient_loss | -9.6e-05     |\n",
            "|    std                  | 0.83         |\n",
            "|    value_loss           | 9.66         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 180\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1261716.70\n",
            "total_reward: 247373.74\n",
            "total_cost: 2533.37\n",
            "total_trades: 388\n",
            "Sharpe: 0.799\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 427          |\n",
            "|    iterations           | 35           |\n",
            "|    time_elapsed         | 167          |\n",
            "|    total_timesteps      | 71680        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038368022 |\n",
            "|    clip_fraction        | 0.0271       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.23        |\n",
            "|    explained_variance   | 0.623        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.83         |\n",
            "|    n_updates            | 340          |\n",
            "|    policy_gradient_loss | -0.0016      |\n",
            "|    std                  | 0.829        |\n",
            "|    value_loss           | 9.95         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 426          |\n",
            "|    iterations           | 36           |\n",
            "|    time_elapsed         | 172          |\n",
            "|    total_timesteps      | 73728        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020990535 |\n",
            "|    clip_fraction        | 0.0222       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.23        |\n",
            "|    explained_variance   | 0.6          |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.56         |\n",
            "|    n_updates            | 350          |\n",
            "|    policy_gradient_loss | 0.000902     |\n",
            "|    std                  | 0.821        |\n",
            "|    value_loss           | 10.4         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 190\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1263388.63\n",
            "total_reward: 249045.67\n",
            "total_cost: 2579.59\n",
            "total_trades: 387\n",
            "Sharpe: 0.784\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 427         |\n",
            "|    iterations           | 37          |\n",
            "|    time_elapsed         | 177         |\n",
            "|    total_timesteps      | 75776       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003910023 |\n",
            "|    clip_fraction        | 0.034       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.22       |\n",
            "|    explained_variance   | 0.586       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.53        |\n",
            "|    n_updates            | 360         |\n",
            "|    policy_gradient_loss | 0.000248    |\n",
            "|    std                  | 0.815       |\n",
            "|    value_loss           | 10.3        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 427         |\n",
            "|    iterations           | 38          |\n",
            "|    time_elapsed         | 181         |\n",
            "|    total_timesteps      | 77824       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004233734 |\n",
            "|    clip_fraction        | 0.0347      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.22       |\n",
            "|    explained_variance   | 0.608       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.38        |\n",
            "|    n_updates            | 370         |\n",
            "|    policy_gradient_loss | -0.00135    |\n",
            "|    std                  | 0.821       |\n",
            "|    value_loss           | 10.6        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 200\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1254810.91\n",
            "total_reward: 240467.95\n",
            "total_cost: 2343.69\n",
            "total_trades: 389\n",
            "Sharpe: 0.812\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 426          |\n",
            "|    iterations           | 39           |\n",
            "|    time_elapsed         | 187          |\n",
            "|    total_timesteps      | 79872        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033648363 |\n",
            "|    clip_fraction        | 0.0197       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.23        |\n",
            "|    explained_variance   | 0.582        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.27         |\n",
            "|    n_updates            | 380          |\n",
            "|    policy_gradient_loss | 0.000922     |\n",
            "|    std                  | 0.827        |\n",
            "|    value_loss           | 10.9         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 427          |\n",
            "|    iterations           | 40           |\n",
            "|    time_elapsed         | 191          |\n",
            "|    total_timesteps      | 81920        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045851385 |\n",
            "|    clip_fraction        | 0.0272       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.22        |\n",
            "|    explained_variance   | 0.587        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.18         |\n",
            "|    n_updates            | 390          |\n",
            "|    policy_gradient_loss | -0.000135    |\n",
            "|    std                  | 0.813        |\n",
            "|    value_loss           | 9.98         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 210\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1249393.15\n",
            "total_reward: 235050.19\n",
            "total_cost: 2383.21\n",
            "total_trades: 389\n",
            "Sharpe: 0.728\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 426         |\n",
            "|    iterations           | 41          |\n",
            "|    time_elapsed         | 196         |\n",
            "|    total_timesteps      | 83968       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005900711 |\n",
            "|    clip_fraction        | 0.033       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.21       |\n",
            "|    explained_variance   | 0.542       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.52        |\n",
            "|    n_updates            | 400         |\n",
            "|    policy_gradient_loss | -0.000166   |\n",
            "|    std                  | 0.811       |\n",
            "|    value_loss           | 9.74        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 426          |\n",
            "|    iterations           | 42           |\n",
            "|    time_elapsed         | 201          |\n",
            "|    total_timesteps      | 86016        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0052124984 |\n",
            "|    clip_fraction        | 0.0351       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.2         |\n",
            "|    explained_variance   | 0.564        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.45         |\n",
            "|    n_updates            | 410          |\n",
            "|    policy_gradient_loss | -0.000214    |\n",
            "|    std                  | 0.799        |\n",
            "|    value_loss           | 9.79         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 220\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1249533.80\n",
            "total_reward: 235190.84\n",
            "total_cost: 2349.07\n",
            "total_trades: 388\n",
            "Sharpe: 0.788\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 427          |\n",
            "|    iterations           | 43           |\n",
            "|    time_elapsed         | 205          |\n",
            "|    total_timesteps      | 88064        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0071589416 |\n",
            "|    clip_fraction        | 0.056        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.2         |\n",
            "|    explained_variance   | 0.579        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.67         |\n",
            "|    n_updates            | 420          |\n",
            "|    policy_gradient_loss | -0.000429    |\n",
            "|    std                  | 0.799        |\n",
            "|    value_loss           | 10.4         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 426          |\n",
            "|    iterations           | 44           |\n",
            "|    time_elapsed         | 211          |\n",
            "|    total_timesteps      | 90112        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016658485 |\n",
            "|    clip_fraction        | 0.0168       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.19        |\n",
            "|    explained_variance   | 0.656        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.28         |\n",
            "|    n_updates            | 430          |\n",
            "|    policy_gradient_loss | 2.66e-05     |\n",
            "|    std                  | 0.799        |\n",
            "|    value_loss           | 8.79         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 230\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1278595.18\n",
            "total_reward: 264252.23\n",
            "total_cost: 2506.91\n",
            "total_trades: 388\n",
            "Sharpe: 0.863\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 427          |\n",
            "|    iterations           | 45           |\n",
            "|    time_elapsed         | 215          |\n",
            "|    total_timesteps      | 92160        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0055195056 |\n",
            "|    clip_fraction        | 0.0226       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.19        |\n",
            "|    explained_variance   | 0.657        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.03         |\n",
            "|    n_updates            | 440          |\n",
            "|    policy_gradient_loss | -0.000627    |\n",
            "|    std                  | 0.789        |\n",
            "|    value_loss           | 9.36         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 240\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1260706.95\n",
            "total_reward: 246363.99\n",
            "total_cost: 2075.14\n",
            "total_trades: 390\n",
            "Sharpe: 0.754\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 427         |\n",
            "|    iterations           | 46          |\n",
            "|    time_elapsed         | 220         |\n",
            "|    total_timesteps      | 94208       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008028019 |\n",
            "|    clip_fraction        | 0.0522      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.18       |\n",
            "|    explained_variance   | 0.629       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.88        |\n",
            "|    n_updates            | 450         |\n",
            "|    policy_gradient_loss | -0.000109   |\n",
            "|    std                  | 0.791       |\n",
            "|    value_loss           | 9.51        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 426          |\n",
            "|    iterations           | 47           |\n",
            "|    time_elapsed         | 225          |\n",
            "|    total_timesteps      | 96256        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0073205833 |\n",
            "|    clip_fraction        | 0.0557       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.18        |\n",
            "|    explained_variance   | 0.622        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.3          |\n",
            "|    n_updates            | 460          |\n",
            "|    policy_gradient_loss | -0.00211     |\n",
            "|    std                  | 0.79         |\n",
            "|    value_loss           | 10.4         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 250\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1257383.43\n",
            "total_reward: 243040.47\n",
            "total_cost: 2162.30\n",
            "total_trades: 387\n",
            "Sharpe: 0.757\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 427          |\n",
            "|    iterations           | 48           |\n",
            "|    time_elapsed         | 230          |\n",
            "|    total_timesteps      | 98304        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0060119955 |\n",
            "|    clip_fraction        | 0.0461       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.18        |\n",
            "|    explained_variance   | 0.574        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.71         |\n",
            "|    n_updates            | 470          |\n",
            "|    policy_gradient_loss | -0.000254    |\n",
            "|    std                  | 0.785        |\n",
            "|    value_loss           | 11           |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 427         |\n",
            "|    iterations           | 49          |\n",
            "|    time_elapsed         | 234         |\n",
            "|    total_timesteps      | 100352      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005250913 |\n",
            "|    clip_fraction        | 0.0503      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.17       |\n",
            "|    explained_variance   | 0.584       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.39        |\n",
            "|    n_updates            | 480         |\n",
            "|    policy_gradient_loss | -0.000946   |\n",
            "|    std                  | 0.776       |\n",
            "|    value_loss           | 10.4        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 260\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1237748.81\n",
            "total_reward: 223405.85\n",
            "total_cost: 2117.87\n",
            "total_trades: 388\n",
            "Sharpe: 0.688\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 427         |\n",
            "|    iterations           | 50          |\n",
            "|    time_elapsed         | 239         |\n",
            "|    total_timesteps      | 102400      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003789249 |\n",
            "|    clip_fraction        | 0.0166      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.16       |\n",
            "|    explained_variance   | 0.614       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.7         |\n",
            "|    n_updates            | 490         |\n",
            "|    policy_gradient_loss | 0.000274    |\n",
            "|    std                  | 0.77        |\n",
            "|    value_loss           | 9.39        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 427          |\n",
            "|    iterations           | 51           |\n",
            "|    time_elapsed         | 244          |\n",
            "|    total_timesteps      | 104448       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024826622 |\n",
            "|    clip_fraction        | 0.0224       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.15        |\n",
            "|    explained_variance   | 0.579        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.62         |\n",
            "|    n_updates            | 500          |\n",
            "|    policy_gradient_loss | -0.000812    |\n",
            "|    std                  | 0.763        |\n",
            "|    value_loss           | 9.78         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 270\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1247775.61\n",
            "total_reward: 233432.65\n",
            "total_cost: 1957.98\n",
            "total_trades: 390\n",
            "Sharpe: 0.701\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 426         |\n",
            "|    iterations           | 52          |\n",
            "|    time_elapsed         | 249         |\n",
            "|    total_timesteps      | 106496      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001068615 |\n",
            "|    clip_fraction        | 0.0569      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.15       |\n",
            "|    explained_variance   | 0.459       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.21        |\n",
            "|    n_updates            | 510         |\n",
            "|    policy_gradient_loss | -0.00196    |\n",
            "|    std                  | 0.763       |\n",
            "|    value_loss           | 10.9        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 427          |\n",
            "|    iterations           | 53           |\n",
            "|    time_elapsed         | 254          |\n",
            "|    total_timesteps      | 108544       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020232697 |\n",
            "|    clip_fraction        | 0.0158       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.14        |\n",
            "|    explained_variance   | 0.372        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.18         |\n",
            "|    n_updates            | 520          |\n",
            "|    policy_gradient_loss | -0.000323    |\n",
            "|    std                  | 0.755        |\n",
            "|    value_loss           | 11.6         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 280\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1261598.97\n",
            "total_reward: 247256.01\n",
            "total_cost: 1800.96\n",
            "total_trades: 389\n",
            "Sharpe: 0.727\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 427          |\n",
            "|    iterations           | 54           |\n",
            "|    time_elapsed         | 258          |\n",
            "|    total_timesteps      | 110592       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0008908545 |\n",
            "|    clip_fraction        | 0.0208       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.13        |\n",
            "|    explained_variance   | 0.437        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.79         |\n",
            "|    n_updates            | 530          |\n",
            "|    policy_gradient_loss | 0.000625     |\n",
            "|    std                  | 0.749        |\n",
            "|    value_loss           | 10.7         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 426          |\n",
            "|    iterations           | 55           |\n",
            "|    time_elapsed         | 263          |\n",
            "|    total_timesteps      | 112640       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029936875 |\n",
            "|    clip_fraction        | 0.0395       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.13        |\n",
            "|    explained_variance   | 0.34         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.51         |\n",
            "|    n_updates            | 540          |\n",
            "|    policy_gradient_loss | -0.00124     |\n",
            "|    std                  | 0.748        |\n",
            "|    value_loss           | 11.4         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 290\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1240170.20\n",
            "total_reward: 225827.24\n",
            "total_cost: 1863.32\n",
            "total_trades: 390\n",
            "Sharpe: 0.686\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 427         |\n",
            "|    iterations           | 56          |\n",
            "|    time_elapsed         | 268         |\n",
            "|    total_timesteps      | 114688      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009709733 |\n",
            "|    clip_fraction        | 0.0472      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.12       |\n",
            "|    explained_variance   | 0.335       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.61        |\n",
            "|    n_updates            | 550         |\n",
            "|    policy_gradient_loss | 0.000398    |\n",
            "|    std                  | 0.741       |\n",
            "|    value_loss           | 11.5        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 427         |\n",
            "|    iterations           | 57          |\n",
            "|    time_elapsed         | 273         |\n",
            "|    total_timesteps      | 116736      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001514448 |\n",
            "|    clip_fraction        | 0.0466      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.12       |\n",
            "|    explained_variance   | 0.286       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 8.46        |\n",
            "|    n_updates            | 560         |\n",
            "|    policy_gradient_loss | 0.00077     |\n",
            "|    std                  | 0.739       |\n",
            "|    value_loss           | 11.8        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 300\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1257352.68\n",
            "total_reward: 243009.72\n",
            "total_cost: 1504.95\n",
            "total_trades: 387\n",
            "Sharpe: 0.718\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 426          |\n",
            "|    iterations           | 58           |\n",
            "|    time_elapsed         | 278          |\n",
            "|    total_timesteps      | 118784       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040521356 |\n",
            "|    clip_fraction        | 0.0683       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.12        |\n",
            "|    explained_variance   | 0.326        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.75         |\n",
            "|    n_updates            | 570          |\n",
            "|    policy_gradient_loss | -0.00296     |\n",
            "|    std                  | 0.74         |\n",
            "|    value_loss           | 11.4         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 427          |\n",
            "|    iterations           | 59           |\n",
            "|    time_elapsed         | 282          |\n",
            "|    total_timesteps      | 120832       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0072993655 |\n",
            "|    clip_fraction        | 0.0367       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.11        |\n",
            "|    explained_variance   | 0.282        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.62         |\n",
            "|    n_updates            | 580          |\n",
            "|    policy_gradient_loss | -0.000979    |\n",
            "|    std                  | 0.733        |\n",
            "|    value_loss           | 11.6         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 310\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1255723.33\n",
            "total_reward: 241380.37\n",
            "total_cost: 1388.68\n",
            "total_trades: 390\n",
            "Sharpe: 0.715\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 426          |\n",
            "|    iterations           | 60           |\n",
            "|    time_elapsed         | 287          |\n",
            "|    total_timesteps      | 122880       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014435492 |\n",
            "|    clip_fraction        | 0.045        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.1         |\n",
            "|    explained_variance   | 0.182        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.51         |\n",
            "|    n_updates            | 590          |\n",
            "|    policy_gradient_loss | -0.0018      |\n",
            "|    std                  | 0.726        |\n",
            "|    value_loss           | 12.2         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 426         |\n",
            "|    iterations           | 61          |\n",
            "|    time_elapsed         | 292         |\n",
            "|    total_timesteps      | 124928      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004874198 |\n",
            "|    clip_fraction        | 0.0454      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.1        |\n",
            "|    explained_variance   | 0.124       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.34        |\n",
            "|    n_updates            | 600         |\n",
            "|    policy_gradient_loss | -0.000235   |\n",
            "|    std                  | 0.723       |\n",
            "|    value_loss           | 13          |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 320\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1258612.02\n",
            "total_reward: 244269.06\n",
            "total_cost: 1284.34\n",
            "total_trades: 389\n",
            "Sharpe: 0.723\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 427          |\n",
            "|    iterations           | 62           |\n",
            "|    time_elapsed         | 297          |\n",
            "|    total_timesteps      | 126976       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021926973 |\n",
            "|    clip_fraction        | 0.0323       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.09        |\n",
            "|    explained_variance   | 0.105        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.17         |\n",
            "|    n_updates            | 610          |\n",
            "|    policy_gradient_loss | 0.000637     |\n",
            "|    std                  | 0.714        |\n",
            "|    value_loss           | 13.1         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 426          |\n",
            "|    iterations           | 63           |\n",
            "|    time_elapsed         | 302          |\n",
            "|    total_timesteps      | 129024       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048530465 |\n",
            "|    clip_fraction        | 0.0275       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.08        |\n",
            "|    explained_variance   | 0.114        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.48         |\n",
            "|    n_updates            | 620          |\n",
            "|    policy_gradient_loss | 0.000395     |\n",
            "|    std                  | 0.704        |\n",
            "|    value_loss           | 12.8         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 330\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1266770.26\n",
            "total_reward: 252427.30\n",
            "total_cost: 1452.84\n",
            "total_trades: 385\n",
            "Sharpe: 0.737\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 427          |\n",
            "|    iterations           | 64           |\n",
            "|    time_elapsed         | 306          |\n",
            "|    total_timesteps      | 131072       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040664654 |\n",
            "|    clip_fraction        | 0.042        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.06        |\n",
            "|    explained_variance   | 0.0914       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.38         |\n",
            "|    n_updates            | 630          |\n",
            "|    policy_gradient_loss | -0.00159     |\n",
            "|    std                  | 0.696        |\n",
            "|    value_loss           | 12.7         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 427          |\n",
            "|    iterations           | 65           |\n",
            "|    time_elapsed         | 311          |\n",
            "|    total_timesteps      | 133120       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010738685 |\n",
            "|    clip_fraction        | 0.0357       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.05        |\n",
            "|    explained_variance   | 0.0846       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.89         |\n",
            "|    n_updates            | 640          |\n",
            "|    policy_gradient_loss | -0.000845    |\n",
            "|    std                  | 0.695        |\n",
            "|    value_loss           | 13.8         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 340\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1250634.44\n",
            "total_reward: 236291.48\n",
            "total_cost: 1273.87\n",
            "total_trades: 389\n",
            "Sharpe: 0.706\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 426         |\n",
            "|    iterations           | 66          |\n",
            "|    time_elapsed         | 316         |\n",
            "|    total_timesteps      | 135168      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001180936 |\n",
            "|    clip_fraction        | 0.0336      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.06       |\n",
            "|    explained_variance   | 0.0869      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 8.4         |\n",
            "|    n_updates            | 650         |\n",
            "|    policy_gradient_loss | 0.000192    |\n",
            "|    std                  | 0.697       |\n",
            "|    value_loss           | 13.3        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 350\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1251777.23\n",
            "total_reward: 237434.27\n",
            "total_cost: 1290.22\n",
            "total_trades: 389\n",
            "Sharpe: 0.708\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 427         |\n",
            "|    iterations           | 67          |\n",
            "|    time_elapsed         | 321         |\n",
            "|    total_timesteps      | 137216      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006063983 |\n",
            "|    clip_fraction        | 0.0303      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.06       |\n",
            "|    explained_variance   | 0.0837      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.94        |\n",
            "|    n_updates            | 660         |\n",
            "|    policy_gradient_loss | 0.000331    |\n",
            "|    std                  | 0.694       |\n",
            "|    value_loss           | 13.2        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 426          |\n",
            "|    iterations           | 68           |\n",
            "|    time_elapsed         | 326          |\n",
            "|    total_timesteps      | 139264       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0069336086 |\n",
            "|    clip_fraction        | 0.0448       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.05        |\n",
            "|    explained_variance   | 0.0929       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.3          |\n",
            "|    n_updates            | 670          |\n",
            "|    policy_gradient_loss | -0.00214     |\n",
            "|    std                  | 0.686        |\n",
            "|    value_loss           | 12.7         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 360\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1247842.59\n",
            "total_reward: 233499.63\n",
            "total_cost: 1516.52\n",
            "total_trades: 389\n",
            "Sharpe: 0.699\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 426         |\n",
            "|    iterations           | 69          |\n",
            "|    time_elapsed         | 331         |\n",
            "|    total_timesteps      | 141312      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003935407 |\n",
            "|    clip_fraction        | 0.0167      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.04       |\n",
            "|    explained_variance   | 0.0936      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.61        |\n",
            "|    n_updates            | 680         |\n",
            "|    policy_gradient_loss | 0.000849    |\n",
            "|    std                  | 0.685       |\n",
            "|    value_loss           | 12.9        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 427          |\n",
            "|    iterations           | 70           |\n",
            "|    time_elapsed         | 335          |\n",
            "|    total_timesteps      | 143360       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038716458 |\n",
            "|    clip_fraction        | 0.0224       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.04        |\n",
            "|    explained_variance   | 0.0895       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.16         |\n",
            "|    n_updates            | 690          |\n",
            "|    policy_gradient_loss | 0.000507     |\n",
            "|    std                  | 0.686        |\n",
            "|    value_loss           | 13.1         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 370\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1246801.09\n",
            "total_reward: 232458.13\n",
            "total_cost: 1373.20\n",
            "total_trades: 390\n",
            "Sharpe: 0.696\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 426          |\n",
            "|    iterations           | 71           |\n",
            "|    time_elapsed         | 340          |\n",
            "|    total_timesteps      | 145408       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018224838 |\n",
            "|    clip_fraction        | 0.0493       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.04        |\n",
            "|    explained_variance   | 0.0667       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.54         |\n",
            "|    n_updates            | 700          |\n",
            "|    policy_gradient_loss | -0.000526    |\n",
            "|    std                  | 0.689        |\n",
            "|    value_loss           | 13.5         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 426          |\n",
            "|    iterations           | 72           |\n",
            "|    time_elapsed         | 345          |\n",
            "|    total_timesteps      | 147456       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038030653 |\n",
            "|    clip_fraction        | 0.0304       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.04        |\n",
            "|    explained_variance   | 0.073        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.57         |\n",
            "|    n_updates            | 710          |\n",
            "|    policy_gradient_loss | -0.0013      |\n",
            "|    std                  | 0.681        |\n",
            "|    value_loss           | 13.1         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 380\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1235616.16\n",
            "total_reward: 221273.20\n",
            "total_cost: 1392.77\n",
            "total_trades: 388\n",
            "Sharpe: 0.674\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 427         |\n",
            "|    iterations           | 73          |\n",
            "|    time_elapsed         | 350         |\n",
            "|    total_timesteps      | 149504      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003649503 |\n",
            "|    clip_fraction        | 0.026       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.03       |\n",
            "|    explained_variance   | 0.0662      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.63        |\n",
            "|    n_updates            | 720         |\n",
            "|    policy_gradient_loss | -0.000746   |\n",
            "|    std                  | 0.672       |\n",
            "|    value_loss           | 12.9        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 426        |\n",
            "|    iterations           | 74         |\n",
            "|    time_elapsed         | 355        |\n",
            "|    total_timesteps      | 151552     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00514442 |\n",
            "|    clip_fraction        | 0.0601     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.01      |\n",
            "|    explained_variance   | 0.1        |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 5.66       |\n",
            "|    n_updates            | 730        |\n",
            "|    policy_gradient_loss | -0.00323   |\n",
            "|    std                  | 0.662      |\n",
            "|    value_loss           | 13.1       |\n",
            "----------------------------------------\n",
            "day: 391, episode: 390\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1252446.62\n",
            "total_reward: 238103.66\n",
            "total_cost: 1326.25\n",
            "total_trades: 387\n",
            "Sharpe: 0.718\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 426         |\n",
            "|    iterations           | 75          |\n",
            "|    time_elapsed         | 359         |\n",
            "|    total_timesteps      | 153600      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002621593 |\n",
            "|    clip_fraction        | 0.0337      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.01       |\n",
            "|    explained_variance   | 0.173       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.28        |\n",
            "|    n_updates            | 740         |\n",
            "|    policy_gradient_loss | 0.000363    |\n",
            "|    std                  | 0.669       |\n",
            "|    value_loss           | 12.1        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 426         |\n",
            "|    iterations           | 76          |\n",
            "|    time_elapsed         | 364         |\n",
            "|    total_timesteps      | 155648      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010890508 |\n",
            "|    clip_fraction        | 0.0346      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.01       |\n",
            "|    explained_variance   | 0.271       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.51        |\n",
            "|    n_updates            | 750         |\n",
            "|    policy_gradient_loss | 9.12e-05    |\n",
            "|    std                  | 0.662       |\n",
            "|    value_loss           | 11          |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 400\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1265185.56\n",
            "total_reward: 250842.61\n",
            "total_cost: 1383.02\n",
            "total_trades: 389\n",
            "Sharpe: 0.751\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 426         |\n",
            "|    iterations           | 77          |\n",
            "|    time_elapsed         | 369         |\n",
            "|    total_timesteps      | 157696      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006273358 |\n",
            "|    clip_fraction        | 0.0493      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1          |\n",
            "|    explained_variance   | 0.379       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.69        |\n",
            "|    n_updates            | 760         |\n",
            "|    policy_gradient_loss | -0.000372   |\n",
            "|    std                  | 0.662       |\n",
            "|    value_loss           | 10.2        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 426         |\n",
            "|    iterations           | 78          |\n",
            "|    time_elapsed         | 374         |\n",
            "|    total_timesteps      | 159744      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007172455 |\n",
            "|    clip_fraction        | 0.0361      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.01       |\n",
            "|    explained_variance   | 0.422       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.38        |\n",
            "|    n_updates            | 770         |\n",
            "|    policy_gradient_loss | 0.00139     |\n",
            "|    std                  | 0.665       |\n",
            "|    value_loss           | 10.3        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 410\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1265287.41\n",
            "total_reward: 250944.46\n",
            "total_cost: 1332.11\n",
            "total_trades: 388\n",
            "Sharpe: 0.750\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 426          |\n",
            "|    iterations           | 79           |\n",
            "|    time_elapsed         | 379          |\n",
            "|    total_timesteps      | 161792       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030002047 |\n",
            "|    clip_fraction        | 0.0287       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.01        |\n",
            "|    explained_variance   | 0.419        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.16         |\n",
            "|    n_updates            | 780          |\n",
            "|    policy_gradient_loss | -0.000443    |\n",
            "|    std                  | 0.658        |\n",
            "|    value_loss           | 11.2         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 426          |\n",
            "|    iterations           | 80           |\n",
            "|    time_elapsed         | 384          |\n",
            "|    total_timesteps      | 163840       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023012096 |\n",
            "|    clip_fraction        | 0.04         |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1           |\n",
            "|    explained_variance   | 0.451        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.27         |\n",
            "|    n_updates            | 790          |\n",
            "|    policy_gradient_loss | -0.00101     |\n",
            "|    std                  | 0.661        |\n",
            "|    value_loss           | 10.9         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 420\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1250550.08\n",
            "total_reward: 236207.12\n",
            "total_cost: 1474.15\n",
            "total_trades: 386\n",
            "Sharpe: 0.717\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 426          |\n",
            "|    iterations           | 81           |\n",
            "|    time_elapsed         | 388          |\n",
            "|    total_timesteps      | 165888       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017470104 |\n",
            "|    clip_fraction        | 0.0303       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.01        |\n",
            "|    explained_variance   | 0.418        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.93         |\n",
            "|    n_updates            | 800          |\n",
            "|    policy_gradient_loss | -0.000657    |\n",
            "|    std                  | 0.667        |\n",
            "|    value_loss           | 10.8         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 426         |\n",
            "|    iterations           | 82          |\n",
            "|    time_elapsed         | 394         |\n",
            "|    total_timesteps      | 167936      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004818974 |\n",
            "|    clip_fraction        | 0.0555      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.01       |\n",
            "|    explained_variance   | 0.392       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.94        |\n",
            "|    n_updates            | 810         |\n",
            "|    policy_gradient_loss | -0.0042     |\n",
            "|    std                  | 0.664       |\n",
            "|    value_loss           | 10.8        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 430\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1253667.51\n",
            "total_reward: 239324.55\n",
            "total_cost: 1764.54\n",
            "total_trades: 387\n",
            "Sharpe: 0.741\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 426          |\n",
            "|    iterations           | 83           |\n",
            "|    time_elapsed         | 398          |\n",
            "|    total_timesteps      | 169984       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0058292346 |\n",
            "|    clip_fraction        | 0.0574       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.01        |\n",
            "|    explained_variance   | 0.453        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.76         |\n",
            "|    n_updates            | 820          |\n",
            "|    policy_gradient_loss | 4.52e-05     |\n",
            "|    std                  | 0.659        |\n",
            "|    value_loss           | 10.9         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 426          |\n",
            "|    iterations           | 84           |\n",
            "|    time_elapsed         | 403          |\n",
            "|    total_timesteps      | 172032       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028642854 |\n",
            "|    clip_fraction        | 0.0332       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.999       |\n",
            "|    explained_variance   | 0.476        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.39         |\n",
            "|    n_updates            | 830          |\n",
            "|    policy_gradient_loss | 0.000245     |\n",
            "|    std                  | 0.653        |\n",
            "|    value_loss           | 11.3         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 440\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1232376.33\n",
            "total_reward: 218033.37\n",
            "total_cost: 1903.60\n",
            "total_trades: 389\n",
            "Sharpe: 0.686\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 426          |\n",
            "|    iterations           | 85           |\n",
            "|    time_elapsed         | 408          |\n",
            "|    total_timesteps      | 174080       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038415971 |\n",
            "|    clip_fraction        | 0.0293       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.992       |\n",
            "|    explained_variance   | 0.506        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.28         |\n",
            "|    n_updates            | 840          |\n",
            "|    policy_gradient_loss | 0.000421     |\n",
            "|    std                  | 0.653        |\n",
            "|    value_loss           | 10.5         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 426         |\n",
            "|    iterations           | 86          |\n",
            "|    time_elapsed         | 412         |\n",
            "|    total_timesteps      | 176128      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008914833 |\n",
            "|    clip_fraction        | 0.027       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.993      |\n",
            "|    explained_variance   | 0.514       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.08        |\n",
            "|    n_updates            | 850         |\n",
            "|    policy_gradient_loss | -1.15e-05   |\n",
            "|    std                  | 0.652       |\n",
            "|    value_loss           | 9.7         |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 450\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1245502.70\n",
            "total_reward: 231159.74\n",
            "total_cost: 1590.96\n",
            "total_trades: 387\n",
            "Sharpe: 0.701\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 426          |\n",
            "|    iterations           | 87           |\n",
            "|    time_elapsed         | 418          |\n",
            "|    total_timesteps      | 178176       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018984766 |\n",
            "|    clip_fraction        | 0.0527       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.988       |\n",
            "|    explained_variance   | 0.486        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.47         |\n",
            "|    n_updates            | 860          |\n",
            "|    policy_gradient_loss | 0.000954     |\n",
            "|    std                  | 0.648        |\n",
            "|    value_loss           | 10.7         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 426          |\n",
            "|    iterations           | 88           |\n",
            "|    time_elapsed         | 422          |\n",
            "|    total_timesteps      | 180224       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026509338 |\n",
            "|    clip_fraction        | 0.0266       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.979       |\n",
            "|    explained_variance   | 0.472        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.92         |\n",
            "|    n_updates            | 870          |\n",
            "|    policy_gradient_loss | 0.000271     |\n",
            "|    std                  | 0.643        |\n",
            "|    value_loss           | 11.4         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 460\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1246086.66\n",
            "total_reward: 231743.70\n",
            "total_cost: 1758.33\n",
            "total_trades: 388\n",
            "Sharpe: 0.710\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 426          |\n",
            "|    iterations           | 89           |\n",
            "|    time_elapsed         | 427          |\n",
            "|    total_timesteps      | 182272       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011715232 |\n",
            "|    clip_fraction        | 0.0189       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.977       |\n",
            "|    explained_variance   | 0.479        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.04         |\n",
            "|    n_updates            | 880          |\n",
            "|    policy_gradient_loss | -0.000193    |\n",
            "|    std                  | 0.643        |\n",
            "|    value_loss           | 10.6         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 470\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1242009.05\n",
            "total_reward: 227666.09\n",
            "total_cost: 1578.30\n",
            "total_trades: 389\n",
            "Sharpe: 0.687\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 425          |\n",
            "|    iterations           | 90           |\n",
            "|    time_elapsed         | 432          |\n",
            "|    total_timesteps      | 184320       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031312504 |\n",
            "|    clip_fraction        | 0.0139       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.981       |\n",
            "|    explained_variance   | 0.475        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.65         |\n",
            "|    n_updates            | 890          |\n",
            "|    policy_gradient_loss | -0.000271    |\n",
            "|    std                  | 0.648        |\n",
            "|    value_loss           | 10.3         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 426         |\n",
            "|    iterations           | 91          |\n",
            "|    time_elapsed         | 437         |\n",
            "|    total_timesteps      | 186368      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005523201 |\n",
            "|    clip_fraction        | 0.0587      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.983      |\n",
            "|    explained_variance   | 0.385       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.92        |\n",
            "|    n_updates            | 900         |\n",
            "|    policy_gradient_loss | -0.00313    |\n",
            "|    std                  | 0.645       |\n",
            "|    value_loss           | 11          |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 480\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1254915.11\n",
            "total_reward: 240572.15\n",
            "total_cost: 1326.29\n",
            "total_trades: 391\n",
            "Sharpe: 0.717\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 426         |\n",
            "|    iterations           | 92          |\n",
            "|    time_elapsed         | 441         |\n",
            "|    total_timesteps      | 188416      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011759432 |\n",
            "|    clip_fraction        | 0.0592      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.974      |\n",
            "|    explained_variance   | 0.474       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.58        |\n",
            "|    n_updates            | 910         |\n",
            "|    policy_gradient_loss | -0.00161    |\n",
            "|    std                  | 0.642       |\n",
            "|    value_loss           | 10.3        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 425          |\n",
            "|    iterations           | 93           |\n",
            "|    time_elapsed         | 447          |\n",
            "|    total_timesteps      | 190464       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021791907 |\n",
            "|    clip_fraction        | 0.0354       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.969       |\n",
            "|    explained_variance   | 0.415        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.75         |\n",
            "|    n_updates            | 920          |\n",
            "|    policy_gradient_loss | 0.000711     |\n",
            "|    std                  | 0.635        |\n",
            "|    value_loss           | 11.2         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 490\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1244002.27\n",
            "total_reward: 229659.31\n",
            "total_cost: 1517.55\n",
            "total_trades: 388\n",
            "Sharpe: 0.693\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 426         |\n",
            "|    iterations           | 94          |\n",
            "|    time_elapsed         | 451         |\n",
            "|    total_timesteps      | 192512      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006060957 |\n",
            "|    clip_fraction        | 0.0534      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.959      |\n",
            "|    explained_variance   | 0.393       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.71        |\n",
            "|    n_updates            | 930         |\n",
            "|    policy_gradient_loss | -0.00261    |\n",
            "|    std                  | 0.627       |\n",
            "|    value_loss           | 11.1        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 426          |\n",
            "|    iterations           | 95           |\n",
            "|    time_elapsed         | 456          |\n",
            "|    total_timesteps      | 194560       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029794427 |\n",
            "|    clip_fraction        | 0.0255       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.952       |\n",
            "|    explained_variance   | 0.349        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.56         |\n",
            "|    n_updates            | 940          |\n",
            "|    policy_gradient_loss | -0.000278    |\n",
            "|    std                  | 0.627        |\n",
            "|    value_loss           | 11.2         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 500\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1256962.31\n",
            "total_reward: 242619.35\n",
            "total_cost: 1488.11\n",
            "total_trades: 390\n",
            "Sharpe: 0.716\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 426         |\n",
            "|    iterations           | 96          |\n",
            "|    time_elapsed         | 461         |\n",
            "|    total_timesteps      | 196608      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005736041 |\n",
            "|    clip_fraction        | 0.043       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.948      |\n",
            "|    explained_variance   | 0.244       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.91        |\n",
            "|    n_updates            | 950         |\n",
            "|    policy_gradient_loss | -2.57e-05   |\n",
            "|    std                  | 0.624       |\n",
            "|    value_loss           | 12.4        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 426         |\n",
            "|    iterations           | 97          |\n",
            "|    time_elapsed         | 466         |\n",
            "|    total_timesteps      | 198656      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.000749703 |\n",
            "|    clip_fraction        | 0.0173      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.953      |\n",
            "|    explained_variance   | 0.121       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.94        |\n",
            "|    n_updates            | 960         |\n",
            "|    policy_gradient_loss | -0.000333   |\n",
            "|    std                  | 0.63        |\n",
            "|    value_loss           | 13.3        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 510\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1243923.73\n",
            "total_reward: 229580.77\n",
            "total_cost: 1287.51\n",
            "total_trades: 387\n",
            "Sharpe: 0.691\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 425          |\n",
            "|    iterations           | 98           |\n",
            "|    time_elapsed         | 471          |\n",
            "|    total_timesteps      | 200704       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027126875 |\n",
            "|    clip_fraction        | 0.026        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.961       |\n",
            "|    explained_variance   | 0.163        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.36         |\n",
            "|    n_updates            | 970          |\n",
            "|    policy_gradient_loss | -0.00212     |\n",
            "|    std                  | 0.634        |\n",
            "|    value_loss           | 12.7         |\n",
            "------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# -------------------------------------------------\n",
        "# Step 4: Train Both Agents\n",
        "# -------------------------------------------------\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.callbacks import CheckpointCallback\n",
        "import os\n",
        "\n",
        "# Make sure your checkpoint folder exists\n",
        "os.makedirs(\"/content/checkpoints/\", exist_ok=True)\n",
        "\n",
        "def train_agent(env, model_name=\"ppo\", total_timesteps=200_000):\n",
        "    \"\"\"Train a trading agent with periodic checkpointing.\"\"\"\n",
        "    # 1. Create the checkpoint callback\n",
        "    checkpoint_callback = CheckpointCallback(\n",
        "        save_freq=50_000,\n",
        "        save_path=\"/content/checkpoints/\",\n",
        "        name_prefix=model_name\n",
        "    )\n",
        "\n",
        "    # 2. Instantiate the PPO model\n",
        "    model = PPO(\n",
        "        \"MlpPolicy\",\n",
        "        env=env,\n",
        "        seed=42,\n",
        "        verbose=1,\n",
        "        policy_kwargs={\n",
        "            \"net_arch\": [{\"pi\": [64, 64], \"vf\": [64, 64]}]\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # 3. Train, *passing* the callback into learn()\n",
        "    model.learn(\n",
        "        total_timesteps=total_timesteps,\n",
        "        callback=checkpoint_callback\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "print(\"Training Chain of Thought Agent…\")\n",
        "chainofthought_model = train_agent(chainofthought_train_env, model_name=\"ppo_chainofthought\")\n",
        "chainofthought_model.save(\"/content/chainofthought_trading_model\")\n",
        "\n",
        "print(\"\\nTraining RefPaper Agent…\")\n",
        "refpaper_model = train_agent(refpaper_train_env, model_name=\"ppo_refpaper\")\n",
        "refpaper_model.save(\"/content/refpaper_trading_model\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "YWuNZ1TaXero"
      },
      "outputs": [],
      "source": [
        "# -------------------------------------------------\n",
        "# Step 5: Save Both Agents\n",
        "# -------------------------------------------------\n",
        "# After training Chain of Thought\n",
        "chainofthought_model.save(f\"{MODEL_DIR}/ppo_chainofthought_latest.zip\")\n",
        "\n",
        "# After training RefPaper\n",
        "refpaper_model.save(f\"{MODEL_DIR}/ppo_refpaper_latest.zip\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------\n",
        "# Step 5 b: Save Both Agents as .pth files\n",
        "# -------------------------------------------------\n",
        "# After training Chain of Thought\n",
        "import torch\n",
        "\n",
        "# Save Chain of Thought model policy as .pth\n",
        "torch.save(chainofthought_model.policy.state_dict(), f\"{MODEL_DIR}/ppo_chainofthought_policy.pth\")\n",
        "\n",
        "# Save RefPaper model policy as .pth\n",
        "torch.save(refpaper_model.policy.state_dict(), f\"{MODEL_DIR}/ppo_refpaper_policy.pth\")\n"
      ],
      "metadata": {
        "id": "xVRwIy1hqyu5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cu8Z8DZL0lvd",
        "outputId": "4f0b7f2a-dfdd-4987-b5ae-67f4a229288d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating Chain of Thought Agent...\n",
            "\n",
            "Evaluating RefPaper Agent...\n"
          ]
        }
      ],
      "source": [
        " # -------------------------------------------------\n",
        "# Step 6: Backtesting and Evaluation - Sharpe ratio,\n",
        "# total return, annual return, annual volatility,\n",
        "# maximum drawdown and win rate\n",
        "# -------------------------------------------------\n",
        "def calculate_metrics(df_account_value):\n",
        "    \"\"\"Calculate performance metrics\"\"\"\n",
        "    df_account_value['daily_return'] = df_account_value['account_value'].pct_change(fill_method=None)\n",
        "    daily_returns = df_account_value['daily_return'].dropna()\n",
        "\n",
        "    # Basic metrics\n",
        "    total_return = df_account_value['account_value'].iloc[-1] / df_account_value['account_value'].iloc[0] - 1\n",
        "    annual_return = np.mean(daily_returns) * 252\n",
        "    annual_volatility = np.std(daily_returns) * np.sqrt(252)\n",
        "    sharpe_ratio = annual_return / annual_volatility if annual_volatility != 0 else 0\n",
        "\n",
        "    # Drawdown calculations\n",
        "    cumulative_returns = (1 + daily_returns).cumprod()\n",
        "    peak = cumulative_returns.cummax()\n",
        "    drawdown = (peak - cumulative_returns) / peak\n",
        "    max_drawdown = drawdown.max()\n",
        "\n",
        "    # Win rate\n",
        "    win_rate = (daily_returns > 0).mean()\n",
        "\n",
        "    return {\n",
        "        'Total Return': total_return,\n",
        "        'Annual Return': annual_return,\n",
        "        'Annual Volatility': annual_volatility,\n",
        "        'Sharpe Ratio': sharpe_ratio,\n",
        "        'Max Drawdown': max_drawdown,\n",
        "        'Win Rate': win_rate\n",
        "    }\n",
        "\n",
        "def evaluate_agent(model, trade_df):\n",
        "    \"\"\"Evaluate agent performance\"\"\"\n",
        "    env = StockTradingEnv(\n",
        "        df=trade_df,\n",
        "        stock_dim=1,\n",
        "        num_stock_shares=[100],\n",
        "        buy_cost_pct=[0.001],\n",
        "        sell_cost_pct=[0.001],\n",
        "        hmax=100,\n",
        "        initial_amount=1_000_000,\n",
        "        reward_scaling=1e-4,\n",
        "        state_space=11,\n",
        "        action_space=1,\n",
        "        tech_indicator_list=INDICATORS,\n",
        "        risk_indicator_col='sentiment'\n",
        "    )\n",
        "\n",
        "    obs, _ = env.reset()\n",
        "    account_values = [env.initial_amount]\n",
        "    dates = [trade_df.iloc[0]['date']]\n",
        "\n",
        "    for i in range(len(trade_df)-1):\n",
        "        action, _ = model.predict(obs)\n",
        "        obs, reward, terminated, truncated, info = env.step(action)\n",
        "        done = terminated or truncated\n",
        "\n",
        "        # Get current account value directly from the environment\n",
        "#        current_account_value = env.total_asset\n",
        "# replaced from below line\n",
        "# Get current account value from the info dict (fallback to internal memory)\n",
        "        current_account_value = info.get('total_asset', None)\n",
        "        if current_account_value is None:\n",
        "# as a backup, grab the last recorded value\n",
        "          current_account_value = env.asset_memory[-1]  # or env.state[0]\n",
        "# replaced till above line\n",
        "        account_values.append(current_account_value)\n",
        "        dates.append(trade_df.iloc[i+1]['date'])\n",
        "\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    df_account_value = pd.DataFrame({'date': dates, 'account_value': account_values})\n",
        "    perf_metrics = calculate_metrics(df_account_value)\n",
        "\n",
        "    return df_account_value, perf_metrics\n",
        "\n",
        "print(\"\\nEvaluating Chain of Thought Agent...\")\n",
        "cf_account_value, cf_metrics = evaluate_agent(chainofthought_model, chainofthought_trade)\n",
        "\n",
        "print(\"\\nEvaluating RefPaper Agent...\")\n",
        "rp_account_value, rp_metrics = evaluate_agent(refpaper_model, refpaper_trade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnZFS3P2nnhk",
        "outputId": "c372599d-e052-4e2f-cba4-5f5a1f23ee07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rachev Ratio (α=0.05) for Chain of Thought Agent: 0.8414\n",
            "Rachev Ratio (α=0.05) for RefPaper Agent: 0.8088\n"
          ]
        }
      ],
      "source": [
        "# -------------------------------------------------\n",
        "# Step 7: Backtesting and Evaluation - Rachev Ratio Calculation\n",
        "# -------------------------------------------------\n",
        "import numpy as np\n",
        "\n",
        "# Choose your tail‐probability (e.g. 5%)\n",
        "alpha = 0.05\n",
        "\n",
        "# Assuming you already have cf_account_value and rp_account_value from evaluate_agent()\n",
        "for name, df in [(\"Chain of Thought\", cf_account_value), (\"RefPaper\", rp_account_value)]:\n",
        "    # 1) Compute daily returns\n",
        "    daily_returns = df['account_value'].pct_change().dropna()\n",
        "\n",
        "    # 2) Compute cutoffs\n",
        "    q_low  = daily_returns.quantile(alpha)\n",
        "    q_high = daily_returns.quantile(1 - alpha)\n",
        "\n",
        "    # 3) Extract tails\n",
        "    lower_tail = daily_returns[daily_returns <= q_low]\n",
        "    upper_tail = daily_returns[daily_returns >= q_high]\n",
        "\n",
        "    # 4) Expected Tail Loss (ETL) and Expected Tail Gain (ETG)\n",
        "    etl = abs(lower_tail.mean())\n",
        "    etg = upper_tail.mean()\n",
        "\n",
        "    # 5) Rachev ratio (guarding against zero ETL)\n",
        "    rachev = etg / etl if etl != 0 else np.nan\n",
        "\n",
        "    print(f\"Rachev Ratio (α={alpha}) for {name} Agent: {rachev:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sm0UsuKW01-c",
        "outputId": "16af2236-7d8e-419b-8904-e7e37feb079a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Performance Comparison ===\n",
            "           Metric  Chain of Thought  RefPaper\n",
            "     Total Return          0.068061  0.057534\n",
            "    Annual Return          0.108283  0.094133\n",
            "Annual Volatility          0.133273  0.139077\n",
            "     Sharpe Ratio          0.812485  0.676839\n",
            "     Max Drawdown          0.112923  0.118230\n",
            "         Win Rate          0.395210  0.395210\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# -------------------------------------------------\n",
        "# Step 8: Comparison and Visualization\n",
        "# -------------------------------------------------\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Combine results for comparison\n",
        "results_df = pd.DataFrame({\n",
        "    'Metric': list(cf_metrics.keys()),\n",
        "    'Chain of Thought': list(cf_metrics.values()),\n",
        "    'RefPaper': list(rp_metrics.values())\n",
        "})\n",
        "\n",
        "print(\"\\n=== Performance Comparison ===\")\n",
        "print(results_df.to_string(index=False))\n",
        "\n",
        "# Plot account value growth\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(cf_account_value['date'], cf_account_value['account_value'], label='Chain of Thought Agent')\n",
        "plt.plot(rp_account_value['date'], rp_account_value['account_value'], label='RefPaper Agent')\n",
        "plt.title('Account Value Growth Comparison')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Account Value ($)')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8e0RJlzv0qtd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6UC4tCux02DH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b8aea02",
        "outputId": "4e4f59b6-05ef-43a2-900a-e3bd847544df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
            "  warnings.warn(\n",
            "<ipython-input-11-a58a326d81c8>:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model_from_pth.policy.load_state_dict(torch.load(\"/content/ppo_chainofthought_policy.pth\"))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating Chain of Thought Agent (from .pth)...\n",
            "\n",
            "=== Performance Metrics from .pth ===\n",
            "           Metric  Chain of Thought (.pth)\n",
            "     Total Return                 0.060744\n",
            "    Annual Return                 0.098343\n",
            "Annual Volatility                 0.136464\n",
            "     Sharpe Ratio                 0.720653\n",
            "     Max Drawdown                 0.116899\n",
            "         Win Rate                 0.395210\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# -------------------------------------------------\n",
        "# Load PPO model from .pth and evaluate Chain of Thought Agent\n",
        "# -------------------------------------------------\n",
        "import torch\n",
        "from stable_baselines3 import PPO\n",
        "\n",
        "\n",
        "# Rebuild the environment used during training\n",
        "env = StockTradingEnv(\n",
        "    df=chainofthought_trade,\n",
        "    stock_dim=1,\n",
        "    num_stock_shares=[100],\n",
        "    buy_cost_pct=[0.001],\n",
        "    sell_cost_pct=[0.001],\n",
        "    hmax=100,\n",
        "    initial_amount=1_000_000,\n",
        "    reward_scaling=1e-4,\n",
        "    state_space=11,\n",
        "    action_space=1,\n",
        "    tech_indicator_list=INDICATORS,\n",
        "    risk_indicator_col='sentiment'\n",
        ")\n",
        "\n",
        "# Recreate the PPO model (same architecture as training)\n",
        "model_from_pth = PPO(\"MlpPolicy\", env=env, verbose=0, seed=42)\n",
        "\n",
        "# Load policy weights from .pth file\n",
        "model_from_pth.policy.load_state_dict(torch.load(\"/content/ppo_chainofthought_policy.pth\"))\n",
        "\n",
        "# Evaluate Chain of Thought agent loaded from .pth\n",
        "print(\"\\nEvaluating Chain of Thought Agent (from .pth)...\")\n",
        "cf_account_value, cf_metrics = evaluate_agent(model_from_pth, chainofthought_trade)\n",
        "\n",
        "# Display performance metrics\n",
        "import pandas as pd\n",
        "results_df = pd.DataFrame({\n",
        "    'Metric': list(cf_metrics.keys()),\n",
        "    'Chain of Thought (.pth)': list(cf_metrics.values())\n",
        "})\n",
        "print(\"\\n=== Performance Metrics from .pth ===\")\n",
        "print(results_df.to_string(index=False))\n",
        "\n",
        "# Plot performance\n",
        "import matplotlib.pyplot as plt\n",
        "cf_account_value['date'] = pd.to_datetime(cf_account_value['date'])\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(cf_account_value['date'], cf_account_value['account_value'], label='Chain of Thought Agent (.pth)', linewidth=2)\n",
        "plt.title('Chain of Thought Agent Performance (Loaded from .pth)')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Account Value ($)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iotNY_FVhR2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rgRtAm4chR6s"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}