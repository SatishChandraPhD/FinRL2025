{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPavz-CozWnc"
      },
      "source": [
        "1. This program takes the combined trade and sentiments data as input:\n",
        "a. aapl_trading_sentiment_data_all_days_counterfactual.csv and\n",
        "b. aapl_trading_sentiment_data_all_days_RefPaper.csv\n",
        "2. Sets up the stock trading environment using libraries from https://github.com/benstaf/FinRL_DeepSeek.git\n",
        "3. Trains agents based on data from Counterfactual prompting approach and the Reference Paper's prompting approach\n",
        "4. Peforms back testing and evaluates both the trading agents\n",
        "5. Compares the performance of the agents     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwYMED_PzgrY",
        "outputId": "cff099cb-9f6a-4493-cfef-43899a6dc93e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Collecting finrl\n",
            "  Downloading FinRL-0.3.7-py3-none-any.whl.metadata (909 bytes)\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.11/dist-packages (0.2.57)\n",
            "Collecting stockstats\n",
            "  Downloading stockstats-0.6.4-py2.py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.11/dist-packages (1.1.1)\n",
            "Collecting stable_baselines3\n",
            "  Downloading stable_baselines3-2.6.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting alpaca-trade-api\n",
            "  Downloading alpaca_trade_api-3.2.0-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting exchange_calendars\n",
            "  Downloading exchange_calendars-4.10-py3-none-any.whl.metadata (37 kB)\n",
            "Collecting wrds\n",
            "  Downloading wrds-3.3.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Collecting ta\n",
            "  Downloading ta-0.11.0.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.0.2)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.32.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.3.7)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2025.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.11/dist-packages (from yfinance) (3.18.1)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.13.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (4.13.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (0.0.4)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.6.0+cu124)\n",
            "Collecting urllib3<2,>1.24 (from alpaca-trade-api)\n",
            "  Downloading urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: websocket-client<2,>=0.56.0 in /usr/local/lib/python3.11/dist-packages (from alpaca-trade-api) (1.8.0)\n",
            "Collecting websockets<11,>=9.0 (from alpaca-trade-api)\n",
            "  Downloading websockets-10.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting msgpack==1.0.3 (from alpaca-trade-api)\n",
            "  Downloading msgpack-1.0.3.tar.gz (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from alpaca-trade-api) (3.11.15)\n",
            "Collecting PyYAML==6.0.1 (from alpaca-trade-api)\n",
            "  Downloading PyYAML-6.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting deprecation==2.1.0 (from alpaca-trade-api)\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from deprecation==2.1.0->alpaca-trade-api) (24.2)\n",
            "Collecting pyluach (from exchange_calendars)\n",
            "  Downloading pyluach-2.2.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.11/dist-packages (from exchange_calendars) (0.12.1)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.11/dist-packages (from exchange_calendars) (2025.2)\n",
            "Collecting korean_lunar_calendar (from exchange_calendars)\n",
            "  Downloading korean_lunar_calendar-0.3.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting psycopg2-binary<2.10,>=2.9 (from wrds)\n",
            "  Downloading psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: sqlalchemy<2.1,>=2 in /usr/local/lib/python3.11/dist-packages (from wrds) (2.0.40)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.3->alpaca-trade-api) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.3->alpaca-trade-api) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.3->alpaca-trade-api) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.3->alpaca-trade-api) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.3->alpaca-trade-api) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.3->alpaca-trade-api) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.3->alpaca-trade-api) (1.20.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<2.1,>=2->wrds) (3.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable_baselines3) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0,>=2.3->stable_baselines3) (3.0.2)\n",
            "Downloading FinRL-0.3.7-py3-none-any.whl (127 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.2/127.2 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stockstats-0.6.4-py2.py3-none-any.whl (31 kB)\n",
            "Downloading stable_baselines3-2.6.0-py3-none-any.whl (184 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.5/184.5 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alpaca_trade_api-3.2.0-py3-none-any.whl (34 kB)\n",
            "Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading PyYAML-6.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (757 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m757.7/757.7 kB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading exchange_calendars-4.10-py3-none-any.whl (198 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.4/198.4 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrds-3.3.0-py3-none-any.whl (13 kB)\n",
            "Downloading psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m105.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m94.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.2/144.2 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-10.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.4/107.4 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading korean_lunar_calendar-0.3.1-py3-none-any.whl (9.0 kB)\n",
            "Downloading pyluach-2.2.0-py3-none-any.whl (25 kB)\n",
            "Building wheels for collected packages: msgpack, ta\n",
            "  Building wheel for msgpack (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for msgpack: filename=msgpack-1.0.3-cp311-cp311-linux_x86_64.whl size=15688 sha256=ae948ecfdb02748f2f0bc23eace0ed7f8cdd2e55d3f35a60e5bfbf3199c67514\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/35/da/ed9b26b510235e00e3a3c3bab7bad97b59214729662255ab3d\n",
            "  Building wheel for ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ta: filename=ta-0.11.0-py3-none-any.whl size=29412 sha256=ed76e6910f98b3a24e35c5624869c84ce2bb4457724ab95cb81b8f3d7ff3fc24\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/d7/29/7781cc5eb9a3659d032d7d15bdd0f49d07d2b24fec29f44bc4\n",
            "Successfully built msgpack ta\n",
            "Installing collected packages: msgpack, korean_lunar_calendar, websockets, urllib3, PyYAML, pyluach, psycopg2-binary, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, finrl, deprecation, nvidia-cusparse-cu12, nvidia-cudnn-cu12, wrds, ta, stockstats, nvidia-cusolver-cu12, exchange_calendars, alpaca-trade-api, stable_baselines3\n",
            "  Attempting uninstall: msgpack\n",
            "    Found existing installation: msgpack 1.1.0\n",
            "    Uninstalling msgpack-1.1.0:\n",
            "      Successfully uninstalled msgpack-1.1.0\n",
            "  Attempting uninstall: websockets\n",
            "    Found existing installation: websockets 15.0.1\n",
            "    Uninstalling websockets-15.0.1:\n",
            "      Successfully uninstalled websockets-15.0.1\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.4.0\n",
            "    Uninstalling urllib3-2.4.0:\n",
            "      Successfully uninstalled urllib3-2.4.0\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 6.0.2\n",
            "    Uninstalling PyYAML-6.0.2:\n",
            "      Successfully uninstalled PyYAML-6.0.2\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-genai 1.13.0 requires websockets<15.1.0,>=13.0.0, but you have websockets 10.4 which is incompatible.\n",
            "dataproc-spark-connect 0.7.2 requires websockets>=14.0, but you have websockets 10.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PyYAML-6.0.1 alpaca-trade-api-3.2.0 deprecation-2.1.0 exchange_calendars-4.10 finrl-0.3.7 korean_lunar_calendar-0.3.1 msgpack-1.0.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 psycopg2-binary-2.9.10 pyluach-2.2.0 stable_baselines3-2.6.0 stockstats-0.6.4 ta-0.11.0 urllib3-1.26.20 websockets-10.4 wrds-3.3.0\n",
            "Cloning into 'FinRL_DeepSeek'...\n",
            "remote: Enumerating objects: 145, done.\u001b[K\n",
            "remote: Counting objects: 100% (145/145), done.\u001b[K\n",
            "remote: Compressing objects: 100% (144/144), done.\u001b[K\n",
            "remote: Total 145 (delta 94), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (145/145), 1.21 MiB | 3.70 MiB/s, done.\n",
            "Resolving deltas: 100% (94/94), done.\n",
            "/content/FinRL_DeepSeek\n"
          ]
        }
      ],
      "source": [
        "# Step 0: Prerequisites & Setup\n",
        "# -------------------------------------------------\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install finrl yfinance stockstats gymnasium stable_baselines3 alpaca-trade-api exchange_calendars wrds matplotlib pandas scikit-learn ta\n",
        "%matplotlib inline\n",
        "\n",
        "# Clone repo and set paths\n",
        "!git clone https://github.com/benstaf/FinRL_DeepSeek.git\n",
        "%cd /content/FinRL_DeepSeek\n",
        "import sys\n",
        "sys.path.append('/content/FinRL_DeepSeek')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wjIshuqAXEPC"
      },
      "outputs": [],
      "source": [
        "# Step 1: Create directory to persist models\n",
        "# -------------------------------------------------\n",
        "\n",
        "\n",
        "import os\n",
        "\n",
        "MODEL_DIR = \"/content/drive/MyDrive/finrl_models\"\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ruZ065y6ziXX"
      },
      "outputs": [],
      "source": [
        "# -------------------------------------------------\n",
        "# Step 2: Data Loading and Preparation\n",
        "# -------------------------------------------------\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from finrl.meta.preprocessor.preprocessors import data_split\n",
        "import itertools\n",
        "\n",
        "def load_and_prepare_data(filepath):\n",
        "    \"\"\"Load and prepare dataset for training\"\"\"\n",
        "    df = pd.read_csv(filepath)\n",
        "    df['date'] = pd.to_datetime(df['date']).dt.normalize()\n",
        "\n",
        "    # Drop unwanted columns\n",
        "    df = df.drop(columns=[col for col in df.columns if 'Unnamed:' in col or col.endswith('_y')])\n",
        "    df.columns = [col.replace('_x', '') for col in df.columns]\n",
        "\n",
        "    # Forward fill missing values\n",
        "    list_ticker = df[\"tic\"].unique().tolist()\n",
        "    list_date = pd.date_range(start=df['date'].min(), end=df['date'].max())\n",
        "    combination = list(itertools.product(list_date, list_ticker))\n",
        "\n",
        "    processed_full = pd.DataFrame(combination, columns=[\"date\", \"tic\"])\n",
        "    processed_full['date'] = pd.to_datetime(processed_full['date']).dt.normalize()\n",
        "    processed_full = processed_full.merge(df, on=[\"date\", \"tic\"], how=\"left\")\n",
        "    processed_full = processed_full.sort_values(by=[\"tic\", \"date\"]).ffill()\n",
        "\n",
        "    return processed_full\n",
        "\n",
        "# Load both datasets\n",
        "counterfactual_df = load_and_prepare_data('/content/Counterfactual_aapl_trading_sentiment_data_all_days.csv')\n",
        "refpaper_df = load_and_prepare_data('/content/aapl_trading_sentiment_data_all_days_RefPaper.csv')\n",
        "\n",
        "# Split into train/trade periods\n",
        "TRAIN_START_DATE = '2022-06-03'\n",
        "TRAIN_END_DATE = '2023-06-30'\n",
        "TRADE_START_DATE = '2023-07-01'\n",
        "TRADE_END_DATE = '2023-12-16'\n",
        "\n",
        "def split_data(df):\n",
        "    train_df = data_split(df, TRAIN_START_DATE, TRAIN_END_DATE)\n",
        "    trade_df = data_split(df, TRADE_START_DATE, TRADE_END_DATE)\n",
        "    return train_df, trade_df\n",
        "\n",
        "counterfactual_train, counterfactual_trade = split_data(counterfactual_df)\n",
        "refpaper_train, refpaper_trade = split_data(refpaper_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "249pPx9K0IAO",
        "outputId": "91e2affd-11c2-4e70-9444-8fe24225362a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lenght of INDICATORS 8\n",
            "lenght of INDICATORS 8\n",
            "Number of indicators: 8\n"
          ]
        }
      ],
      "source": [
        "# -------------------------------------------------\n",
        "# Step 3: Environment Setup\n",
        "# -------------------------------------------------\n",
        "from env_stocktrading import StockTradingEnv\n",
        "from finrl.config import INDICATORS\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "import gymnasium as gym\n",
        "\n",
        "def create_env(df, state_space=11):  # Correct observation space size\n",
        "    \"\"\"Create trading environment\"\"\"\n",
        "    env = StockTradingEnv(\n",
        "        df=df,\n",
        "        stock_dim=1,\n",
        "        num_stock_shares=[100],\n",
        "        buy_cost_pct=[0.001],\n",
        "        sell_cost_pct=[0.001],\n",
        "        hmax=100,\n",
        "        initial_amount=1_000_000,\n",
        "        reward_scaling=1e-4,\n",
        "        state_space=state_space,\n",
        "        action_space=1,\n",
        "        tech_indicator_list=INDICATORS,\n",
        "        risk_indicator_col='sentiment'\n",
        "    )\n",
        "    print(\"lenght of INDICATORS\" , len(INDICATORS))\n",
        "    return DummyVecEnv([lambda: env])\n",
        "\n",
        "# Create environments with correct observation size\n",
        "counterfactual_train_env = create_env(counterfactual_train)\n",
        "refpaper_train_env = create_env(refpaper_train)\n",
        "\n",
        "from finrl.config import INDICATORS\n",
        "print(f\"Number of indicators: {len(INDICATORS)}\")  # e.g., 5\n",
        "state_space_size=11\n",
        "#state_space_sizeprint(f\"State space size : {len(state_space_size)}\")\n",
        "#state_space_size = 4 (price) + 1 (holdings) + len(INDICATORS) + 1 #(sentiment if used)\n",
        "#print(f\"Calculated state space size: {state_space_size}\")\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKoDZquekHLX",
        "outputId": "5641ebba-bc62-4aae-fdbf-c13bbecda155"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Counterfactual Agent…\n",
            "Using cuda device\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/policies.py:486: UserWarning: As shared layers in the mlp_extractor are removed since SB3 v1.8.0, you should now pass directly a dictionary and not a list (net_arch=dict(pi=..., vf=...) instead of net_arch=[dict(pi=..., vf=...)])\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 541  |\n",
            "|    iterations      | 1    |\n",
            "|    time_elapsed    | 3    |\n",
            "|    total_timesteps | 2048 |\n",
            "-----------------------------\n",
            "day: 391, episode: 10\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1047200.94\n",
            "total_reward: 32857.98\n",
            "total_cost: 3850.27\n",
            "total_trades: 386\n",
            "Sharpe: 0.517\n",
            "=================================\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 414           |\n",
            "|    iterations           | 2             |\n",
            "|    time_elapsed         | 9             |\n",
            "|    total_timesteps      | 4096          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00043162014 |\n",
            "|    clip_fraction        | 0.0108        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.42         |\n",
            "|    explained_variance   | -0.0194       |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 0.244         |\n",
            "|    n_updates            | 10            |\n",
            "|    policy_gradient_loss | -0.000242     |\n",
            "|    std                  | 1.01          |\n",
            "|    value_loss           | 0.749         |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 404         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 15          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003442506 |\n",
            "|    clip_fraction        | 0.0195      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.43       |\n",
            "|    explained_variance   | -0.00181    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.339       |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.00097    |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 0.527       |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 20\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1014782.29\n",
            "total_reward: 439.33\n",
            "total_cost: 2991.83\n",
            "total_trades: 333\n",
            "Sharpe: 0.026\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 411         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 19          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005402279 |\n",
            "|    clip_fraction        | 0.0313      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.43       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.17        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.00195    |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 0.231       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 407         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 25          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003608014 |\n",
            "|    clip_fraction        | 0.016       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.42       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0143      |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.000929   |\n",
            "|    std                  | 0.999       |\n",
            "|    value_loss           | 0.052       |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 30\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1007801.90\n",
            "total_reward: -6541.06\n",
            "total_cost: 3539.54\n",
            "total_trades: 381\n",
            "Sharpe: -0.118\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 408          |\n",
            "|    iterations           | 6            |\n",
            "|    time_elapsed         | 30           |\n",
            "|    total_timesteps      | 12288        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0075070364 |\n",
            "|    clip_fraction        | 0.037        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0382       |\n",
            "|    n_updates            | 50           |\n",
            "|    policy_gradient_loss | -0.00335     |\n",
            "|    std                  | 0.979        |\n",
            "|    value_loss           | 0.0757       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 412          |\n",
            "|    iterations           | 7            |\n",
            "|    time_elapsed         | 34           |\n",
            "|    total_timesteps      | 14336        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011230812 |\n",
            "|    clip_fraction        | 0.000586     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.39        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.401        |\n",
            "|    n_updates            | 60           |\n",
            "|    policy_gradient_loss | -0.00016     |\n",
            "|    std                  | 0.963        |\n",
            "|    value_loss           | 0.683        |\n",
            "------------------------------------------\n",
            "day: 391, episode: 40\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1143296.94\n",
            "total_reward: 128953.98\n",
            "total_cost: 3437.13\n",
            "total_trades: 389\n",
            "Sharpe: 0.980\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 407         |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 40          |\n",
            "|    total_timesteps      | 16384       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007200155 |\n",
            "|    clip_fraction        | 0.0751      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.37       |\n",
            "|    explained_variance   | 0.000672    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.284       |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.00488    |\n",
            "|    std                  | 0.95        |\n",
            "|    value_loss           | 0.745       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 411         |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 44          |\n",
            "|    total_timesteps      | 18432       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002705615 |\n",
            "|    clip_fraction        | 0.00288     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.36       |\n",
            "|    explained_variance   | 0.0105      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.96        |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.000349   |\n",
            "|    std                  | 0.942       |\n",
            "|    value_loss           | 2.1         |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 50\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1300222.66\n",
            "total_reward: 285879.70\n",
            "total_cost: 3640.78\n",
            "total_trades: 389\n",
            "Sharpe: 1.215\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 412          |\n",
            "|    iterations           | 10           |\n",
            "|    time_elapsed         | 49           |\n",
            "|    total_timesteps      | 20480        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038957838 |\n",
            "|    clip_fraction        | 0.03         |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.35        |\n",
            "|    explained_variance   | 0.00502      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.734        |\n",
            "|    n_updates            | 90           |\n",
            "|    policy_gradient_loss | -0.0019      |\n",
            "|    std                  | 0.933        |\n",
            "|    value_loss           | 1.21         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 410         |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 54          |\n",
            "|    total_timesteps      | 22528       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003198679 |\n",
            "|    clip_fraction        | 0.0206      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.35       |\n",
            "|    explained_variance   | -0.0248     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.784       |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.00164    |\n",
            "|    std                  | 0.94        |\n",
            "|    value_loss           | 2.66        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 60\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1290636.70\n",
            "total_reward: 276293.74\n",
            "total_cost: 3520.19\n",
            "total_trades: 388\n",
            "Sharpe: 1.175\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 412          |\n",
            "|    iterations           | 12           |\n",
            "|    time_elapsed         | 59           |\n",
            "|    total_timesteps      | 24576        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012094651 |\n",
            "|    clip_fraction        | 0.0112       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.35        |\n",
            "|    explained_variance   | 0.152        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2            |\n",
            "|    n_updates            | 110          |\n",
            "|    policy_gradient_loss | -0.00132     |\n",
            "|    std                  | 0.931        |\n",
            "|    value_loss           | 5.27         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 409         |\n",
            "|    iterations           | 13          |\n",
            "|    time_elapsed         | 65          |\n",
            "|    total_timesteps      | 26624       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003283367 |\n",
            "|    clip_fraction        | 0.0168      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.35       |\n",
            "|    explained_variance   | 0.318       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.5         |\n",
            "|    n_updates            | 120         |\n",
            "|    policy_gradient_loss | -0.000357   |\n",
            "|    std                  | 0.933       |\n",
            "|    value_loss           | 5.82        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 70\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1290016.61\n",
            "total_reward: 275673.65\n",
            "total_cost: 3277.26\n",
            "total_trades: 389\n",
            "Sharpe: 0.975\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 410         |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 69          |\n",
            "|    total_timesteps      | 28672       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001787947 |\n",
            "|    clip_fraction        | 0.0199      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.35       |\n",
            "|    explained_variance   | 0.41        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.21        |\n",
            "|    n_updates            | 130         |\n",
            "|    policy_gradient_loss | -0.00128    |\n",
            "|    std                  | 0.932       |\n",
            "|    value_loss           | 6.96        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 412         |\n",
            "|    iterations           | 15          |\n",
            "|    time_elapsed         | 74          |\n",
            "|    total_timesteps      | 30720       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004714548 |\n",
            "|    clip_fraction        | 0.0406      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.35       |\n",
            "|    explained_variance   | 0.615       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.52        |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | -0.00201    |\n",
            "|    std                  | 0.928       |\n",
            "|    value_loss           | 7.05        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 80\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1297692.61\n",
            "total_reward: 283349.65\n",
            "total_cost: 3398.19\n",
            "total_trades: 385\n",
            "Sharpe: 1.240\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 409          |\n",
            "|    iterations           | 16           |\n",
            "|    time_elapsed         | 79           |\n",
            "|    total_timesteps      | 32768        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0043679047 |\n",
            "|    clip_fraction        | 0.0232       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.34        |\n",
            "|    explained_variance   | 0.654        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.81         |\n",
            "|    n_updates            | 150          |\n",
            "|    policy_gradient_loss | -0.00143     |\n",
            "|    std                  | 0.914        |\n",
            "|    value_loss           | 7.48         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 411         |\n",
            "|    iterations           | 17          |\n",
            "|    time_elapsed         | 84          |\n",
            "|    total_timesteps      | 34816       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002724619 |\n",
            "|    clip_fraction        | 0.0167      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.33       |\n",
            "|    explained_variance   | 0.666       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.65        |\n",
            "|    n_updates            | 160         |\n",
            "|    policy_gradient_loss | -0.00143    |\n",
            "|    std                  | 0.908       |\n",
            "|    value_loss           | 8.66        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 90\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1283487.51\n",
            "total_reward: 269144.55\n",
            "total_cost: 2930.30\n",
            "total_trades: 388\n",
            "Sharpe: 0.945\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 411          |\n",
            "|    iterations           | 18           |\n",
            "|    time_elapsed         | 89           |\n",
            "|    total_timesteps      | 36864        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0055132587 |\n",
            "|    clip_fraction        | 0.0432       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.32        |\n",
            "|    explained_variance   | 0.684        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.03         |\n",
            "|    n_updates            | 170          |\n",
            "|    policy_gradient_loss | -0.00197     |\n",
            "|    std                  | 0.9          |\n",
            "|    value_loss           | 9.04         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 410          |\n",
            "|    iterations           | 19           |\n",
            "|    time_elapsed         | 94           |\n",
            "|    total_timesteps      | 38912        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022431095 |\n",
            "|    clip_fraction        | 0.0151       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.31        |\n",
            "|    explained_variance   | 0.678        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.95         |\n",
            "|    n_updates            | 180          |\n",
            "|    policy_gradient_loss | -0.00146     |\n",
            "|    std                  | 0.899        |\n",
            "|    value_loss           | 9.76         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 100\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1283862.61\n",
            "total_reward: 269519.65\n",
            "total_cost: 3232.44\n",
            "total_trades: 388\n",
            "Sharpe: 0.921\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 412          |\n",
            "|    iterations           | 20           |\n",
            "|    time_elapsed         | 99           |\n",
            "|    total_timesteps      | 40960        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042961626 |\n",
            "|    clip_fraction        | 0.0303       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.716        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.41         |\n",
            "|    n_updates            | 190          |\n",
            "|    policy_gradient_loss | -0.00215     |\n",
            "|    std                  | 0.888        |\n",
            "|    value_loss           | 9.2          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 410          |\n",
            "|    iterations           | 21           |\n",
            "|    time_elapsed         | 104          |\n",
            "|    total_timesteps      | 43008        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0062894956 |\n",
            "|    clip_fraction        | 0.0622       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.666        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6            |\n",
            "|    n_updates            | 200          |\n",
            "|    policy_gradient_loss | -0.00472     |\n",
            "|    std                  | 0.887        |\n",
            "|    value_loss           | 10.6         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 110\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1252807.25\n",
            "total_reward: 238464.29\n",
            "total_cost: 2789.79\n",
            "total_trades: 386\n",
            "Sharpe: 0.739\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 411          |\n",
            "|    iterations           | 22           |\n",
            "|    time_elapsed         | 109          |\n",
            "|    total_timesteps      | 45056        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017109932 |\n",
            "|    clip_fraction        | 0.0186       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.64         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.93         |\n",
            "|    n_updates            | 210          |\n",
            "|    policy_gradient_loss | -0.000812    |\n",
            "|    std                  | 0.885        |\n",
            "|    value_loss           | 11.2         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 120\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1228458.68\n",
            "total_reward: 214115.73\n",
            "total_cost: 2564.03\n",
            "total_trades: 389\n",
            "Sharpe: 0.667\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 412          |\n",
            "|    iterations           | 23           |\n",
            "|    time_elapsed         | 114          |\n",
            "|    total_timesteps      | 47104        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031370088 |\n",
            "|    clip_fraction        | 0.0212       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.624        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.68         |\n",
            "|    n_updates            | 220          |\n",
            "|    policy_gradient_loss | -0.00158     |\n",
            "|    std                  | 0.879        |\n",
            "|    value_loss           | 11.1         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 411          |\n",
            "|    iterations           | 24           |\n",
            "|    time_elapsed         | 119          |\n",
            "|    total_timesteps      | 49152        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032447886 |\n",
            "|    clip_fraction        | 0.0241       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.558        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.2          |\n",
            "|    n_updates            | 230          |\n",
            "|    policy_gradient_loss | -0.000971    |\n",
            "|    std                  | 0.882        |\n",
            "|    value_loss           | 11.1         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 130\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1247542.31\n",
            "total_reward: 233199.35\n",
            "total_cost: 3039.19\n",
            "total_trades: 389\n",
            "Sharpe: 0.749\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 412         |\n",
            "|    iterations           | 25          |\n",
            "|    time_elapsed         | 124         |\n",
            "|    total_timesteps      | 51200       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005512218 |\n",
            "|    clip_fraction        | 0.0448      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.29       |\n",
            "|    explained_variance   | 0.568       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.69        |\n",
            "|    n_updates            | 240         |\n",
            "|    policy_gradient_loss | -0.00113    |\n",
            "|    std                  | 0.872       |\n",
            "|    value_loss           | 11          |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 410         |\n",
            "|    iterations           | 26          |\n",
            "|    time_elapsed         | 129         |\n",
            "|    total_timesteps      | 53248       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002505812 |\n",
            "|    clip_fraction        | 0.0205      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.28       |\n",
            "|    explained_variance   | 0.546       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.96        |\n",
            "|    n_updates            | 250         |\n",
            "|    policy_gradient_loss | -0.00142    |\n",
            "|    std                  | 0.873       |\n",
            "|    value_loss           | 11.3        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 140\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1270785.62\n",
            "total_reward: 256442.66\n",
            "total_cost: 2862.13\n",
            "total_trades: 386\n",
            "Sharpe: 0.818\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 411         |\n",
            "|    iterations           | 27          |\n",
            "|    time_elapsed         | 134         |\n",
            "|    total_timesteps      | 55296       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003155088 |\n",
            "|    clip_fraction        | 0.0246      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.28       |\n",
            "|    explained_variance   | 0.63        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.71        |\n",
            "|    n_updates            | 260         |\n",
            "|    policy_gradient_loss | -0.00197    |\n",
            "|    std                  | 0.867       |\n",
            "|    value_loss           | 9.24        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 411         |\n",
            "|    iterations           | 28          |\n",
            "|    time_elapsed         | 139         |\n",
            "|    total_timesteps      | 57344       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006034213 |\n",
            "|    clip_fraction        | 0.0333      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.27       |\n",
            "|    explained_variance   | 0.591       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.59        |\n",
            "|    n_updates            | 270         |\n",
            "|    policy_gradient_loss | -0.0017     |\n",
            "|    std                  | 0.858       |\n",
            "|    value_loss           | 10.3        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 150\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1245180.50\n",
            "total_reward: 230837.54\n",
            "total_cost: 2508.40\n",
            "total_trades: 389\n",
            "Sharpe: 0.735\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 410         |\n",
            "|    iterations           | 29          |\n",
            "|    time_elapsed         | 144         |\n",
            "|    total_timesteps      | 59392       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005522497 |\n",
            "|    clip_fraction        | 0.0325      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.26       |\n",
            "|    explained_variance   | 0.559       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.83        |\n",
            "|    n_updates            | 280         |\n",
            "|    policy_gradient_loss | 0.000235    |\n",
            "|    std                  | 0.842       |\n",
            "|    value_loss           | 10.5        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 411         |\n",
            "|    iterations           | 30          |\n",
            "|    time_elapsed         | 149         |\n",
            "|    total_timesteps      | 61440       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003004686 |\n",
            "|    clip_fraction        | 0.0175      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.24       |\n",
            "|    explained_variance   | 0.532       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.6         |\n",
            "|    n_updates            | 290         |\n",
            "|    policy_gradient_loss | -0.000233   |\n",
            "|    std                  | 0.835       |\n",
            "|    value_loss           | 11.3        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 160\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1275443.44\n",
            "total_reward: 261100.48\n",
            "total_cost: 3001.27\n",
            "total_trades: 389\n",
            "Sharpe: 0.877\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 411          |\n",
            "|    iterations           | 31           |\n",
            "|    time_elapsed         | 154          |\n",
            "|    total_timesteps      | 63488        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026927388 |\n",
            "|    clip_fraction        | 0.0385       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.23        |\n",
            "|    explained_variance   | 0.601        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.59         |\n",
            "|    n_updates            | 300          |\n",
            "|    policy_gradient_loss | -0.00215     |\n",
            "|    std                  | 0.83         |\n",
            "|    value_loss           | 10.3         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 410          |\n",
            "|    iterations           | 32           |\n",
            "|    time_elapsed         | 159          |\n",
            "|    total_timesteps      | 65536        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032059916 |\n",
            "|    clip_fraction        | 0.0216       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.21        |\n",
            "|    explained_variance   | 0.681        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.27         |\n",
            "|    n_updates            | 310          |\n",
            "|    policy_gradient_loss | -0.00173     |\n",
            "|    std                  | 0.799        |\n",
            "|    value_loss           | 8.85         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 170\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1249078.77\n",
            "total_reward: 234735.81\n",
            "total_cost: 2524.30\n",
            "total_trades: 389\n",
            "Sharpe: 0.772\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 411          |\n",
            "|    iterations           | 33           |\n",
            "|    time_elapsed         | 164          |\n",
            "|    total_timesteps      | 67584        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023778677 |\n",
            "|    clip_fraction        | 0.0334       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.2         |\n",
            "|    explained_variance   | 0.698        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.5          |\n",
            "|    n_updates            | 320          |\n",
            "|    policy_gradient_loss | -0.000295    |\n",
            "|    std                  | 0.809        |\n",
            "|    value_loss           | 8.66         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 410          |\n",
            "|    iterations           | 34           |\n",
            "|    time_elapsed         | 169          |\n",
            "|    total_timesteps      | 69632        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026998934 |\n",
            "|    clip_fraction        | 0.0268       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.2         |\n",
            "|    explained_variance   | 0.697        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.54         |\n",
            "|    n_updates            | 330          |\n",
            "|    policy_gradient_loss | -0.000867    |\n",
            "|    std                  | 0.802        |\n",
            "|    value_loss           | 9.74         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 180\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1261477.17\n",
            "total_reward: 247134.21\n",
            "total_cost: 2649.97\n",
            "total_trades: 386\n",
            "Sharpe: 0.814\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 411        |\n",
            "|    iterations           | 35         |\n",
            "|    time_elapsed         | 174        |\n",
            "|    total_timesteps      | 71680      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00430891 |\n",
            "|    clip_fraction        | 0.0645     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.2       |\n",
            "|    explained_variance   | 0.7        |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 3.64       |\n",
            "|    n_updates            | 340        |\n",
            "|    policy_gradient_loss | -0.000763  |\n",
            "|    std                  | 0.8        |\n",
            "|    value_loss           | 9.6        |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 411          |\n",
            "|    iterations           | 36           |\n",
            "|    time_elapsed         | 179          |\n",
            "|    total_timesteps      | 73728        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046629426 |\n",
            "|    clip_fraction        | 0.0333       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.19        |\n",
            "|    explained_variance   | 0.609        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.56         |\n",
            "|    n_updates            | 350          |\n",
            "|    policy_gradient_loss | -0.00215     |\n",
            "|    std                  | 0.785        |\n",
            "|    value_loss           | 11.7         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 190\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1257346.97\n",
            "total_reward: 243004.01\n",
            "total_cost: 2690.12\n",
            "total_trades: 384\n",
            "Sharpe: 0.752\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 409         |\n",
            "|    iterations           | 37          |\n",
            "|    time_elapsed         | 185         |\n",
            "|    total_timesteps      | 75776       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004276785 |\n",
            "|    clip_fraction        | 0.0293      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.18       |\n",
            "|    explained_variance   | 0.587       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.03        |\n",
            "|    n_updates            | 360         |\n",
            "|    policy_gradient_loss | -1.53e-05   |\n",
            "|    std                  | 0.785       |\n",
            "|    value_loss           | 11.5        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 409         |\n",
            "|    iterations           | 38          |\n",
            "|    time_elapsed         | 189         |\n",
            "|    total_timesteps      | 77824       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001648762 |\n",
            "|    clip_fraction        | 0.0259      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.18       |\n",
            "|    explained_variance   | 0.595       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.22        |\n",
            "|    n_updates            | 370         |\n",
            "|    policy_gradient_loss | -0.00212    |\n",
            "|    std                  | 0.79        |\n",
            "|    value_loss           | 11.4        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 200\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1247866.96\n",
            "total_reward: 233524.00\n",
            "total_cost: 2405.00\n",
            "total_trades: 389\n",
            "Sharpe: 0.729\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 409          |\n",
            "|    iterations           | 39           |\n",
            "|    time_elapsed         | 195          |\n",
            "|    total_timesteps      | 79872        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021620905 |\n",
            "|    clip_fraction        | 0.0252       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.19        |\n",
            "|    explained_variance   | 0.509        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6            |\n",
            "|    n_updates            | 380          |\n",
            "|    policy_gradient_loss | 0.000118     |\n",
            "|    std                  | 0.791        |\n",
            "|    value_loss           | 11.8         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 409          |\n",
            "|    iterations           | 40           |\n",
            "|    time_elapsed         | 200          |\n",
            "|    total_timesteps      | 81920        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028605745 |\n",
            "|    clip_fraction        | 0.0284       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.17        |\n",
            "|    explained_variance   | 0.473        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.58         |\n",
            "|    n_updates            | 390          |\n",
            "|    policy_gradient_loss | -0.000608    |\n",
            "|    std                  | 0.773        |\n",
            "|    value_loss           | 11.7         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 210\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1241759.60\n",
            "total_reward: 227416.64\n",
            "total_cost: 2467.26\n",
            "total_trades: 391\n",
            "Sharpe: 0.699\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 410          |\n",
            "|    iterations           | 41           |\n",
            "|    time_elapsed         | 204          |\n",
            "|    total_timesteps      | 83968        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035406328 |\n",
            "|    clip_fraction        | 0.0258       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.16        |\n",
            "|    explained_variance   | 0.48         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.06         |\n",
            "|    n_updates            | 400          |\n",
            "|    policy_gradient_loss | -0.000998    |\n",
            "|    std                  | 0.772        |\n",
            "|    value_loss           | 11.1         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 409          |\n",
            "|    iterations           | 42           |\n",
            "|    time_elapsed         | 210          |\n",
            "|    total_timesteps      | 86016        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028669785 |\n",
            "|    clip_fraction        | 0.0259       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.15        |\n",
            "|    explained_variance   | 0.528        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.46         |\n",
            "|    n_updates            | 410          |\n",
            "|    policy_gradient_loss | -0.00104     |\n",
            "|    std                  | 0.758        |\n",
            "|    value_loss           | 10.6         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 220\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1249083.04\n",
            "total_reward: 234740.08\n",
            "total_cost: 2300.85\n",
            "total_trades: 387\n",
            "Sharpe: 0.730\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 409          |\n",
            "|    iterations           | 43           |\n",
            "|    time_elapsed         | 214          |\n",
            "|    total_timesteps      | 88064        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010055163 |\n",
            "|    clip_fraction        | 0.0198       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.14        |\n",
            "|    explained_variance   | 0.494        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.59         |\n",
            "|    n_updates            | 420          |\n",
            "|    policy_gradient_loss | 0.000284     |\n",
            "|    std                  | 0.756        |\n",
            "|    value_loss           | 11.4         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 410          |\n",
            "|    iterations           | 44           |\n",
            "|    time_elapsed         | 219          |\n",
            "|    total_timesteps      | 90112        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054046027 |\n",
            "|    clip_fraction        | 0.0315       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.14        |\n",
            "|    explained_variance   | 0.5          |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.27         |\n",
            "|    n_updates            | 430          |\n",
            "|    policy_gradient_loss | 0.000181     |\n",
            "|    std                  | 0.762        |\n",
            "|    value_loss           | 11.6         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 230\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1253237.41\n",
            "total_reward: 238894.45\n",
            "total_cost: 2349.69\n",
            "total_trades: 388\n",
            "Sharpe: 0.723\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 409          |\n",
            "|    iterations           | 45           |\n",
            "|    time_elapsed         | 224          |\n",
            "|    total_timesteps      | 92160        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026558484 |\n",
            "|    clip_fraction        | 0.0359       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.15        |\n",
            "|    explained_variance   | 0.446        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.19         |\n",
            "|    n_updates            | 440          |\n",
            "|    policy_gradient_loss | -0.00208     |\n",
            "|    std                  | 0.76         |\n",
            "|    value_loss           | 11.3         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 240\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1248144.61\n",
            "total_reward: 233801.65\n",
            "total_cost: 2222.30\n",
            "total_trades: 388\n",
            "Sharpe: 0.703\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 410         |\n",
            "|    iterations           | 46          |\n",
            "|    time_elapsed         | 229         |\n",
            "|    total_timesteps      | 94208       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002829641 |\n",
            "|    clip_fraction        | 0.0358      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.14       |\n",
            "|    explained_variance   | 0.39        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.52        |\n",
            "|    n_updates            | 450         |\n",
            "|    policy_gradient_loss | -0.000753   |\n",
            "|    std                  | 0.76        |\n",
            "|    value_loss           | 11.5        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 410          |\n",
            "|    iterations           | 47           |\n",
            "|    time_elapsed         | 234          |\n",
            "|    total_timesteps      | 96256        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0050825635 |\n",
            "|    clip_fraction        | 0.049        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.14        |\n",
            "|    explained_variance   | 0.326        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.6          |\n",
            "|    n_updates            | 460          |\n",
            "|    policy_gradient_loss | -0.00335     |\n",
            "|    std                  | 0.759        |\n",
            "|    value_loss           | 12.6         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 250\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1238456.87\n",
            "total_reward: 224113.91\n",
            "total_cost: 2088.88\n",
            "total_trades: 387\n",
            "Sharpe: 0.689\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 410         |\n",
            "|    iterations           | 48          |\n",
            "|    time_elapsed         | 239         |\n",
            "|    total_timesteps      | 98304       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005734128 |\n",
            "|    clip_fraction        | 0.0486      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.13       |\n",
            "|    explained_variance   | 0.272       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.77        |\n",
            "|    n_updates            | 470         |\n",
            "|    policy_gradient_loss | -0.00394    |\n",
            "|    std                  | 0.747       |\n",
            "|    value_loss           | 12.8        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 410        |\n",
            "|    iterations           | 49         |\n",
            "|    time_elapsed         | 244        |\n",
            "|    total_timesteps      | 100352     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00635505 |\n",
            "|    clip_fraction        | 0.0401     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.12      |\n",
            "|    explained_variance   | 0.265      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 4.54       |\n",
            "|    n_updates            | 480        |\n",
            "|    policy_gradient_loss | -0.00199   |\n",
            "|    std                  | 0.739      |\n",
            "|    value_loss           | 12.3       |\n",
            "----------------------------------------\n",
            "day: 391, episode: 260\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1241983.53\n",
            "total_reward: 227640.57\n",
            "total_cost: 2078.39\n",
            "total_trades: 388\n",
            "Sharpe: 0.688\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 409         |\n",
            "|    iterations           | 50          |\n",
            "|    time_elapsed         | 249         |\n",
            "|    total_timesteps      | 102400      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003671416 |\n",
            "|    clip_fraction        | 0.0399      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.11       |\n",
            "|    explained_variance   | 0.317       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.41        |\n",
            "|    n_updates            | 490         |\n",
            "|    policy_gradient_loss | -0.00216    |\n",
            "|    std                  | 0.736       |\n",
            "|    value_loss           | 11.5        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 410          |\n",
            "|    iterations           | 51           |\n",
            "|    time_elapsed         | 254          |\n",
            "|    total_timesteps      | 104448       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032854916 |\n",
            "|    clip_fraction        | 0.0337       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.11        |\n",
            "|    explained_variance   | 0.279        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.36         |\n",
            "|    n_updates            | 500          |\n",
            "|    policy_gradient_loss | -0.000126    |\n",
            "|    std                  | 0.734        |\n",
            "|    value_loss           | 11.9         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 270\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1249193.61\n",
            "total_reward: 234850.65\n",
            "total_cost: 2024.58\n",
            "total_trades: 386\n",
            "Sharpe: 0.702\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 410          |\n",
            "|    iterations           | 52           |\n",
            "|    time_elapsed         | 259          |\n",
            "|    total_timesteps      | 106496       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0051397667 |\n",
            "|    clip_fraction        | 0.0441       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.11        |\n",
            "|    explained_variance   | 0.244        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.54         |\n",
            "|    n_updates            | 510          |\n",
            "|    policy_gradient_loss | -0.00191     |\n",
            "|    std                  | 0.728        |\n",
            "|    value_loss           | 12.4         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 410          |\n",
            "|    iterations           | 53           |\n",
            "|    time_elapsed         | 264          |\n",
            "|    total_timesteps      | 108544       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039147777 |\n",
            "|    clip_fraction        | 0.034        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.09        |\n",
            "|    explained_variance   | 0.197        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.9          |\n",
            "|    n_updates            | 520          |\n",
            "|    policy_gradient_loss | -0.0026      |\n",
            "|    std                  | 0.719        |\n",
            "|    value_loss           | 12.9         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 280\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1268298.68\n",
            "total_reward: 253955.72\n",
            "total_cost: 2204.80\n",
            "total_trades: 391\n",
            "Sharpe: 0.740\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 410          |\n",
            "|    iterations           | 54           |\n",
            "|    time_elapsed         | 269          |\n",
            "|    total_timesteps      | 110592       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015735461 |\n",
            "|    clip_fraction        | 0.0212       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.08        |\n",
            "|    explained_variance   | 0.225        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.48         |\n",
            "|    n_updates            | 530          |\n",
            "|    policy_gradient_loss | 0.00095      |\n",
            "|    std                  | 0.709        |\n",
            "|    value_loss           | 12.2         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 410          |\n",
            "|    iterations           | 55           |\n",
            "|    time_elapsed         | 274          |\n",
            "|    total_timesteps      | 112640       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0049749212 |\n",
            "|    clip_fraction        | 0.0484       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.07        |\n",
            "|    explained_variance   | 0.12         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.02         |\n",
            "|    n_updates            | 540          |\n",
            "|    policy_gradient_loss | -0.00254     |\n",
            "|    std                  | 0.708        |\n",
            "|    value_loss           | 13           |\n",
            "------------------------------------------\n",
            "day: 391, episode: 290\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1243659.65\n",
            "total_reward: 229316.69\n",
            "total_cost: 2258.19\n",
            "total_trades: 387\n",
            "Sharpe: 0.691\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 410          |\n",
            "|    iterations           | 56           |\n",
            "|    time_elapsed         | 279          |\n",
            "|    total_timesteps      | 114688       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0056423554 |\n",
            "|    clip_fraction        | 0.0456       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.07        |\n",
            "|    explained_variance   | 0.108        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.17         |\n",
            "|    n_updates            | 550          |\n",
            "|    policy_gradient_loss | -0.00112     |\n",
            "|    std                  | 0.703        |\n",
            "|    value_loss           | 13.4         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 410          |\n",
            "|    iterations           | 57           |\n",
            "|    time_elapsed         | 284          |\n",
            "|    total_timesteps      | 116736       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010882914 |\n",
            "|    clip_fraction        | 0.0249       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.07        |\n",
            "|    explained_variance   | 0.108        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.45         |\n",
            "|    n_updates            | 560          |\n",
            "|    policy_gradient_loss | -0.00171     |\n",
            "|    std                  | 0.705        |\n",
            "|    value_loss           | 13.2         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 300\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1262535.74\n",
            "total_reward: 248192.78\n",
            "total_cost: 1951.34\n",
            "total_trades: 389\n",
            "Sharpe: 0.729\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 410          |\n",
            "|    iterations           | 58           |\n",
            "|    time_elapsed         | 289          |\n",
            "|    total_timesteps      | 118784       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0052390033 |\n",
            "|    clip_fraction        | 0.0505       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.06        |\n",
            "|    explained_variance   | 0.131        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.23         |\n",
            "|    n_updates            | 570          |\n",
            "|    policy_gradient_loss | -0.00423     |\n",
            "|    std                  | 0.697        |\n",
            "|    value_loss           | 13           |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 410         |\n",
            "|    iterations           | 59          |\n",
            "|    time_elapsed         | 294         |\n",
            "|    total_timesteps      | 120832      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006491242 |\n",
            "|    clip_fraction        | 0.0348      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.05       |\n",
            "|    explained_variance   | 0.107       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 8.16        |\n",
            "|    n_updates            | 580         |\n",
            "|    policy_gradient_loss | -0.00151    |\n",
            "|    std                  | 0.684       |\n",
            "|    value_loss           | 13          |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 310\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1259936.72\n",
            "total_reward: 245593.76\n",
            "total_cost: 1713.38\n",
            "total_trades: 389\n",
            "Sharpe: 0.723\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 410          |\n",
            "|    iterations           | 60           |\n",
            "|    time_elapsed         | 299          |\n",
            "|    total_timesteps      | 122880       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0053140963 |\n",
            "|    clip_fraction        | 0.0435       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.03        |\n",
            "|    explained_variance   | 0.0468       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.45         |\n",
            "|    n_updates            | 590          |\n",
            "|    policy_gradient_loss | -0.00215     |\n",
            "|    std                  | 0.678        |\n",
            "|    value_loss           | 13.6         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 410         |\n",
            "|    iterations           | 61          |\n",
            "|    time_elapsed         | 304         |\n",
            "|    total_timesteps      | 124928      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004823519 |\n",
            "|    clip_fraction        | 0.027       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.03       |\n",
            "|    explained_variance   | 0.0274      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 8.48        |\n",
            "|    n_updates            | 600         |\n",
            "|    policy_gradient_loss | -0.000213   |\n",
            "|    std                  | 0.671       |\n",
            "|    value_loss           | 14.1        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 320\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1259858.09\n",
            "total_reward: 245515.13\n",
            "total_cost: 1770.44\n",
            "total_trades: 389\n",
            "Sharpe: 0.725\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 410          |\n",
            "|    iterations           | 62           |\n",
            "|    time_elapsed         | 309          |\n",
            "|    total_timesteps      | 126976       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024546739 |\n",
            "|    clip_fraction        | 0.0189       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.02        |\n",
            "|    explained_variance   | 0.0225       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.91         |\n",
            "|    n_updates            | 610          |\n",
            "|    policy_gradient_loss | -0.0025      |\n",
            "|    std                  | 0.667        |\n",
            "|    value_loss           | 14.2         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 410         |\n",
            "|    iterations           | 63          |\n",
            "|    time_elapsed         | 314         |\n",
            "|    total_timesteps      | 129024      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002458177 |\n",
            "|    clip_fraction        | 0.0279      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.01       |\n",
            "|    explained_variance   | 0.0349      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.13        |\n",
            "|    n_updates            | 620         |\n",
            "|    policy_gradient_loss | 0.000515    |\n",
            "|    std                  | 0.661       |\n",
            "|    value_loss           | 13.7        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 330\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1261874.89\n",
            "total_reward: 247531.93\n",
            "total_cost: 2131.01\n",
            "total_trades: 383\n",
            "Sharpe: 0.728\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 410          |\n",
            "|    iterations           | 64           |\n",
            "|    time_elapsed         | 319          |\n",
            "|    total_timesteps      | 131072       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018857322 |\n",
            "|    clip_fraction        | 0.0339       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1           |\n",
            "|    explained_variance   | 0.029        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.18         |\n",
            "|    n_updates            | 630          |\n",
            "|    policy_gradient_loss | -0.00209     |\n",
            "|    std                  | 0.656        |\n",
            "|    value_loss           | 13.3         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 410         |\n",
            "|    iterations           | 65          |\n",
            "|    time_elapsed         | 324         |\n",
            "|    total_timesteps      | 133120      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004911754 |\n",
            "|    clip_fraction        | 0.0344      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1          |\n",
            "|    explained_variance   | 0.0371      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.38        |\n",
            "|    n_updates            | 640         |\n",
            "|    policy_gradient_loss | -0.000841   |\n",
            "|    std                  | 0.659       |\n",
            "|    value_loss           | 13.8        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 340\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1249534.88\n",
            "total_reward: 235191.92\n",
            "total_cost: 2017.50\n",
            "total_trades: 388\n",
            "Sharpe: 0.702\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 410         |\n",
            "|    iterations           | 66          |\n",
            "|    time_elapsed         | 329         |\n",
            "|    total_timesteps      | 135168      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003506186 |\n",
            "|    clip_fraction        | 0.0427      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.998      |\n",
            "|    explained_variance   | 0.112       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 8.85        |\n",
            "|    n_updates            | 650         |\n",
            "|    policy_gradient_loss | -0.000216   |\n",
            "|    std                  | 0.656       |\n",
            "|    value_loss           | 13.9        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 350\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1252859.56\n",
            "total_reward: 238516.60\n",
            "total_cost: 1964.32\n",
            "total_trades: 387\n",
            "Sharpe: 0.711\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 410          |\n",
            "|    iterations           | 67           |\n",
            "|    time_elapsed         | 334          |\n",
            "|    total_timesteps      | 137216       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016406863 |\n",
            "|    clip_fraction        | 0.0274       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.992       |\n",
            "|    explained_variance   | 0.0392       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.42         |\n",
            "|    n_updates            | 660          |\n",
            "|    policy_gradient_loss | -0.00106     |\n",
            "|    std                  | 0.651        |\n",
            "|    value_loss           | 13.7         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 410          |\n",
            "|    iterations           | 68           |\n",
            "|    time_elapsed         | 339          |\n",
            "|    total_timesteps      | 139264       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0060187047 |\n",
            "|    clip_fraction        | 0.0618       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.986       |\n",
            "|    explained_variance   | 0.0474       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.9          |\n",
            "|    n_updates            | 670          |\n",
            "|    policy_gradient_loss | -0.00515     |\n",
            "|    std                  | 0.645        |\n",
            "|    value_loss           | 13.4         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 360\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1248298.30\n",
            "total_reward: 233955.34\n",
            "total_cost: 2153.40\n",
            "total_trades: 387\n",
            "Sharpe: 0.700\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 410          |\n",
            "|    iterations           | 69           |\n",
            "|    time_elapsed         | 344          |\n",
            "|    total_timesteps      | 141312       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017332232 |\n",
            "|    clip_fraction        | 0.0188       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.98        |\n",
            "|    explained_variance   | 0.0382       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.22         |\n",
            "|    n_updates            | 680          |\n",
            "|    policy_gradient_loss | -0.000427    |\n",
            "|    std                  | 0.646        |\n",
            "|    value_loss           | 13.7         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 410          |\n",
            "|    iterations           | 70           |\n",
            "|    time_elapsed         | 349          |\n",
            "|    total_timesteps      | 143360       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032928865 |\n",
            "|    clip_fraction        | 0.0268       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.982       |\n",
            "|    explained_variance   | 0.0249       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.14         |\n",
            "|    n_updates            | 690          |\n",
            "|    policy_gradient_loss | -0.000964    |\n",
            "|    std                  | 0.645        |\n",
            "|    value_loss           | 13.9         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 370\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1248401.36\n",
            "total_reward: 234058.40\n",
            "total_cost: 2127.59\n",
            "total_trades: 387\n",
            "Sharpe: 0.698\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 409          |\n",
            "|    iterations           | 71           |\n",
            "|    time_elapsed         | 354          |\n",
            "|    total_timesteps      | 145408       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030965975 |\n",
            "|    clip_fraction        | 0.0376       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.981       |\n",
            "|    explained_variance   | 0.0103       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.91         |\n",
            "|    n_updates            | 700          |\n",
            "|    policy_gradient_loss | -0.00171     |\n",
            "|    std                  | 0.645        |\n",
            "|    value_loss           | 14.2         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 410          |\n",
            "|    iterations           | 72           |\n",
            "|    time_elapsed         | 359          |\n",
            "|    total_timesteps      | 147456       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0050628204 |\n",
            "|    clip_fraction        | 0.0445       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.974       |\n",
            "|    explained_variance   | 0.00641      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.02         |\n",
            "|    n_updates            | 710          |\n",
            "|    policy_gradient_loss | -0.0021      |\n",
            "|    std                  | 0.638        |\n",
            "|    value_loss           | 13.9         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 380\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1244359.29\n",
            "total_reward: 230016.33\n",
            "total_cost: 2124.58\n",
            "total_trades: 389\n",
            "Sharpe: 0.691\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 410         |\n",
            "|    iterations           | 73          |\n",
            "|    time_elapsed         | 364         |\n",
            "|    total_timesteps      | 149504      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005435466 |\n",
            "|    clip_fraction        | 0.0663      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.96       |\n",
            "|    explained_variance   | 0.00522     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.23        |\n",
            "|    n_updates            | 720         |\n",
            "|    policy_gradient_loss | -0.00396    |\n",
            "|    std                  | 0.627       |\n",
            "|    value_loss           | 13.9        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 410         |\n",
            "|    iterations           | 74          |\n",
            "|    time_elapsed         | 369         |\n",
            "|    total_timesteps      | 151552      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005732055 |\n",
            "|    clip_fraction        | 0.0512      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.945      |\n",
            "|    explained_variance   | 0.0225      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.37        |\n",
            "|    n_updates            | 730         |\n",
            "|    policy_gradient_loss | -0.00237    |\n",
            "|    std                  | 0.62        |\n",
            "|    value_loss           | 14.5        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 390\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1260442.73\n",
            "total_reward: 246099.77\n",
            "total_cost: 2009.33\n",
            "total_trades: 388\n",
            "Sharpe: 0.724\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 410          |\n",
            "|    iterations           | 75           |\n",
            "|    time_elapsed         | 374          |\n",
            "|    total_timesteps      | 153600       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0057249945 |\n",
            "|    clip_fraction        | 0.0439       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.938       |\n",
            "|    explained_variance   | 0.0349       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.62         |\n",
            "|    n_updates            | 740          |\n",
            "|    policy_gradient_loss | 0.000275     |\n",
            "|    std                  | 0.618        |\n",
            "|    value_loss           | 14           |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 409          |\n",
            "|    iterations           | 76           |\n",
            "|    time_elapsed         | 379          |\n",
            "|    total_timesteps      | 155648       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033813117 |\n",
            "|    clip_fraction        | 0.0313       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.935       |\n",
            "|    explained_variance   | 0.0157       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.24         |\n",
            "|    n_updates            | 750          |\n",
            "|    policy_gradient_loss | -0.00026     |\n",
            "|    std                  | 0.614        |\n",
            "|    value_loss           | 14           |\n",
            "------------------------------------------\n",
            "day: 391, episode: 400\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1264444.96\n",
            "total_reward: 250102.00\n",
            "total_cost: 2114.57\n",
            "total_trades: 387\n",
            "Sharpe: 0.733\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 410         |\n",
            "|    iterations           | 77          |\n",
            "|    time_elapsed         | 384         |\n",
            "|    total_timesteps      | 157696      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003419357 |\n",
            "|    clip_fraction        | 0.0542      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.932      |\n",
            "|    explained_variance   | 0.0142      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.99        |\n",
            "|    n_updates            | 760         |\n",
            "|    policy_gradient_loss | 0.000308    |\n",
            "|    std                  | 0.616       |\n",
            "|    value_loss           | 13.7        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 410          |\n",
            "|    iterations           | 78           |\n",
            "|    time_elapsed         | 389          |\n",
            "|    total_timesteps      | 159744       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022691824 |\n",
            "|    clip_fraction        | 0.0239       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.937       |\n",
            "|    explained_variance   | 0.0234       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.88         |\n",
            "|    n_updates            | 770          |\n",
            "|    policy_gradient_loss | 0.00106      |\n",
            "|    std                  | 0.618        |\n",
            "|    value_loss           | 14           |\n",
            "------------------------------------------\n",
            "day: 391, episode: 410\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1262093.76\n",
            "total_reward: 247750.80\n",
            "total_cost: 2366.73\n",
            "total_trades: 386\n",
            "Sharpe: 0.730\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 410         |\n",
            "|    iterations           | 79          |\n",
            "|    time_elapsed         | 394         |\n",
            "|    total_timesteps      | 161792      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005771707 |\n",
            "|    clip_fraction        | 0.0302      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.935      |\n",
            "|    explained_variance   | 0.031       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.18        |\n",
            "|    n_updates            | 780         |\n",
            "|    policy_gradient_loss | -0.00131    |\n",
            "|    std                  | 0.612       |\n",
            "|    value_loss           | 13.9        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 410          |\n",
            "|    iterations           | 80           |\n",
            "|    time_elapsed         | 399          |\n",
            "|    total_timesteps      | 163840       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027626571 |\n",
            "|    clip_fraction        | 0.0333       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.934       |\n",
            "|    explained_variance   | 0.0556       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.35         |\n",
            "|    n_updates            | 790          |\n",
            "|    policy_gradient_loss | 1.94e-05     |\n",
            "|    std                  | 0.619        |\n",
            "|    value_loss           | 13.5         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 420\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1250868.36\n",
            "total_reward: 236525.40\n",
            "total_cost: 2454.31\n",
            "total_trades: 388\n",
            "Sharpe: 0.708\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 410         |\n",
            "|    iterations           | 81          |\n",
            "|    time_elapsed         | 404         |\n",
            "|    total_timesteps      | 165888      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007820324 |\n",
            "|    clip_fraction        | 0.0458      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.943      |\n",
            "|    explained_variance   | 0.0406      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.12        |\n",
            "|    n_updates            | 800         |\n",
            "|    policy_gradient_loss | -0.00312    |\n",
            "|    std                  | 0.624       |\n",
            "|    value_loss           | 13.5        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 410          |\n",
            "|    iterations           | 82           |\n",
            "|    time_elapsed         | 409          |\n",
            "|    total_timesteps      | 167936       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042034667 |\n",
            "|    clip_fraction        | 0.0561       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.945       |\n",
            "|    explained_variance   | 0.0359       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.77         |\n",
            "|    n_updates            | 810          |\n",
            "|    policy_gradient_loss | -0.00288     |\n",
            "|    std                  | 0.622        |\n",
            "|    value_loss           | 13.4         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 430\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1240476.48\n",
            "total_reward: 226133.52\n",
            "total_cost: 2728.61\n",
            "total_trades: 386\n",
            "Sharpe: 0.688\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 410          |\n",
            "|    iterations           | 83           |\n",
            "|    time_elapsed         | 413          |\n",
            "|    total_timesteps      | 169984       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0053721895 |\n",
            "|    clip_fraction        | 0.0762       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.937       |\n",
            "|    explained_variance   | 0.0477       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.91         |\n",
            "|    n_updates            | 820          |\n",
            "|    policy_gradient_loss | -0.00297     |\n",
            "|    std                  | 0.615        |\n",
            "|    value_loss           | 13.8         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 410         |\n",
            "|    iterations           | 84          |\n",
            "|    time_elapsed         | 419         |\n",
            "|    total_timesteps      | 172032      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004250833 |\n",
            "|    clip_fraction        | 0.0286      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.927      |\n",
            "|    explained_variance   | 0.0764      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.42        |\n",
            "|    n_updates            | 830         |\n",
            "|    policy_gradient_loss | -0.0017     |\n",
            "|    std                  | 0.608       |\n",
            "|    value_loss           | 13.3        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 440\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1223565.99\n",
            "total_reward: 209223.03\n",
            "total_cost: 2749.51\n",
            "total_trades: 386\n",
            "Sharpe: 0.653\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 410         |\n",
            "|    iterations           | 85          |\n",
            "|    time_elapsed         | 424         |\n",
            "|    total_timesteps      | 174080      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004574561 |\n",
            "|    clip_fraction        | 0.0312      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.913      |\n",
            "|    explained_variance   | 0.149       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.34        |\n",
            "|    n_updates            | 840         |\n",
            "|    policy_gradient_loss | -0.001      |\n",
            "|    std                  | 0.599       |\n",
            "|    value_loss           | 12          |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 410          |\n",
            "|    iterations           | 86           |\n",
            "|    time_elapsed         | 428          |\n",
            "|    total_timesteps      | 176128       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032893284 |\n",
            "|    clip_fraction        | 0.0377       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.902       |\n",
            "|    explained_variance   | 0.245        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.69         |\n",
            "|    n_updates            | 850          |\n",
            "|    policy_gradient_loss | -0.000772    |\n",
            "|    std                  | 0.595        |\n",
            "|    value_loss           | 11.2         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 450\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1243237.14\n",
            "total_reward: 228894.18\n",
            "total_cost: 2503.90\n",
            "total_trades: 382\n",
            "Sharpe: 0.697\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 410       |\n",
            "|    iterations           | 87        |\n",
            "|    time_elapsed         | 434       |\n",
            "|    total_timesteps      | 178176    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0045576 |\n",
            "|    clip_fraction        | 0.0301    |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -0.894    |\n",
            "|    explained_variance   | 0.285     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 5.62      |\n",
            "|    n_updates            | 860       |\n",
            "|    policy_gradient_loss | -0.000455 |\n",
            "|    std                  | 0.589     |\n",
            "|    value_loss           | 12        |\n",
            "---------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 410          |\n",
            "|    iterations           | 88           |\n",
            "|    time_elapsed         | 439          |\n",
            "|    total_timesteps      | 180224       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042307675 |\n",
            "|    clip_fraction        | 0.0264       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.884       |\n",
            "|    explained_variance   | 0.306        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.23         |\n",
            "|    n_updates            | 870          |\n",
            "|    policy_gradient_loss | -0.000388    |\n",
            "|    std                  | 0.584        |\n",
            "|    value_loss           | 12.1         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 460\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1244891.43\n",
            "total_reward: 230548.47\n",
            "total_cost: 2572.61\n",
            "total_trades: 386\n",
            "Sharpe: 0.708\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 410         |\n",
            "|    iterations           | 89          |\n",
            "|    time_elapsed         | 444         |\n",
            "|    total_timesteps      | 182272      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004445152 |\n",
            "|    clip_fraction        | 0.0304      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.874      |\n",
            "|    explained_variance   | 0.384       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.34        |\n",
            "|    n_updates            | 880         |\n",
            "|    policy_gradient_loss | -0.000645   |\n",
            "|    std                  | 0.576       |\n",
            "|    value_loss           | 11.1        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 470\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1240227.93\n",
            "total_reward: 225884.97\n",
            "total_cost: 2697.09\n",
            "total_trades: 389\n",
            "Sharpe: 0.686\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 410          |\n",
            "|    iterations           | 90           |\n",
            "|    time_elapsed         | 449          |\n",
            "|    total_timesteps      | 184320       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046536233 |\n",
            "|    clip_fraction        | 0.0368       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.873       |\n",
            "|    explained_variance   | 0.394        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.47         |\n",
            "|    n_updates            | 890          |\n",
            "|    policy_gradient_loss | -0.00172     |\n",
            "|    std                  | 0.578        |\n",
            "|    value_loss           | 11.2         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 410         |\n",
            "|    iterations           | 91          |\n",
            "|    time_elapsed         | 453         |\n",
            "|    total_timesteps      | 186368      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008395394 |\n",
            "|    clip_fraction        | 0.0708      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.869      |\n",
            "|    explained_variance   | 0.378       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.36        |\n",
            "|    n_updates            | 900         |\n",
            "|    policy_gradient_loss | -0.00318    |\n",
            "|    std                  | 0.576       |\n",
            "|    value_loss           | 11.3        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 480\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1248005.48\n",
            "total_reward: 233662.52\n",
            "total_cost: 2446.43\n",
            "total_trades: 387\n",
            "Sharpe: 0.707\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 410          |\n",
            "|    iterations           | 92           |\n",
            "|    time_elapsed         | 459          |\n",
            "|    total_timesteps      | 188416       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0070146136 |\n",
            "|    clip_fraction        | 0.0674       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.865       |\n",
            "|    explained_variance   | 0.457        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.41         |\n",
            "|    n_updates            | 910          |\n",
            "|    policy_gradient_loss | -0.00413     |\n",
            "|    std                  | 0.575        |\n",
            "|    value_loss           | 11           |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 410          |\n",
            "|    iterations           | 93           |\n",
            "|    time_elapsed         | 463          |\n",
            "|    total_timesteps      | 190464       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034059386 |\n",
            "|    clip_fraction        | 0.0358       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.855       |\n",
            "|    explained_variance   | 0.459        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.53         |\n",
            "|    n_updates            | 920          |\n",
            "|    policy_gradient_loss | 0.000181     |\n",
            "|    std                  | 0.563        |\n",
            "|    value_loss           | 11.6         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 490\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1243100.44\n",
            "total_reward: 228757.48\n",
            "total_cost: 2515.30\n",
            "total_trades: 389\n",
            "Sharpe: 0.704\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 410         |\n",
            "|    iterations           | 94          |\n",
            "|    time_elapsed         | 468         |\n",
            "|    total_timesteps      | 192512      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007007422 |\n",
            "|    clip_fraction        | 0.0448      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.837      |\n",
            "|    explained_variance   | 0.5         |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.1         |\n",
            "|    n_updates            | 930         |\n",
            "|    policy_gradient_loss | -0.00147    |\n",
            "|    std                  | 0.554       |\n",
            "|    value_loss           | 10.7        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 410         |\n",
            "|    iterations           | 95          |\n",
            "|    time_elapsed         | 474         |\n",
            "|    total_timesteps      | 194560      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008154387 |\n",
            "|    clip_fraction        | 0.0495      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.83       |\n",
            "|    explained_variance   | 0.511       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.72        |\n",
            "|    n_updates            | 940         |\n",
            "|    policy_gradient_loss | 0.000184    |\n",
            "|    std                  | 0.554       |\n",
            "|    value_loss           | 10.8        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 500\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1234847.73\n",
            "total_reward: 220504.77\n",
            "total_cost: 2576.06\n",
            "total_trades: 386\n",
            "Sharpe: 0.677\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 410          |\n",
            "|    iterations           | 96           |\n",
            "|    time_elapsed         | 478          |\n",
            "|    total_timesteps      | 196608       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0078070043 |\n",
            "|    clip_fraction        | 0.0641       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.828       |\n",
            "|    explained_variance   | 0.471        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.71         |\n",
            "|    n_updates            | 950          |\n",
            "|    policy_gradient_loss | -0.000928    |\n",
            "|    std                  | 0.554        |\n",
            "|    value_loss           | 11.5         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 410         |\n",
            "|    iterations           | 97          |\n",
            "|    time_elapsed         | 484         |\n",
            "|    total_timesteps      | 198656      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004582964 |\n",
            "|    clip_fraction        | 0.0374      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.825      |\n",
            "|    explained_variance   | 0.376       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.22        |\n",
            "|    n_updates            | 960         |\n",
            "|    policy_gradient_loss | -0.00158    |\n",
            "|    std                  | 0.552       |\n",
            "|    value_loss           | 12          |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 510\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1239145.97\n",
            "total_reward: 224803.01\n",
            "total_cost: 2516.30\n",
            "total_trades: 389\n",
            "Sharpe: 0.696\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 410         |\n",
            "|    iterations           | 98          |\n",
            "|    time_elapsed         | 489         |\n",
            "|    total_timesteps      | 200704      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005543167 |\n",
            "|    clip_fraction        | 0.0521      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.825      |\n",
            "|    explained_variance   | 0.438       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.63        |\n",
            "|    n_updates            | 970         |\n",
            "|    policy_gradient_loss | -0.00129    |\n",
            "|    std                  | 0.552       |\n",
            "|    value_loss           | 11.2        |\n",
            "-----------------------------------------\n",
            "\n",
            "Training RefPaper Agent…\n",
            "Using cuda device\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/policies.py:486: UserWarning: As shared layers in the mlp_extractor are removed since SB3 v1.8.0, you should now pass directly a dictionary and not a list (net_arch=dict(pi=..., vf=...) instead of net_arch=[dict(pi=..., vf=...)])\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 630  |\n",
            "|    iterations      | 1    |\n",
            "|    time_elapsed    | 3    |\n",
            "|    total_timesteps | 2048 |\n",
            "-----------------------------\n",
            "day: 391, episode: 10\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1047200.94\n",
            "total_reward: 32857.98\n",
            "total_cost: 3850.27\n",
            "total_trades: 386\n",
            "Sharpe: 0.517\n",
            "=================================\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 470           |\n",
            "|    iterations           | 2             |\n",
            "|    time_elapsed         | 8             |\n",
            "|    total_timesteps      | 4096          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00043162014 |\n",
            "|    clip_fraction        | 0.0108        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.42         |\n",
            "|    explained_variance   | -0.0194       |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 0.244         |\n",
            "|    n_updates            | 10            |\n",
            "|    policy_gradient_loss | -0.000242     |\n",
            "|    std                  | 1.01          |\n",
            "|    value_loss           | 0.749         |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 458         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 13          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003442506 |\n",
            "|    clip_fraction        | 0.0195      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.43       |\n",
            "|    explained_variance   | -0.00181    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.339       |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.00097    |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 0.527       |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 20\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1014782.29\n",
            "total_reward: 439.33\n",
            "total_cost: 2991.83\n",
            "total_trades: 333\n",
            "Sharpe: 0.026\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 445         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 18          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005402279 |\n",
            "|    clip_fraction        | 0.0313      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.43       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.17        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.00195    |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 0.231       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 435         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 23          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003608014 |\n",
            "|    clip_fraction        | 0.016       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.42       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0143      |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.000929   |\n",
            "|    std                  | 0.999       |\n",
            "|    value_loss           | 0.052       |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 30\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1007801.90\n",
            "total_reward: -6541.06\n",
            "total_cost: 3539.54\n",
            "total_trades: 381\n",
            "Sharpe: -0.118\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 435          |\n",
            "|    iterations           | 6            |\n",
            "|    time_elapsed         | 28           |\n",
            "|    total_timesteps      | 12288        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0075070364 |\n",
            "|    clip_fraction        | 0.037        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0382       |\n",
            "|    n_updates            | 50           |\n",
            "|    policy_gradient_loss | -0.00335     |\n",
            "|    std                  | 0.979        |\n",
            "|    value_loss           | 0.0757       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 425          |\n",
            "|    iterations           | 7            |\n",
            "|    time_elapsed         | 33           |\n",
            "|    total_timesteps      | 14336        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011230812 |\n",
            "|    clip_fraction        | 0.000586     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.39        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.401        |\n",
            "|    n_updates            | 60           |\n",
            "|    policy_gradient_loss | -0.00016     |\n",
            "|    std                  | 0.963        |\n",
            "|    value_loss           | 0.683        |\n",
            "------------------------------------------\n",
            "day: 391, episode: 40\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1143296.94\n",
            "total_reward: 128953.98\n",
            "total_cost: 3437.13\n",
            "total_trades: 389\n",
            "Sharpe: 0.980\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 427         |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 38          |\n",
            "|    total_timesteps      | 16384       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007200155 |\n",
            "|    clip_fraction        | 0.0751      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.37       |\n",
            "|    explained_variance   | 0.000672    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.284       |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.00488    |\n",
            "|    std                  | 0.95        |\n",
            "|    value_loss           | 0.745       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 428         |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 43          |\n",
            "|    total_timesteps      | 18432       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002705615 |\n",
            "|    clip_fraction        | 0.00288     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.36       |\n",
            "|    explained_variance   | 0.0105      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.96        |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.000349   |\n",
            "|    std                  | 0.942       |\n",
            "|    value_loss           | 2.1         |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 50\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1300222.66\n",
            "total_reward: 285879.70\n",
            "total_cost: 3640.78\n",
            "total_trades: 389\n",
            "Sharpe: 1.215\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 422          |\n",
            "|    iterations           | 10           |\n",
            "|    time_elapsed         | 48           |\n",
            "|    total_timesteps      | 20480        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038957838 |\n",
            "|    clip_fraction        | 0.03         |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.35        |\n",
            "|    explained_variance   | 0.00502      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.734        |\n",
            "|    n_updates            | 90           |\n",
            "|    policy_gradient_loss | -0.0019      |\n",
            "|    std                  | 0.933        |\n",
            "|    value_loss           | 1.21         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 424         |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 53          |\n",
            "|    total_timesteps      | 22528       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003198679 |\n",
            "|    clip_fraction        | 0.0206      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.35       |\n",
            "|    explained_variance   | -0.0248     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.784       |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.00164    |\n",
            "|    std                  | 0.94        |\n",
            "|    value_loss           | 2.66        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 60\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1290636.70\n",
            "total_reward: 276293.74\n",
            "total_cost: 3520.19\n",
            "total_trades: 388\n",
            "Sharpe: 1.175\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 417          |\n",
            "|    iterations           | 12           |\n",
            "|    time_elapsed         | 58           |\n",
            "|    total_timesteps      | 24576        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012094651 |\n",
            "|    clip_fraction        | 0.0112       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.35        |\n",
            "|    explained_variance   | 0.152        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2            |\n",
            "|    n_updates            | 110          |\n",
            "|    policy_gradient_loss | -0.00132     |\n",
            "|    std                  | 0.931        |\n",
            "|    value_loss           | 5.27         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 418         |\n",
            "|    iterations           | 13          |\n",
            "|    time_elapsed         | 63          |\n",
            "|    total_timesteps      | 26624       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003283367 |\n",
            "|    clip_fraction        | 0.0168      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.35       |\n",
            "|    explained_variance   | 0.318       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.5         |\n",
            "|    n_updates            | 120         |\n",
            "|    policy_gradient_loss | -0.000357   |\n",
            "|    std                  | 0.933       |\n",
            "|    value_loss           | 5.82        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 70\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1290016.61\n",
            "total_reward: 275673.65\n",
            "total_cost: 3277.26\n",
            "total_trades: 389\n",
            "Sharpe: 0.975\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 419         |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 68          |\n",
            "|    total_timesteps      | 28672       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001787947 |\n",
            "|    clip_fraction        | 0.0199      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.35       |\n",
            "|    explained_variance   | 0.41        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.21        |\n",
            "|    n_updates            | 130         |\n",
            "|    policy_gradient_loss | -0.00128    |\n",
            "|    std                  | 0.932       |\n",
            "|    value_loss           | 6.96        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 15          |\n",
            "|    time_elapsed         | 73          |\n",
            "|    total_timesteps      | 30720       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004714548 |\n",
            "|    clip_fraction        | 0.0406      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.35       |\n",
            "|    explained_variance   | 0.615       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.52        |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | -0.00201    |\n",
            "|    std                  | 0.928       |\n",
            "|    value_loss           | 7.05        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 80\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1297692.61\n",
            "total_reward: 283349.65\n",
            "total_cost: 3398.19\n",
            "total_trades: 385\n",
            "Sharpe: 1.240\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 416          |\n",
            "|    iterations           | 16           |\n",
            "|    time_elapsed         | 78           |\n",
            "|    total_timesteps      | 32768        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0043679047 |\n",
            "|    clip_fraction        | 0.0232       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.34        |\n",
            "|    explained_variance   | 0.654        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.81         |\n",
            "|    n_updates            | 150          |\n",
            "|    policy_gradient_loss | -0.00143     |\n",
            "|    std                  | 0.914        |\n",
            "|    value_loss           | 7.48         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 417         |\n",
            "|    iterations           | 17          |\n",
            "|    time_elapsed         | 83          |\n",
            "|    total_timesteps      | 34816       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002724619 |\n",
            "|    clip_fraction        | 0.0167      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.33       |\n",
            "|    explained_variance   | 0.666       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.65        |\n",
            "|    n_updates            | 160         |\n",
            "|    policy_gradient_loss | -0.00143    |\n",
            "|    std                  | 0.908       |\n",
            "|    value_loss           | 8.66        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 90\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1283487.51\n",
            "total_reward: 269144.55\n",
            "total_cost: 2930.30\n",
            "total_trades: 388\n",
            "Sharpe: 0.945\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 18           |\n",
            "|    time_elapsed         | 88           |\n",
            "|    total_timesteps      | 36864        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0055132587 |\n",
            "|    clip_fraction        | 0.0432       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.32        |\n",
            "|    explained_variance   | 0.684        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.03         |\n",
            "|    n_updates            | 170          |\n",
            "|    policy_gradient_loss | -0.00197     |\n",
            "|    std                  | 0.9          |\n",
            "|    value_loss           | 9.04         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 417          |\n",
            "|    iterations           | 19           |\n",
            "|    time_elapsed         | 93           |\n",
            "|    total_timesteps      | 38912        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022431095 |\n",
            "|    clip_fraction        | 0.0151       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.31        |\n",
            "|    explained_variance   | 0.678        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.95         |\n",
            "|    n_updates            | 180          |\n",
            "|    policy_gradient_loss | -0.00146     |\n",
            "|    std                  | 0.899        |\n",
            "|    value_loss           | 9.76         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 100\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1283862.61\n",
            "total_reward: 269519.65\n",
            "total_cost: 3232.44\n",
            "total_trades: 388\n",
            "Sharpe: 0.921\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 414          |\n",
            "|    iterations           | 20           |\n",
            "|    time_elapsed         | 98           |\n",
            "|    total_timesteps      | 40960        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042961626 |\n",
            "|    clip_fraction        | 0.0303       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.716        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.41         |\n",
            "|    n_updates            | 190          |\n",
            "|    policy_gradient_loss | -0.00215     |\n",
            "|    std                  | 0.888        |\n",
            "|    value_loss           | 9.2          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 21           |\n",
            "|    time_elapsed         | 103          |\n",
            "|    total_timesteps      | 43008        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0062894956 |\n",
            "|    clip_fraction        | 0.0622       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.666        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6            |\n",
            "|    n_updates            | 200          |\n",
            "|    policy_gradient_loss | -0.00472     |\n",
            "|    std                  | 0.887        |\n",
            "|    value_loss           | 10.6         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 110\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1252807.25\n",
            "total_reward: 238464.29\n",
            "total_cost: 2789.79\n",
            "total_trades: 386\n",
            "Sharpe: 0.739\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 416          |\n",
            "|    iterations           | 22           |\n",
            "|    time_elapsed         | 108          |\n",
            "|    total_timesteps      | 45056        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017109932 |\n",
            "|    clip_fraction        | 0.0186       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.64         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.93         |\n",
            "|    n_updates            | 210          |\n",
            "|    policy_gradient_loss | -0.000812    |\n",
            "|    std                  | 0.885        |\n",
            "|    value_loss           | 11.2         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 120\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1228458.68\n",
            "total_reward: 214115.73\n",
            "total_cost: 2564.03\n",
            "total_trades: 389\n",
            "Sharpe: 0.667\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 414          |\n",
            "|    iterations           | 23           |\n",
            "|    time_elapsed         | 113          |\n",
            "|    total_timesteps      | 47104        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031370088 |\n",
            "|    clip_fraction        | 0.0212       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.624        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.68         |\n",
            "|    n_updates            | 220          |\n",
            "|    policy_gradient_loss | -0.00158     |\n",
            "|    std                  | 0.879        |\n",
            "|    value_loss           | 11.1         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 24           |\n",
            "|    time_elapsed         | 118          |\n",
            "|    total_timesteps      | 49152        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032447886 |\n",
            "|    clip_fraction        | 0.0241       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.558        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.2          |\n",
            "|    n_updates            | 230          |\n",
            "|    policy_gradient_loss | -0.000971    |\n",
            "|    std                  | 0.882        |\n",
            "|    value_loss           | 11.1         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 130\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1247542.31\n",
            "total_reward: 233199.35\n",
            "total_cost: 3039.19\n",
            "total_trades: 389\n",
            "Sharpe: 0.749\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 25          |\n",
            "|    time_elapsed         | 123         |\n",
            "|    total_timesteps      | 51200       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005512218 |\n",
            "|    clip_fraction        | 0.0448      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.29       |\n",
            "|    explained_variance   | 0.568       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.69        |\n",
            "|    n_updates            | 240         |\n",
            "|    policy_gradient_loss | -0.00113    |\n",
            "|    std                  | 0.872       |\n",
            "|    value_loss           | 11          |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 414         |\n",
            "|    iterations           | 26          |\n",
            "|    time_elapsed         | 128         |\n",
            "|    total_timesteps      | 53248       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002505812 |\n",
            "|    clip_fraction        | 0.0205      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.28       |\n",
            "|    explained_variance   | 0.546       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.96        |\n",
            "|    n_updates            | 250         |\n",
            "|    policy_gradient_loss | -0.00142    |\n",
            "|    std                  | 0.873       |\n",
            "|    value_loss           | 11.3        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 140\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1270785.62\n",
            "total_reward: 256442.66\n",
            "total_cost: 2862.13\n",
            "total_trades: 386\n",
            "Sharpe: 0.818\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 27          |\n",
            "|    time_elapsed         | 133         |\n",
            "|    total_timesteps      | 55296       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003155088 |\n",
            "|    clip_fraction        | 0.0246      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.28       |\n",
            "|    explained_variance   | 0.63        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.71        |\n",
            "|    n_updates            | 260         |\n",
            "|    policy_gradient_loss | -0.00197    |\n",
            "|    std                  | 0.867       |\n",
            "|    value_loss           | 9.24        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 414         |\n",
            "|    iterations           | 28          |\n",
            "|    time_elapsed         | 138         |\n",
            "|    total_timesteps      | 57344       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006034213 |\n",
            "|    clip_fraction        | 0.0333      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.27       |\n",
            "|    explained_variance   | 0.591       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.59        |\n",
            "|    n_updates            | 270         |\n",
            "|    policy_gradient_loss | -0.0017     |\n",
            "|    std                  | 0.858       |\n",
            "|    value_loss           | 10.3        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 150\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1245180.50\n",
            "total_reward: 230837.54\n",
            "total_cost: 2508.40\n",
            "total_trades: 389\n",
            "Sharpe: 0.735\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 414         |\n",
            "|    iterations           | 29          |\n",
            "|    time_elapsed         | 143         |\n",
            "|    total_timesteps      | 59392       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005522497 |\n",
            "|    clip_fraction        | 0.0325      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.26       |\n",
            "|    explained_variance   | 0.559       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.83        |\n",
            "|    n_updates            | 280         |\n",
            "|    policy_gradient_loss | 0.000235    |\n",
            "|    std                  | 0.842       |\n",
            "|    value_loss           | 10.5        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 30          |\n",
            "|    time_elapsed         | 147         |\n",
            "|    total_timesteps      | 61440       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003004686 |\n",
            "|    clip_fraction        | 0.0175      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.24       |\n",
            "|    explained_variance   | 0.532       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.6         |\n",
            "|    n_updates            | 290         |\n",
            "|    policy_gradient_loss | -0.000233   |\n",
            "|    std                  | 0.835       |\n",
            "|    value_loss           | 11.3        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 160\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1275443.44\n",
            "total_reward: 261100.48\n",
            "total_cost: 3001.27\n",
            "total_trades: 389\n",
            "Sharpe: 0.877\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 414          |\n",
            "|    iterations           | 31           |\n",
            "|    time_elapsed         | 153          |\n",
            "|    total_timesteps      | 63488        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026927388 |\n",
            "|    clip_fraction        | 0.0385       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.23        |\n",
            "|    explained_variance   | 0.601        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.59         |\n",
            "|    n_updates            | 300          |\n",
            "|    policy_gradient_loss | -0.00215     |\n",
            "|    std                  | 0.83         |\n",
            "|    value_loss           | 10.3         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 32           |\n",
            "|    time_elapsed         | 157          |\n",
            "|    total_timesteps      | 65536        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032059916 |\n",
            "|    clip_fraction        | 0.0216       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.21        |\n",
            "|    explained_variance   | 0.681        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.27         |\n",
            "|    n_updates            | 310          |\n",
            "|    policy_gradient_loss | -0.00173     |\n",
            "|    std                  | 0.799        |\n",
            "|    value_loss           | 8.85         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 170\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1249078.77\n",
            "total_reward: 234735.81\n",
            "total_cost: 2524.30\n",
            "total_trades: 389\n",
            "Sharpe: 0.772\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 414          |\n",
            "|    iterations           | 33           |\n",
            "|    time_elapsed         | 163          |\n",
            "|    total_timesteps      | 67584        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023778677 |\n",
            "|    clip_fraction        | 0.0334       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.2         |\n",
            "|    explained_variance   | 0.698        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.5          |\n",
            "|    n_updates            | 320          |\n",
            "|    policy_gradient_loss | -0.000295    |\n",
            "|    std                  | 0.809        |\n",
            "|    value_loss           | 8.66         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 414          |\n",
            "|    iterations           | 34           |\n",
            "|    time_elapsed         | 168          |\n",
            "|    total_timesteps      | 69632        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026998934 |\n",
            "|    clip_fraction        | 0.0268       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.2         |\n",
            "|    explained_variance   | 0.697        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.54         |\n",
            "|    n_updates            | 330          |\n",
            "|    policy_gradient_loss | -0.000867    |\n",
            "|    std                  | 0.802        |\n",
            "|    value_loss           | 9.74         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 180\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1261477.17\n",
            "total_reward: 247134.21\n",
            "total_cost: 2649.97\n",
            "total_trades: 386\n",
            "Sharpe: 0.814\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 414        |\n",
            "|    iterations           | 35         |\n",
            "|    time_elapsed         | 172        |\n",
            "|    total_timesteps      | 71680      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00430891 |\n",
            "|    clip_fraction        | 0.0645     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.2       |\n",
            "|    explained_variance   | 0.7        |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 3.64       |\n",
            "|    n_updates            | 340        |\n",
            "|    policy_gradient_loss | -0.000763  |\n",
            "|    std                  | 0.8        |\n",
            "|    value_loss           | 9.6        |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 413          |\n",
            "|    iterations           | 36           |\n",
            "|    time_elapsed         | 178          |\n",
            "|    total_timesteps      | 73728        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046629426 |\n",
            "|    clip_fraction        | 0.0333       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.19        |\n",
            "|    explained_variance   | 0.609        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.56         |\n",
            "|    n_updates            | 350          |\n",
            "|    policy_gradient_loss | -0.00215     |\n",
            "|    std                  | 0.785        |\n",
            "|    value_loss           | 11.7         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 190\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1257346.97\n",
            "total_reward: 243004.01\n",
            "total_cost: 2690.12\n",
            "total_trades: 384\n",
            "Sharpe: 0.752\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 414         |\n",
            "|    iterations           | 37          |\n",
            "|    time_elapsed         | 182         |\n",
            "|    total_timesteps      | 75776       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004276785 |\n",
            "|    clip_fraction        | 0.0293      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.18       |\n",
            "|    explained_variance   | 0.587       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.03        |\n",
            "|    n_updates            | 360         |\n",
            "|    policy_gradient_loss | -1.53e-05   |\n",
            "|    std                  | 0.785       |\n",
            "|    value_loss           | 11.5        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 414         |\n",
            "|    iterations           | 38          |\n",
            "|    time_elapsed         | 187         |\n",
            "|    total_timesteps      | 77824       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001648762 |\n",
            "|    clip_fraction        | 0.0259      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.18       |\n",
            "|    explained_variance   | 0.595       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.22        |\n",
            "|    n_updates            | 370         |\n",
            "|    policy_gradient_loss | -0.00212    |\n",
            "|    std                  | 0.79        |\n",
            "|    value_loss           | 11.4        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 200\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1247866.96\n",
            "total_reward: 233524.00\n",
            "total_cost: 2405.00\n",
            "total_trades: 389\n",
            "Sharpe: 0.729\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 413          |\n",
            "|    iterations           | 39           |\n",
            "|    time_elapsed         | 193          |\n",
            "|    total_timesteps      | 79872        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021620905 |\n",
            "|    clip_fraction        | 0.0252       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.19        |\n",
            "|    explained_variance   | 0.509        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6            |\n",
            "|    n_updates            | 380          |\n",
            "|    policy_gradient_loss | 0.000118     |\n",
            "|    std                  | 0.791        |\n",
            "|    value_loss           | 11.8         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 414          |\n",
            "|    iterations           | 40           |\n",
            "|    time_elapsed         | 197          |\n",
            "|    total_timesteps      | 81920        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028605745 |\n",
            "|    clip_fraction        | 0.0284       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.17        |\n",
            "|    explained_variance   | 0.473        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.58         |\n",
            "|    n_updates            | 390          |\n",
            "|    policy_gradient_loss | -0.000608    |\n",
            "|    std                  | 0.773        |\n",
            "|    value_loss           | 11.7         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 210\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1241759.60\n",
            "total_reward: 227416.64\n",
            "total_cost: 2467.26\n",
            "total_trades: 391\n",
            "Sharpe: 0.699\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 413          |\n",
            "|    iterations           | 41           |\n",
            "|    time_elapsed         | 203          |\n",
            "|    total_timesteps      | 83968        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035406328 |\n",
            "|    clip_fraction        | 0.0258       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.16        |\n",
            "|    explained_variance   | 0.48         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.06         |\n",
            "|    n_updates            | 400          |\n",
            "|    policy_gradient_loss | -0.000998    |\n",
            "|    std                  | 0.772        |\n",
            "|    value_loss           | 11.1         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 413          |\n",
            "|    iterations           | 42           |\n",
            "|    time_elapsed         | 207          |\n",
            "|    total_timesteps      | 86016        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028669785 |\n",
            "|    clip_fraction        | 0.0259       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.15        |\n",
            "|    explained_variance   | 0.528        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.46         |\n",
            "|    n_updates            | 410          |\n",
            "|    policy_gradient_loss | -0.00104     |\n",
            "|    std                  | 0.758        |\n",
            "|    value_loss           | 10.6         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 220\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1249083.04\n",
            "total_reward: 234740.08\n",
            "total_cost: 2300.85\n",
            "total_trades: 387\n",
            "Sharpe: 0.730\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 414          |\n",
            "|    iterations           | 43           |\n",
            "|    time_elapsed         | 212          |\n",
            "|    total_timesteps      | 88064        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010055163 |\n",
            "|    clip_fraction        | 0.0198       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.14        |\n",
            "|    explained_variance   | 0.494        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.59         |\n",
            "|    n_updates            | 420          |\n",
            "|    policy_gradient_loss | 0.000284     |\n",
            "|    std                  | 0.756        |\n",
            "|    value_loss           | 11.4         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 413          |\n",
            "|    iterations           | 44           |\n",
            "|    time_elapsed         | 218          |\n",
            "|    total_timesteps      | 90112        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054046027 |\n",
            "|    clip_fraction        | 0.0315       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.14        |\n",
            "|    explained_variance   | 0.5          |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.27         |\n",
            "|    n_updates            | 430          |\n",
            "|    policy_gradient_loss | 0.000181     |\n",
            "|    std                  | 0.762        |\n",
            "|    value_loss           | 11.6         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 230\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1253237.41\n",
            "total_reward: 238894.45\n",
            "total_cost: 2349.69\n",
            "total_trades: 388\n",
            "Sharpe: 0.723\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 413          |\n",
            "|    iterations           | 45           |\n",
            "|    time_elapsed         | 222          |\n",
            "|    total_timesteps      | 92160        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026558484 |\n",
            "|    clip_fraction        | 0.0359       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.15        |\n",
            "|    explained_variance   | 0.446        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.19         |\n",
            "|    n_updates            | 440          |\n",
            "|    policy_gradient_loss | -0.00208     |\n",
            "|    std                  | 0.76         |\n",
            "|    value_loss           | 11.3         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 240\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1248144.61\n",
            "total_reward: 233801.65\n",
            "total_cost: 2222.30\n",
            "total_trades: 388\n",
            "Sharpe: 0.703\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 413         |\n",
            "|    iterations           | 46          |\n",
            "|    time_elapsed         | 227         |\n",
            "|    total_timesteps      | 94208       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002829641 |\n",
            "|    clip_fraction        | 0.0358      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.14       |\n",
            "|    explained_variance   | 0.39        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.52        |\n",
            "|    n_updates            | 450         |\n",
            "|    policy_gradient_loss | -0.000753   |\n",
            "|    std                  | 0.76        |\n",
            "|    value_loss           | 11.5        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 413          |\n",
            "|    iterations           | 47           |\n",
            "|    time_elapsed         | 232          |\n",
            "|    total_timesteps      | 96256        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0050825635 |\n",
            "|    clip_fraction        | 0.049        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.14        |\n",
            "|    explained_variance   | 0.326        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.6          |\n",
            "|    n_updates            | 460          |\n",
            "|    policy_gradient_loss | -0.00335     |\n",
            "|    std                  | 0.759        |\n",
            "|    value_loss           | 12.6         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 250\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1238456.87\n",
            "total_reward: 224113.91\n",
            "total_cost: 2088.88\n",
            "total_trades: 387\n",
            "Sharpe: 0.689\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 413         |\n",
            "|    iterations           | 48          |\n",
            "|    time_elapsed         | 237         |\n",
            "|    total_timesteps      | 98304       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005734128 |\n",
            "|    clip_fraction        | 0.0486      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.13       |\n",
            "|    explained_variance   | 0.272       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.77        |\n",
            "|    n_updates            | 470         |\n",
            "|    policy_gradient_loss | -0.00394    |\n",
            "|    std                  | 0.747       |\n",
            "|    value_loss           | 12.8        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 412        |\n",
            "|    iterations           | 49         |\n",
            "|    time_elapsed         | 243        |\n",
            "|    total_timesteps      | 100352     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00635505 |\n",
            "|    clip_fraction        | 0.0401     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.12      |\n",
            "|    explained_variance   | 0.265      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 4.54       |\n",
            "|    n_updates            | 480        |\n",
            "|    policy_gradient_loss | -0.00199   |\n",
            "|    std                  | 0.739      |\n",
            "|    value_loss           | 12.3       |\n",
            "----------------------------------------\n",
            "day: 391, episode: 260\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1241983.53\n",
            "total_reward: 227640.57\n",
            "total_cost: 2078.39\n",
            "total_trades: 388\n",
            "Sharpe: 0.688\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 413         |\n",
            "|    iterations           | 50          |\n",
            "|    time_elapsed         | 247         |\n",
            "|    total_timesteps      | 102400      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003671416 |\n",
            "|    clip_fraction        | 0.0399      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.11       |\n",
            "|    explained_variance   | 0.317       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.41        |\n",
            "|    n_updates            | 490         |\n",
            "|    policy_gradient_loss | -0.00216    |\n",
            "|    std                  | 0.736       |\n",
            "|    value_loss           | 11.5        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 413          |\n",
            "|    iterations           | 51           |\n",
            "|    time_elapsed         | 252          |\n",
            "|    total_timesteps      | 104448       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032854916 |\n",
            "|    clip_fraction        | 0.0337       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.11        |\n",
            "|    explained_variance   | 0.279        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.36         |\n",
            "|    n_updates            | 500          |\n",
            "|    policy_gradient_loss | -0.000126    |\n",
            "|    std                  | 0.734        |\n",
            "|    value_loss           | 11.9         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 270\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1249193.61\n",
            "total_reward: 234850.65\n",
            "total_cost: 2024.58\n",
            "total_trades: 386\n",
            "Sharpe: 0.702\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 413          |\n",
            "|    iterations           | 52           |\n",
            "|    time_elapsed         | 257          |\n",
            "|    total_timesteps      | 106496       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0051397667 |\n",
            "|    clip_fraction        | 0.0441       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.11        |\n",
            "|    explained_variance   | 0.244        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.54         |\n",
            "|    n_updates            | 510          |\n",
            "|    policy_gradient_loss | -0.00191     |\n",
            "|    std                  | 0.728        |\n",
            "|    value_loss           | 12.4         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 413          |\n",
            "|    iterations           | 53           |\n",
            "|    time_elapsed         | 262          |\n",
            "|    total_timesteps      | 108544       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039147777 |\n",
            "|    clip_fraction        | 0.034        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.09        |\n",
            "|    explained_variance   | 0.197        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.9          |\n",
            "|    n_updates            | 520          |\n",
            "|    policy_gradient_loss | -0.0026      |\n",
            "|    std                  | 0.719        |\n",
            "|    value_loss           | 12.9         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 280\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1268298.68\n",
            "total_reward: 253955.72\n",
            "total_cost: 2204.80\n",
            "total_trades: 391\n",
            "Sharpe: 0.740\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 413          |\n",
            "|    iterations           | 54           |\n",
            "|    time_elapsed         | 267          |\n",
            "|    total_timesteps      | 110592       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015735461 |\n",
            "|    clip_fraction        | 0.0212       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.08        |\n",
            "|    explained_variance   | 0.225        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.48         |\n",
            "|    n_updates            | 530          |\n",
            "|    policy_gradient_loss | 0.00095      |\n",
            "|    std                  | 0.709        |\n",
            "|    value_loss           | 12.2         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 413          |\n",
            "|    iterations           | 55           |\n",
            "|    time_elapsed         | 272          |\n",
            "|    total_timesteps      | 112640       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0049749212 |\n",
            "|    clip_fraction        | 0.0484       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.07        |\n",
            "|    explained_variance   | 0.12         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.02         |\n",
            "|    n_updates            | 540          |\n",
            "|    policy_gradient_loss | -0.00254     |\n",
            "|    std                  | 0.708        |\n",
            "|    value_loss           | 13           |\n",
            "------------------------------------------\n",
            "day: 391, episode: 290\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1243659.65\n",
            "total_reward: 229316.69\n",
            "total_cost: 2258.19\n",
            "total_trades: 387\n",
            "Sharpe: 0.691\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 413          |\n",
            "|    iterations           | 56           |\n",
            "|    time_elapsed         | 277          |\n",
            "|    total_timesteps      | 114688       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0056423554 |\n",
            "|    clip_fraction        | 0.0456       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.07        |\n",
            "|    explained_variance   | 0.108        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.17         |\n",
            "|    n_updates            | 550          |\n",
            "|    policy_gradient_loss | -0.00112     |\n",
            "|    std                  | 0.703        |\n",
            "|    value_loss           | 13.4         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 413          |\n",
            "|    iterations           | 57           |\n",
            "|    time_elapsed         | 282          |\n",
            "|    total_timesteps      | 116736       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010882914 |\n",
            "|    clip_fraction        | 0.0249       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.07        |\n",
            "|    explained_variance   | 0.108        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.45         |\n",
            "|    n_updates            | 560          |\n",
            "|    policy_gradient_loss | -0.00171     |\n",
            "|    std                  | 0.705        |\n",
            "|    value_loss           | 13.2         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 300\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1262535.74\n",
            "total_reward: 248192.78\n",
            "total_cost: 1951.34\n",
            "total_trades: 389\n",
            "Sharpe: 0.729\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 413          |\n",
            "|    iterations           | 58           |\n",
            "|    time_elapsed         | 287          |\n",
            "|    total_timesteps      | 118784       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0052390033 |\n",
            "|    clip_fraction        | 0.0505       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.06        |\n",
            "|    explained_variance   | 0.131        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.23         |\n",
            "|    n_updates            | 570          |\n",
            "|    policy_gradient_loss | -0.00423     |\n",
            "|    std                  | 0.697        |\n",
            "|    value_loss           | 13           |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 414         |\n",
            "|    iterations           | 59          |\n",
            "|    time_elapsed         | 291         |\n",
            "|    total_timesteps      | 120832      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006491242 |\n",
            "|    clip_fraction        | 0.0348      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.05       |\n",
            "|    explained_variance   | 0.107       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 8.16        |\n",
            "|    n_updates            | 580         |\n",
            "|    policy_gradient_loss | -0.00151    |\n",
            "|    std                  | 0.684       |\n",
            "|    value_loss           | 13          |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 310\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1259936.72\n",
            "total_reward: 245593.76\n",
            "total_cost: 1713.38\n",
            "total_trades: 389\n",
            "Sharpe: 0.723\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 413          |\n",
            "|    iterations           | 60           |\n",
            "|    time_elapsed         | 297          |\n",
            "|    total_timesteps      | 122880       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0053140963 |\n",
            "|    clip_fraction        | 0.0435       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.03        |\n",
            "|    explained_variance   | 0.0468       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.45         |\n",
            "|    n_updates            | 590          |\n",
            "|    policy_gradient_loss | -0.00215     |\n",
            "|    std                  | 0.678        |\n",
            "|    value_loss           | 13.6         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 413         |\n",
            "|    iterations           | 61          |\n",
            "|    time_elapsed         | 301         |\n",
            "|    total_timesteps      | 124928      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004823519 |\n",
            "|    clip_fraction        | 0.027       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.03       |\n",
            "|    explained_variance   | 0.0274      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 8.48        |\n",
            "|    n_updates            | 600         |\n",
            "|    policy_gradient_loss | -0.000213   |\n",
            "|    std                  | 0.671       |\n",
            "|    value_loss           | 14.1        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 320\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1259858.09\n",
            "total_reward: 245515.13\n",
            "total_cost: 1770.44\n",
            "total_trades: 389\n",
            "Sharpe: 0.725\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 413          |\n",
            "|    iterations           | 62           |\n",
            "|    time_elapsed         | 306          |\n",
            "|    total_timesteps      | 126976       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024546739 |\n",
            "|    clip_fraction        | 0.0189       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.02        |\n",
            "|    explained_variance   | 0.0225       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.91         |\n",
            "|    n_updates            | 610          |\n",
            "|    policy_gradient_loss | -0.0025      |\n",
            "|    std                  | 0.667        |\n",
            "|    value_loss           | 14.2         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 413         |\n",
            "|    iterations           | 63          |\n",
            "|    time_elapsed         | 311         |\n",
            "|    total_timesteps      | 129024      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002458177 |\n",
            "|    clip_fraction        | 0.0279      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.01       |\n",
            "|    explained_variance   | 0.0349      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.13        |\n",
            "|    n_updates            | 620         |\n",
            "|    policy_gradient_loss | 0.000515    |\n",
            "|    std                  | 0.661       |\n",
            "|    value_loss           | 13.7        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 330\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1261874.89\n",
            "total_reward: 247531.93\n",
            "total_cost: 2131.01\n",
            "total_trades: 383\n",
            "Sharpe: 0.728\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 414          |\n",
            "|    iterations           | 64           |\n",
            "|    time_elapsed         | 316          |\n",
            "|    total_timesteps      | 131072       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018857322 |\n",
            "|    clip_fraction        | 0.0339       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1           |\n",
            "|    explained_variance   | 0.029        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.18         |\n",
            "|    n_updates            | 630          |\n",
            "|    policy_gradient_loss | -0.00209     |\n",
            "|    std                  | 0.656        |\n",
            "|    value_loss           | 13.3         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 413         |\n",
            "|    iterations           | 65          |\n",
            "|    time_elapsed         | 322         |\n",
            "|    total_timesteps      | 133120      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004911754 |\n",
            "|    clip_fraction        | 0.0344      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1          |\n",
            "|    explained_variance   | 0.0371      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.38        |\n",
            "|    n_updates            | 640         |\n",
            "|    policy_gradient_loss | -0.000841   |\n",
            "|    std                  | 0.659       |\n",
            "|    value_loss           | 13.8        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 340\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1249534.88\n",
            "total_reward: 235191.92\n",
            "total_cost: 2017.50\n",
            "total_trades: 388\n",
            "Sharpe: 0.702\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 413         |\n",
            "|    iterations           | 66          |\n",
            "|    time_elapsed         | 326         |\n",
            "|    total_timesteps      | 135168      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003506186 |\n",
            "|    clip_fraction        | 0.0427      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.998      |\n",
            "|    explained_variance   | 0.112       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 8.85        |\n",
            "|    n_updates            | 650         |\n",
            "|    policy_gradient_loss | -0.000216   |\n",
            "|    std                  | 0.656       |\n",
            "|    value_loss           | 13.9        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 350\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1252859.56\n",
            "total_reward: 238516.60\n",
            "total_cost: 1964.32\n",
            "total_trades: 387\n",
            "Sharpe: 0.711\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 413          |\n",
            "|    iterations           | 67           |\n",
            "|    time_elapsed         | 331          |\n",
            "|    total_timesteps      | 137216       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016406863 |\n",
            "|    clip_fraction        | 0.0274       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.992       |\n",
            "|    explained_variance   | 0.0392       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.42         |\n",
            "|    n_updates            | 660          |\n",
            "|    policy_gradient_loss | -0.00106     |\n",
            "|    std                  | 0.651        |\n",
            "|    value_loss           | 13.7         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 413          |\n",
            "|    iterations           | 68           |\n",
            "|    time_elapsed         | 336          |\n",
            "|    total_timesteps      | 139264       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0060187047 |\n",
            "|    clip_fraction        | 0.0618       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.986       |\n",
            "|    explained_variance   | 0.0474       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.9          |\n",
            "|    n_updates            | 670          |\n",
            "|    policy_gradient_loss | -0.00515     |\n",
            "|    std                  | 0.645        |\n",
            "|    value_loss           | 13.4         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 360\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1248298.30\n",
            "total_reward: 233955.34\n",
            "total_cost: 2153.40\n",
            "total_trades: 387\n",
            "Sharpe: 0.700\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 413          |\n",
            "|    iterations           | 69           |\n",
            "|    time_elapsed         | 341          |\n",
            "|    total_timesteps      | 141312       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017332232 |\n",
            "|    clip_fraction        | 0.0188       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.98        |\n",
            "|    explained_variance   | 0.0382       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.22         |\n",
            "|    n_updates            | 680          |\n",
            "|    policy_gradient_loss | -0.000427    |\n",
            "|    std                  | 0.646        |\n",
            "|    value_loss           | 13.7         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 413          |\n",
            "|    iterations           | 70           |\n",
            "|    time_elapsed         | 346          |\n",
            "|    total_timesteps      | 143360       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032928865 |\n",
            "|    clip_fraction        | 0.0268       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.982       |\n",
            "|    explained_variance   | 0.0249       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.14         |\n",
            "|    n_updates            | 690          |\n",
            "|    policy_gradient_loss | -0.000964    |\n",
            "|    std                  | 0.645        |\n",
            "|    value_loss           | 13.9         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 370\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1248401.36\n",
            "total_reward: 234058.40\n",
            "total_cost: 2127.59\n",
            "total_trades: 387\n",
            "Sharpe: 0.698\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 413          |\n",
            "|    iterations           | 71           |\n",
            "|    time_elapsed         | 351          |\n",
            "|    total_timesteps      | 145408       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030965975 |\n",
            "|    clip_fraction        | 0.0376       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.981       |\n",
            "|    explained_variance   | 0.0103       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.91         |\n",
            "|    n_updates            | 700          |\n",
            "|    policy_gradient_loss | -0.00171     |\n",
            "|    std                  | 0.645        |\n",
            "|    value_loss           | 14.2         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 413          |\n",
            "|    iterations           | 72           |\n",
            "|    time_elapsed         | 356          |\n",
            "|    total_timesteps      | 147456       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0050628204 |\n",
            "|    clip_fraction        | 0.0445       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.974       |\n",
            "|    explained_variance   | 0.00641      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.02         |\n",
            "|    n_updates            | 710          |\n",
            "|    policy_gradient_loss | -0.0021      |\n",
            "|    std                  | 0.638        |\n",
            "|    value_loss           | 13.9         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 380\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1244359.29\n",
            "total_reward: 230016.33\n",
            "total_cost: 2124.58\n",
            "total_trades: 389\n",
            "Sharpe: 0.691\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 413         |\n",
            "|    iterations           | 73          |\n",
            "|    time_elapsed         | 361         |\n",
            "|    total_timesteps      | 149504      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005435466 |\n",
            "|    clip_fraction        | 0.0663      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.96       |\n",
            "|    explained_variance   | 0.00522     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.23        |\n",
            "|    n_updates            | 720         |\n",
            "|    policy_gradient_loss | -0.00396    |\n",
            "|    std                  | 0.627       |\n",
            "|    value_loss           | 13.9        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 413         |\n",
            "|    iterations           | 74          |\n",
            "|    time_elapsed         | 366         |\n",
            "|    total_timesteps      | 151552      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005732055 |\n",
            "|    clip_fraction        | 0.0512      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.945      |\n",
            "|    explained_variance   | 0.0225      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.37        |\n",
            "|    n_updates            | 730         |\n",
            "|    policy_gradient_loss | -0.00237    |\n",
            "|    std                  | 0.62        |\n",
            "|    value_loss           | 14.5        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 390\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1260442.73\n",
            "total_reward: 246099.77\n",
            "total_cost: 2009.33\n",
            "total_trades: 388\n",
            "Sharpe: 0.724\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 413          |\n",
            "|    iterations           | 75           |\n",
            "|    time_elapsed         | 371          |\n",
            "|    total_timesteps      | 153600       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0057249945 |\n",
            "|    clip_fraction        | 0.0439       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.938       |\n",
            "|    explained_variance   | 0.0349       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.62         |\n",
            "|    n_updates            | 740          |\n",
            "|    policy_gradient_loss | 0.000275     |\n",
            "|    std                  | 0.618        |\n",
            "|    value_loss           | 14           |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 413          |\n",
            "|    iterations           | 76           |\n",
            "|    time_elapsed         | 376          |\n",
            "|    total_timesteps      | 155648       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033813117 |\n",
            "|    clip_fraction        | 0.0313       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.935       |\n",
            "|    explained_variance   | 0.0157       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.24         |\n",
            "|    n_updates            | 750          |\n",
            "|    policy_gradient_loss | -0.00026     |\n",
            "|    std                  | 0.614        |\n",
            "|    value_loss           | 14           |\n",
            "------------------------------------------\n",
            "day: 391, episode: 400\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1264444.96\n",
            "total_reward: 250102.00\n",
            "total_cost: 2114.57\n",
            "total_trades: 387\n",
            "Sharpe: 0.733\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 413         |\n",
            "|    iterations           | 77          |\n",
            "|    time_elapsed         | 381         |\n",
            "|    total_timesteps      | 157696      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003419357 |\n",
            "|    clip_fraction        | 0.0542      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.932      |\n",
            "|    explained_variance   | 0.0142      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.99        |\n",
            "|    n_updates            | 760         |\n",
            "|    policy_gradient_loss | 0.000308    |\n",
            "|    std                  | 0.616       |\n",
            "|    value_loss           | 13.7        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 413          |\n",
            "|    iterations           | 78           |\n",
            "|    time_elapsed         | 386          |\n",
            "|    total_timesteps      | 159744       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022691824 |\n",
            "|    clip_fraction        | 0.0239       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.937       |\n",
            "|    explained_variance   | 0.0234       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.88         |\n",
            "|    n_updates            | 770          |\n",
            "|    policy_gradient_loss | 0.00106      |\n",
            "|    std                  | 0.618        |\n",
            "|    value_loss           | 14           |\n",
            "------------------------------------------\n",
            "day: 391, episode: 410\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1262093.76\n",
            "total_reward: 247750.80\n",
            "total_cost: 2366.73\n",
            "total_trades: 386\n",
            "Sharpe: 0.730\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 413         |\n",
            "|    iterations           | 79          |\n",
            "|    time_elapsed         | 391         |\n",
            "|    total_timesteps      | 161792      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005771707 |\n",
            "|    clip_fraction        | 0.0302      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.935      |\n",
            "|    explained_variance   | 0.031       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.18        |\n",
            "|    n_updates            | 780         |\n",
            "|    policy_gradient_loss | -0.00131    |\n",
            "|    std                  | 0.612       |\n",
            "|    value_loss           | 13.9        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 413          |\n",
            "|    iterations           | 80           |\n",
            "|    time_elapsed         | 395          |\n",
            "|    total_timesteps      | 163840       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027626571 |\n",
            "|    clip_fraction        | 0.0333       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.934       |\n",
            "|    explained_variance   | 0.0556       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.35         |\n",
            "|    n_updates            | 790          |\n",
            "|    policy_gradient_loss | 1.94e-05     |\n",
            "|    std                  | 0.619        |\n",
            "|    value_loss           | 13.5         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 420\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1250868.36\n",
            "total_reward: 236525.40\n",
            "total_cost: 2454.31\n",
            "total_trades: 388\n",
            "Sharpe: 0.708\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 413         |\n",
            "|    iterations           | 81          |\n",
            "|    time_elapsed         | 401         |\n",
            "|    total_timesteps      | 165888      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007820324 |\n",
            "|    clip_fraction        | 0.0458      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.943      |\n",
            "|    explained_variance   | 0.0406      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.12        |\n",
            "|    n_updates            | 800         |\n",
            "|    policy_gradient_loss | -0.00312    |\n",
            "|    std                  | 0.624       |\n",
            "|    value_loss           | 13.5        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 413          |\n",
            "|    iterations           | 82           |\n",
            "|    time_elapsed         | 405          |\n",
            "|    total_timesteps      | 167936       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042034667 |\n",
            "|    clip_fraction        | 0.0561       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.945       |\n",
            "|    explained_variance   | 0.0359       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.77         |\n",
            "|    n_updates            | 810          |\n",
            "|    policy_gradient_loss | -0.00288     |\n",
            "|    std                  | 0.622        |\n",
            "|    value_loss           | 13.4         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 430\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1240476.48\n",
            "total_reward: 226133.52\n",
            "total_cost: 2728.61\n",
            "total_trades: 386\n",
            "Sharpe: 0.688\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 413          |\n",
            "|    iterations           | 83           |\n",
            "|    time_elapsed         | 410          |\n",
            "|    total_timesteps      | 169984       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0053721895 |\n",
            "|    clip_fraction        | 0.0762       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.937       |\n",
            "|    explained_variance   | 0.0477       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.91         |\n",
            "|    n_updates            | 820          |\n",
            "|    policy_gradient_loss | -0.00297     |\n",
            "|    std                  | 0.615        |\n",
            "|    value_loss           | 13.8         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 413         |\n",
            "|    iterations           | 84          |\n",
            "|    time_elapsed         | 415         |\n",
            "|    total_timesteps      | 172032      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004250833 |\n",
            "|    clip_fraction        | 0.0286      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.927      |\n",
            "|    explained_variance   | 0.0764      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.42        |\n",
            "|    n_updates            | 830         |\n",
            "|    policy_gradient_loss | -0.0017     |\n",
            "|    std                  | 0.608       |\n",
            "|    value_loss           | 13.3        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 440\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1223565.99\n",
            "total_reward: 209223.03\n",
            "total_cost: 2749.51\n",
            "total_trades: 386\n",
            "Sharpe: 0.653\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 413         |\n",
            "|    iterations           | 85          |\n",
            "|    time_elapsed         | 420         |\n",
            "|    total_timesteps      | 174080      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004574561 |\n",
            "|    clip_fraction        | 0.0312      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.913      |\n",
            "|    explained_variance   | 0.149       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.34        |\n",
            "|    n_updates            | 840         |\n",
            "|    policy_gradient_loss | -0.001      |\n",
            "|    std                  | 0.599       |\n",
            "|    value_loss           | 12          |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 413          |\n",
            "|    iterations           | 86           |\n",
            "|    time_elapsed         | 426          |\n",
            "|    total_timesteps      | 176128       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032893284 |\n",
            "|    clip_fraction        | 0.0377       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.902       |\n",
            "|    explained_variance   | 0.245        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.69         |\n",
            "|    n_updates            | 850          |\n",
            "|    policy_gradient_loss | -0.000772    |\n",
            "|    std                  | 0.595        |\n",
            "|    value_loss           | 11.2         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 450\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1243237.14\n",
            "total_reward: 228894.18\n",
            "total_cost: 2503.90\n",
            "total_trades: 382\n",
            "Sharpe: 0.697\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 413       |\n",
            "|    iterations           | 87        |\n",
            "|    time_elapsed         | 430       |\n",
            "|    total_timesteps      | 178176    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0045576 |\n",
            "|    clip_fraction        | 0.0301    |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -0.894    |\n",
            "|    explained_variance   | 0.285     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 5.62      |\n",
            "|    n_updates            | 860       |\n",
            "|    policy_gradient_loss | -0.000455 |\n",
            "|    std                  | 0.589     |\n",
            "|    value_loss           | 12        |\n",
            "---------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 413          |\n",
            "|    iterations           | 88           |\n",
            "|    time_elapsed         | 435          |\n",
            "|    total_timesteps      | 180224       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042307675 |\n",
            "|    clip_fraction        | 0.0264       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.884       |\n",
            "|    explained_variance   | 0.306        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.23         |\n",
            "|    n_updates            | 870          |\n",
            "|    policy_gradient_loss | -0.000388    |\n",
            "|    std                  | 0.584        |\n",
            "|    value_loss           | 12.1         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 460\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1244891.43\n",
            "total_reward: 230548.47\n",
            "total_cost: 2572.61\n",
            "total_trades: 386\n",
            "Sharpe: 0.708\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 413         |\n",
            "|    iterations           | 89          |\n",
            "|    time_elapsed         | 440         |\n",
            "|    total_timesteps      | 182272      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004445152 |\n",
            "|    clip_fraction        | 0.0304      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.874      |\n",
            "|    explained_variance   | 0.384       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.34        |\n",
            "|    n_updates            | 880         |\n",
            "|    policy_gradient_loss | -0.000645   |\n",
            "|    std                  | 0.576       |\n",
            "|    value_loss           | 11.1        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 470\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1240227.93\n",
            "total_reward: 225884.97\n",
            "total_cost: 2697.09\n",
            "total_trades: 389\n",
            "Sharpe: 0.686\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 413          |\n",
            "|    iterations           | 90           |\n",
            "|    time_elapsed         | 445          |\n",
            "|    total_timesteps      | 184320       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046536233 |\n",
            "|    clip_fraction        | 0.0368       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.873       |\n",
            "|    explained_variance   | 0.394        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.47         |\n",
            "|    n_updates            | 890          |\n",
            "|    policy_gradient_loss | -0.00172     |\n",
            "|    std                  | 0.578        |\n",
            "|    value_loss           | 11.2         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 413         |\n",
            "|    iterations           | 91          |\n",
            "|    time_elapsed         | 450         |\n",
            "|    total_timesteps      | 186368      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008395394 |\n",
            "|    clip_fraction        | 0.0708      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.869      |\n",
            "|    explained_variance   | 0.378       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.36        |\n",
            "|    n_updates            | 900         |\n",
            "|    policy_gradient_loss | -0.00318    |\n",
            "|    std                  | 0.576       |\n",
            "|    value_loss           | 11.3        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 480\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1248005.48\n",
            "total_reward: 233662.52\n",
            "total_cost: 2446.43\n",
            "total_trades: 387\n",
            "Sharpe: 0.707\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 413          |\n",
            "|    iterations           | 92           |\n",
            "|    time_elapsed         | 455          |\n",
            "|    total_timesteps      | 188416       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0070146136 |\n",
            "|    clip_fraction        | 0.0674       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.865       |\n",
            "|    explained_variance   | 0.457        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.41         |\n",
            "|    n_updates            | 910          |\n",
            "|    policy_gradient_loss | -0.00413     |\n",
            "|    std                  | 0.575        |\n",
            "|    value_loss           | 11           |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 413          |\n",
            "|    iterations           | 93           |\n",
            "|    time_elapsed         | 460          |\n",
            "|    total_timesteps      | 190464       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034059386 |\n",
            "|    clip_fraction        | 0.0358       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.855       |\n",
            "|    explained_variance   | 0.459        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.53         |\n",
            "|    n_updates            | 920          |\n",
            "|    policy_gradient_loss | 0.000181     |\n",
            "|    std                  | 0.563        |\n",
            "|    value_loss           | 11.6         |\n",
            "------------------------------------------\n",
            "day: 391, episode: 490\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1243100.44\n",
            "total_reward: 228757.48\n",
            "total_cost: 2515.30\n",
            "total_trades: 389\n",
            "Sharpe: 0.704\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 413         |\n",
            "|    iterations           | 94          |\n",
            "|    time_elapsed         | 465         |\n",
            "|    total_timesteps      | 192512      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007007422 |\n",
            "|    clip_fraction        | 0.0448      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.837      |\n",
            "|    explained_variance   | 0.5         |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.1         |\n",
            "|    n_updates            | 930         |\n",
            "|    policy_gradient_loss | -0.00147    |\n",
            "|    std                  | 0.554       |\n",
            "|    value_loss           | 10.7        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 413         |\n",
            "|    iterations           | 95          |\n",
            "|    time_elapsed         | 470         |\n",
            "|    total_timesteps      | 194560      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008154387 |\n",
            "|    clip_fraction        | 0.0495      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.83       |\n",
            "|    explained_variance   | 0.511       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.72        |\n",
            "|    n_updates            | 940         |\n",
            "|    policy_gradient_loss | 0.000184    |\n",
            "|    std                  | 0.554       |\n",
            "|    value_loss           | 10.8        |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 500\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1234847.73\n",
            "total_reward: 220504.77\n",
            "total_cost: 2576.06\n",
            "total_trades: 386\n",
            "Sharpe: 0.677\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 414          |\n",
            "|    iterations           | 96           |\n",
            "|    time_elapsed         | 474          |\n",
            "|    total_timesteps      | 196608       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0078070043 |\n",
            "|    clip_fraction        | 0.0641       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.828       |\n",
            "|    explained_variance   | 0.471        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.71         |\n",
            "|    n_updates            | 950          |\n",
            "|    policy_gradient_loss | -0.000928    |\n",
            "|    std                  | 0.554        |\n",
            "|    value_loss           | 11.5         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 413         |\n",
            "|    iterations           | 97          |\n",
            "|    time_elapsed         | 480         |\n",
            "|    total_timesteps      | 198656      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004582964 |\n",
            "|    clip_fraction        | 0.0374      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.825      |\n",
            "|    explained_variance   | 0.376       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.22        |\n",
            "|    n_updates            | 960         |\n",
            "|    policy_gradient_loss | -0.00158    |\n",
            "|    std                  | 0.552       |\n",
            "|    value_loss           | 12          |\n",
            "-----------------------------------------\n",
            "day: 391, episode: 510\n",
            "begin_total_asset: 1014342.96\n",
            "end_total_asset: 1239145.97\n",
            "total_reward: 224803.01\n",
            "total_cost: 2516.30\n",
            "total_trades: 389\n",
            "Sharpe: 0.696\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 413         |\n",
            "|    iterations           | 98          |\n",
            "|    time_elapsed         | 484         |\n",
            "|    total_timesteps      | 200704      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005543167 |\n",
            "|    clip_fraction        | 0.0521      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.825      |\n",
            "|    explained_variance   | 0.438       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.63        |\n",
            "|    n_updates            | 970         |\n",
            "|    policy_gradient_loss | -0.00129    |\n",
            "|    std                  | 0.552       |\n",
            "|    value_loss           | 11.2        |\n",
            "-----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# -------------------------------------------------\n",
        "# Step 4: Train Both Agents\n",
        "# -------------------------------------------------\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.callbacks import CheckpointCallback\n",
        "import os\n",
        "\n",
        "# Make sure your checkpoint folder exists\n",
        "os.makedirs(\"/content/checkpoints/\", exist_ok=True)\n",
        "\n",
        "def train_agent(env, model_name=\"ppo\", total_timesteps=200_000):\n",
        "    \"\"\"Train a trading agent with periodic checkpointing.\"\"\"\n",
        "    # 1. Create the checkpoint callback\n",
        "    checkpoint_callback = CheckpointCallback(\n",
        "        save_freq=50_000,\n",
        "        save_path=\"/content/checkpoints/\",\n",
        "        name_prefix=model_name\n",
        "    )\n",
        "\n",
        "    # 2. Instantiate the PPO model\n",
        "    model = PPO(\n",
        "        \"MlpPolicy\",\n",
        "        env=env,\n",
        "        seed=42,\n",
        "        verbose=1,\n",
        "        policy_kwargs={\n",
        "            \"net_arch\": [{\"pi\": [64, 64], \"vf\": [64, 64]}]\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # 3. Train, *passing* the callback into learn()\n",
        "    model.learn(\n",
        "        total_timesteps=total_timesteps,\n",
        "        callback=checkpoint_callback\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "print(\"Training Counterfactual Agent…\")\n",
        "counterfactual_model = train_agent(counterfactual_train_env, model_name=\"ppo_counterfactual\")\n",
        "counterfactual_model.save(\"/content/counterfactual_trading_model\")\n",
        "\n",
        "print(\"\\nTraining RefPaper Agent…\")\n",
        "refpaper_model = train_agent(refpaper_train_env, model_name=\"ppo_refpaper\")\n",
        "refpaper_model.save(\"/content/refpaper_trading_model\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "YWuNZ1TaXero"
      },
      "outputs": [],
      "source": [
        "# -------------------------------------------------\n",
        "# Step 5: Save Both Agents\n",
        "# -------------------------------------------------\n",
        "# After training Counterfactual\n",
        "counterfactual_model.save(f\"{MODEL_DIR}/ppo_counterfactual_latest.zip\")\n",
        "\n",
        "# After training RefPaper\n",
        "refpaper_model.save(f\"{MODEL_DIR}/ppo_refpaper_latest.zip\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------\n",
        "# Step 5 b: Save Both Agents as .pth files\n",
        "# -------------------------------------------------\n",
        "# After training Counterfactual\n",
        "import torch\n",
        "\n",
        "# Save Counterfactual model policy as .pth\n",
        "torch.save(counterfactual_model.policy.state_dict(), f\"{MODEL_DIR}/ppo_counterfactual_policy.pth\")\n",
        "\n",
        "# Save RefPaper model policy as .pth\n",
        "torch.save(refpaper_model.policy.state_dict(), f\"{MODEL_DIR}/ppo_refpaper_policy.pth\")\n"
      ],
      "metadata": {
        "id": "xVRwIy1hqyu5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cu8Z8DZL0lvd",
        "outputId": "5e829efd-ef1c-4b6b-eee5-5316fa16d3eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating Counterfactual Agent...\n",
            "\n",
            "Evaluating RefPaper Agent...\n"
          ]
        }
      ],
      "source": [
        " # -------------------------------------------------\n",
        "# Step 6: Backtesting and Evaluation - Sharpe ratio,\n",
        "# total return, annual return, annual volatility,\n",
        "# maximum drawdown and win rate\n",
        "# -------------------------------------------------\n",
        "def calculate_metrics(df_account_value):\n",
        "    \"\"\"Calculate performance metrics\"\"\"\n",
        "    df_account_value['daily_return'] = df_account_value['account_value'].pct_change(fill_method=None)\n",
        "    daily_returns = df_account_value['daily_return'].dropna()\n",
        "\n",
        "    # Basic metrics\n",
        "    total_return = df_account_value['account_value'].iloc[-1] / df_account_value['account_value'].iloc[0] - 1\n",
        "    annual_return = np.mean(daily_returns) * 252\n",
        "    annual_volatility = np.std(daily_returns) * np.sqrt(252)\n",
        "    sharpe_ratio = annual_return / annual_volatility if annual_volatility != 0 else 0\n",
        "\n",
        "    # Drawdown calculations\n",
        "    cumulative_returns = (1 + daily_returns).cumprod()\n",
        "    peak = cumulative_returns.cummax()\n",
        "    drawdown = (peak - cumulative_returns) / peak\n",
        "    max_drawdown = drawdown.max()\n",
        "\n",
        "    # Win rate\n",
        "    win_rate = (daily_returns > 0).mean()\n",
        "\n",
        "    return {\n",
        "        'Total Return': total_return,\n",
        "        'Annual Return': annual_return,\n",
        "        'Annual Volatility': annual_volatility,\n",
        "        'Sharpe Ratio': sharpe_ratio,\n",
        "        'Max Drawdown': max_drawdown,\n",
        "        'Win Rate': win_rate\n",
        "    }\n",
        "\n",
        "def evaluate_agent(model, trade_df):\n",
        "    \"\"\"Evaluate agent performance\"\"\"\n",
        "    env = StockTradingEnv(\n",
        "        df=trade_df,\n",
        "        stock_dim=1,\n",
        "        num_stock_shares=[100],\n",
        "        buy_cost_pct=[0.001],\n",
        "        sell_cost_pct=[0.001],\n",
        "        hmax=100,\n",
        "        initial_amount=1_000_000,\n",
        "        reward_scaling=1e-4,\n",
        "        state_space=11,\n",
        "        action_space=1,\n",
        "        tech_indicator_list=INDICATORS,\n",
        "        risk_indicator_col='sentiment'\n",
        "    )\n",
        "\n",
        "    obs, _ = env.reset()\n",
        "    account_values = [env.initial_amount]\n",
        "    dates = [trade_df.iloc[0]['date']]\n",
        "\n",
        "    for i in range(len(trade_df)-1):\n",
        "        action, _ = model.predict(obs)\n",
        "        obs, reward, terminated, truncated, info = env.step(action)\n",
        "        done = terminated or truncated\n",
        "\n",
        "        # Get current account value directly from the environment\n",
        "#        current_account_value = env.total_asset\n",
        "# replaced from below line\n",
        "# Get current account value from the info dict (fallback to internal memory)\n",
        "        current_account_value = info.get('total_asset', None)\n",
        "        if current_account_value is None:\n",
        "# as a backup, grab the last recorded value\n",
        "          current_account_value = env.asset_memory[-1]  # or env.state[0]\n",
        "# replaced till above line\n",
        "        account_values.append(current_account_value)\n",
        "        dates.append(trade_df.iloc[i+1]['date'])\n",
        "\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    df_account_value = pd.DataFrame({'date': dates, 'account_value': account_values})\n",
        "    perf_metrics = calculate_metrics(df_account_value)\n",
        "\n",
        "    return df_account_value, perf_metrics\n",
        "\n",
        "print(\"\\nEvaluating Counterfactual Agent...\")\n",
        "cf_account_value, cf_metrics = evaluate_agent(counterfactual_model, counterfactual_trade)\n",
        "\n",
        "print(\"\\nEvaluating RefPaper Agent...\")\n",
        "rp_account_value, rp_metrics = evaluate_agent(refpaper_model, refpaper_trade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnZFS3P2nnhk",
        "outputId": "9c399231-c67b-49a5-c39e-0f43813d396f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rachev Ratio (α=0.05) for Counterfactual Agent: 0.9316\n",
            "Rachev Ratio (α=0.05) for RefPaper Agent: 0.9042\n"
          ]
        }
      ],
      "source": [
        "# -------------------------------------------------\n",
        "# Step 7: Backtesting and Evaluation - Rachev Ratio Calculation\n",
        "# -------------------------------------------------\n",
        "import numpy as np\n",
        "\n",
        "# Choose your tail‐probability (e.g. 5%)\n",
        "alpha = 0.05\n",
        "\n",
        "# Assuming you already have cf_account_value and rp_account_value from evaluate_agent()\n",
        "for name, df in [(\"Counterfactual\", cf_account_value), (\"RefPaper\", rp_account_value)]:\n",
        "    # 1) Compute daily returns\n",
        "    daily_returns = df['account_value'].pct_change().dropna()\n",
        "\n",
        "    # 2) Compute cutoffs\n",
        "    q_low  = daily_returns.quantile(alpha)\n",
        "    q_high = daily_returns.quantile(1 - alpha)\n",
        "\n",
        "    # 3) Extract tails\n",
        "    lower_tail = daily_returns[daily_returns <= q_low]\n",
        "    upper_tail = daily_returns[daily_returns >= q_high]\n",
        "\n",
        "    # 4) Expected Tail Loss (ETL) and Expected Tail Gain (ETG)\n",
        "    etl = abs(lower_tail.mean())\n",
        "    etg = upper_tail.mean()\n",
        "\n",
        "    # 5) Rachev ratio (guarding against zero ETL)\n",
        "    rachev = etg / etl if etl != 0 else np.nan\n",
        "\n",
        "    print(f\"Rachev Ratio (α={alpha}) for {name} Agent: {rachev:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sm0UsuKW01-c",
        "outputId": "7b2f058f-2095-4b67-b4a7-1bd165509124"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Performance Comparison ===\n",
            "           Metric  Counterfactual  RefPaper\n",
            "     Total Return        0.078088  0.072370\n",
            "    Annual Return        0.120755  0.113106\n",
            "Annual Volatility        0.120535  0.123613\n",
            "     Sharpe Ratio        1.001830  0.915002\n",
            "     Max Drawdown        0.098987  0.101649\n",
            "         Win Rate        0.395210  0.395210\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# -------------------------------------------------\n",
        "# Step 8: Comparison and Visualization\n",
        "# -------------------------------------------------\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Combine results for comparison\n",
        "results_df = pd.DataFrame({\n",
        "    'Metric': list(cf_metrics.keys()),\n",
        "    'Counterfactual': list(cf_metrics.values()),\n",
        "    'RefPaper': list(rp_metrics.values())\n",
        "})\n",
        "\n",
        "print(\"\\n=== Performance Comparison ===\")\n",
        "print(results_df.to_string(index=False))\n",
        "\n",
        "# Plot account value growth\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(cf_account_value['date'], cf_account_value['account_value'], label='Counterfactual Agent')\n",
        "plt.plot(rp_account_value['date'], rp_account_value['account_value'], label='RefPaper Agent')\n",
        "plt.title('Account Value Growth Comparison')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Account Value ($)')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8e0RJlzv0qtd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6UC4tCux02DH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b8aea02",
        "outputId": "07cfacba-9e7a-488a-d2f0-d8ed57c8557b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating Counterfactual Agent (from .pth)...\n",
            "\n",
            "=== Performance Metrics from .pth ===\n",
            "           Metric  Counterfactual (.pth)\n",
            "     Total Return               0.072264\n",
            "    Annual Return               0.113120\n",
            "Annual Volatility               0.124904\n",
            "     Sharpe Ratio               0.905658\n",
            "     Max Drawdown               0.103105\n",
            "         Win Rate               0.395210\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# -------------------------------------------------\n",
        "# Load PPO model from .pth and evaluate Counterfactual Agent\n",
        "# -------------------------------------------------\n",
        "import torch\n",
        "from stable_baselines3 import PPO\n",
        "\n",
        "\n",
        "# Rebuild the environment used during training\n",
        "env = StockTradingEnv(\n",
        "    df=counterfactual_trade,\n",
        "    stock_dim=1,\n",
        "    num_stock_shares=[100],\n",
        "    buy_cost_pct=[0.001],\n",
        "    sell_cost_pct=[0.001],\n",
        "    hmax=100,\n",
        "    initial_amount=1_000_000,\n",
        "    reward_scaling=1e-4,\n",
        "    state_space=11,\n",
        "    action_space=1,\n",
        "    tech_indicator_list=INDICATORS,\n",
        "    risk_indicator_col='sentiment'\n",
        ")\n",
        "\n",
        "# Recreate the PPO model (same architecture as training)\n",
        "model_from_pth = PPO(\"MlpPolicy\", env=env, verbose=0, seed=42)\n",
        "\n",
        "# Load policy weights from .pth file\n",
        "model_from_pth.policy.load_state_dict(torch.load(\"/content/ppo_counterfactual_policy.pth\"))\n",
        "\n",
        "# Evaluate Counterfactual agent loaded from .pth\n",
        "print(\"\\nEvaluating Counterfactual Agent (from .pth)...\")\n",
        "cf_account_value, cf_metrics = evaluate_agent(model_from_pth, counterfactual_trade)\n",
        "\n",
        "# Display performance metrics\n",
        "import pandas as pd\n",
        "results_df = pd.DataFrame({\n",
        "    'Metric': list(cf_metrics.keys()),\n",
        "    'Counterfactual (.pth)': list(cf_metrics.values())\n",
        "})\n",
        "print(\"\\n=== Performance Metrics from .pth ===\")\n",
        "print(results_df.to_string(index=False))\n",
        "\n",
        "# Plot performance\n",
        "import matplotlib.pyplot as plt\n",
        "cf_account_value['date'] = pd.to_datetime(cf_account_value['date'])\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(cf_account_value['date'], cf_account_value['account_value'], label='Counterfactual Agent (.pth)', linewidth=2)\n",
        "plt.title('Counterfactual Agent Performance (Loaded from .pth)')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Account Value ($)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iotNY_FVhR2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rgRtAm4chR6s"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}